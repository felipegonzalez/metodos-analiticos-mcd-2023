# Modelos causales e inferencia

En esta parte consideramos nuestros modelos gráficos no simplemente
como maneras de factorizar un modelo probabilístico, sino 
también como una manera de establecer nuestros supuestos causales
acerca del problema de interés. Estos son supuestos que son necesarios para hacer inferencia causal. 

Comenzaremos entonces con una pregunta fundamental de inferencia causal: ¿qué sucede si modificamos una variable $X=x$ a una variable respuesta $Y$? 
¿Podemos estimar este efecto a partir de datos observados? La respuesta dependerá
de nuestros supuestos causales, y veremos varios ejemplos de cuándo es posible 
y cómo **identificar** y calcular estas estimaciones causales.

## Intervenciones

```{r}
#| code-fold: true
#| warning: false
library(tidyverse)
library(kableExtra)
library(DiagrammeR)
ggplot2::theme_set(ggplot2::theme_light())
inv_logit <- \(x) 1 / (1 + exp(-x)) 

```

 Desde el punto de vista de Pearl, nuestro objeto principal
de interés es la distribución condicional de la respuesta *dada una manipulación*,
que define como
$$p(y | do(x))$$
Esto significa: ¿cómo se distribuye la $Y$ dado que intervenimos en la población
completa (aunque podemos también considerar subpoblaciones más adelante) para
poner en $X=x$?. En primer lugar, notemos que esto no es lo mismo que la distribución 

$$p(y|x)$$
que podemos estimar directamente de los datos.

### Ejemplo (Pearl) {-}
Supongamos que tenemos el siguiente modelo del diagrama causal: 

```{r}
#| code-fold: true
grViz("
digraph {
  graph [ranksep = 0.2]
  node [shape=plaintext]

  edge [minlen = 3]
   U_t -> T
   T -> A
   T -> Z
   U_a -> A
   U_z -> Z
   
   
}
")
```

donde
$T$ es la temperatura, $A$ son las unidades de agua embotellada vendida
y $Z$ es la actividad de los mosquitos (medido con muestreo, por ejemplo).
Mostramos también otras variables causales que pueden afectar
a las variables de interés (muchas veces omitimos estas variables que solo afectan a una
variable de interés), pero que no tienen efecto sobre otras variables del diagrama.

No interesa contestar la pregunta: ¿qué tanto influyen las ventas de agua embotellada en la actividad de los mosquitos? 
Del diagrama, sabemos que no hay ningún camino causal de $Z$ a $A$, por 
lo que nuestra respuesta debería ser igual a 0. 

Sin embargo, sabemos que estas
dos variables están asociadas (por el análisis de DAGs), de manera que describir cómo cambia $p(z|a)$ cuando
condicionamos a distintos valores de $a$ no responde nuestra pregunta. La distribución $p(z|do(a))$ nos dice cómo se distribuye $Z$ cuando manipulamos $a$ artificialmente. Por ejemplo, si cerramos todas las tiendas un día haciendo $do(a=0)$, veríamos que esta variable no tiene efecto sobre la actividad de mosquitos, por ejemplo comparado con $do(a = 10000)$.

Ilustramos la diferencia entre $p(y|x)$ y $p(y|do(x))$ simulando del ejemplo anterior. Supondremos que sólo consideramos un día del año a lo largo de varios años, para
no modelar el comportamiento cíclo de la temperatura:

```{r}
simular_t <- function(n = 10, dia = 150){
  # simular un año, alrededor del día 160 (en junio)
  t_maxima <- rnorm(n, 28, 2)
  mosquitos <- rpois(n, 250 + 10 * (t_maxima - 28))
  a_unidades <- rnorm(n, 20000 + 2000 * (t_maxima -  28), 2000)
  tibble(t_maxima, a_unidades, mosquitos)
}
set.seed(128)
simular_dias <- simular_t(50)
```

Si simulamos, vemos que $mosquitos$ y $unidades$ son dependientes, pues tenemos
un camino abierto dado por la bifurcación en temperatura:

```{r, fig.width = 5, fig.height=3.5}
ggplot(simular_dias, aes(x = a_unidades, y = mosquitos)) + geom_point() +
  geom_smooth(method = "loess", method.args = list(degree = 1)) +
  xlab("Ventas de agua embotellada")
```

Sabemos que esta asociación no es causal, pues no hay caminos causales entre estas
variables dos variables, pero que hay una dependencia debido a la bifurcación en 
$T$. La gráfica muestra que la media condicional $E[M|A=a]$ depende fuertemente
de $a$, lo que quiere decir que $p(m|a)$ depende de $a$ fuertemente.


## Ejemplo: una intervención simple

En este caso, nos interesaría saber qué sucede si alteramos artificalmente el número
de botellas de agua vendidas (puedes imaginar distintas maneras de hacer esto).

Cuando hacemos esto, quitamos las aristas que van hacia $A$,
pues $A$ ya no está determinado por el proceso generador de datos. Tenemos
entonces la nueva gráfica:

```{r}
#| code-fold: true
grViz("
digraph {
  graph [ranksep = 0.2]
  node [shape=plaintext]
   A
  edge [minlen = 3]
   U_t -> T
   T -> Z
   U_m -> Z
{ rank = same; A; Z }
}
")
```

En esta nueva gráfica, $A$ y $Z$ son independientes, que es la respuesta correcta.
Como cambiamos la gráfica, su proceso generador es diferente al original
de los datos observados. Sin embargo, en este ejemplo puedes ver por qué es
claro que el cambio que hicimos (manipular $A$ en lugar de que esté determinado
por su proceso generador original) no cambia el modelo de $Z$, de manera
que podemos simular de nuestro nuevo proceso generador donde manipulamos $A$:

```{r}
simular_cirugia <- function(n = 10, a_unidades = a_unidades){
  # simular un año, alrededor del día 160 (en junio)
  t_maxima <- rnorm(n, 28, 2)
  #### cirugía #########
  # ahora a_unidades es fijado por nosotros:
  # a_unidades <- rnorm(n, 20000 + 2000 * (t_maxima -  28), 2000)
  a_unidades <- a_unidades
  ######################
  mosquitos <- rpois(n, 250 + 10 * (t_maxima - 28))
  tibble(t_maxima, a_unidades, mosquitos)
}
```


Y ahora simulamos y graficamos $p(z|do(a))$ para distintos valores de $u$:

```{r}
set.seed(128)
simular_dias_2 <- map_df(seq(10000, 30000, 1000),
  \(u) simular_cirugia(50, a_unidades = u))
```


```{r, fig.width = 5, fig.height=3.5}
ggplot(simular_dias_2, aes(x = a_unidades, y = mosquitos)) +
  geom_point() + geom_smooth()
```

y vemos, como esperaríamos, que no hay relación entre unidades de agua embotellada
y tasa de crimen.

## Cálculo-do de Pearl

El cálculo do nos da reglas para operar con probabilidades que incluyen
nuestro operador *do* de intervención. En este ejemplo particular, veremos 
cómo es el argumento:

Nótese que al intervenir $A$ hemos modificado el proceso generador. Si la conjunta original
tiene distribución $p$, escribimos $p_m$ para la conjunta de la gráfica modificada,
de manera que $p(z|do(a)) = p_m(z|a)$.

Aunque intuitivamente vimos cómo simular de esta distribución arriba, especificamos
abajo qué reglas son las que nos permiten hacer esto: ¿cómo calculamos $p_m$?

En primer lugar, consideremos $p_m(t)$. Esta marginal es invariante a nuestra
cirugía, pues la arista $T\to A$ que eliminamos $T$ no afecta el proceso que determina $T$. De
modo que la marginal del proceso modificado es igual a la marginal observada:

$$p_m(t) = p(t)$$
En segundo lugar, tenemos que 

$$p_m(z|t,a) = p(z|t,a),$$
Pues el proceso por el cual $Z$ responde  a $T$ y $A$ es el mismo, no importa si
$A$ fue modificada artificalmente o no.

Juntamos estos argumentos. Primero, por definición,

$$p(z|do(a)) = p_m(z|a)$$

Por la regla de probabilidad total, podemos condicionar todo a $T$ y marginalizar.
La segunda igualdad la obtenemos por la independencia entre $T$ y $Z$ en nuestra
gráfica modificada (están $d$ separadas):

$$p_m(z|a) = \int p_m(z|a,t)p_m(t|a)dt = \int p_m(z|a,t)p_m(t)dt$$
En segunda igualdad, nótese que cambiamos $p_m(t|a) = p_m(t)$, lo cual podemos
verificar pues en la gráfica modificada $A$ y $T$ están $d$-separados.

Finalmente, las últimas dos distribuciones podemos extraerlas de los datos, como
explicamos arriba $p_m(z|t,a) = p(z|t,a)$ y $p_m(t) = p(t),$ y terminamos con la
fórmula

$$p(z|do(a))=p_m(z|a) = \int p(z|a,t)p(t)dt $$

Las dos distribuciones de la derecha pueden ser estimadas pues están en el contexto
de $p$, el proceso generador de datos. Así que podemos estimarlas
de los datos observados.

- Este argumento justifica el proceso que hicimos arriba: simulamos primero $T$
con su proceso generador, y después simulamos $Z$ condicional a $A$ y $T$ *según
el proceso generador original*, el cual no depende de $A$ en este ejemplo.

En el caso de arriba, simulamos de la distribución para entender cómo
se distribuía $Z$ dependiendo de modificaciones a $A$. Muchas veces nos interesa
calcular solamente la esperanza condicional, es decir, cuál es el valor
esperado de la variable de interés dado el nivel intervenido, es decir:

$E(Z|do(a)) = E_m(Z|A =a),$

que mostramos arriba con la línea ajustada. También quisiéramos 
calcular **contrastes** particulares, como qué pasaría si las ventas
de agua las aumentamos en 10 mil unidades:

$$E(Z|do(30000)) - E(Z|do(20000)),$$
que podemos calcular de manera simple con simulación:

```{r}
simular_contraste <- map_df(c(20000, 30000),
  \(u) simular_cirugia(1000, a_unidades = u)) |> 
  group_by(a_unidades) |> 
  summarise(media_mosquitos = mean(mosquitos))
simular_contraste
```
Y vemos que no hay diferencia entre las dos medias.

### Ejemplo {-}

Ahora hagamos otro ejemplo donde hay una relación causal que
queremos estimar. Imaginemos una ciudad en donde temperaturas altas
producen desabasto de agua en algunos hogares, debido a un aumento del riego. 
Nos interesa estimar el 
efecto del desabasto en las compras de agua embotellada. Nuestro diagrama
ahora es:

```{r}
#| code-fold: true
grViz("
digraph {
  graph [ranksep = 0.2]
  node [shape=plaintext]

  edge [minlen = 3]
   U_t -> T
   T -> A
   T -> D
   D -> A
   U_a -> A
   U_d -> D

{ rank = same; A; D }

}
")
```


```{r}
simular_t <- function(n = 10, dia = 150){
  # simular un año, alrededor del día 160 (en junio)
  t_maxima <- rnorm(n, 28, 2)
  u <- rnorm(n, 0, 1)
  desabasto_agua <- 1/(1 + exp(-(t_maxima - 28) + u))
  unidades <- rnorm(n, 20000 + 2000 * (t_maxima -  28) + 8000*desabasto_agua, 2000)
  tibble(t_maxima, unidades, desabasto_agua)
}
set.seed(128)
simular_dias <- simular_t(150)
```

```{r, fig.width = 5, fig.height=3.5}
ggplot(simular_dias, aes(x = desabasto_agua, y = unidades)) + 
  geom_point() + geom_smooth()
```

La correlación parece muy fuerte, sin embargo, sabemos que hay un camino no causal
de asociación entre estas dos variables. 

Igual que en ejemplo anterior, vamos a intervenir teóricamente en el desabasto
de agua. Después de la cirugía, nuestro diagrama modificado es:

```{r}
#| code-fold: true
grViz("
digraph {
  graph [ranksep = 0.2]
  node [shape=plaintext]

  edge [minlen = 3]
   U_t -> T
   T -> A
   D -> A
   U_a -> A
{ rank = same; A; D }

}
")
```

Ahora queremos calcular $p(a|do(d)) = p_m(a|d)$ en función de los datos. Siguiendo el mismo
argumento que en el ejemplo anterior, sabemos que tenemos que estratificar o condicionar
a $T$ para poder usar nuestro proceso generador de observaciones, y obtenemos:


$$p(a|do(d))=p_m(a|d) = \int p(a|d,t)p(t)dt $$
Aunque a veces es posible calcular analíticamente el lado derecho analíticamente,
podemos simular como hicimos en los ejemplos anteriores:

```{r}
simular_cirugia <- function(n = 10, da = 0){
  # simular un año, alrededor del día 160 (en junio)
  t_maxima <- rnorm(n, 28, 2)
  ### cirugía ####
  #u <- rnorm(n, 0, 1) 
  desabasto_agua <- da
  ######
  unidades <- rnorm(n, 20000 + 2000 * (t_maxima -  28) + 8000*desabasto_agua, 2000)
  tibble(t_maxima, unidades, desabasto_agua)
}
set.seed(128)
simular_dias_c <- map_df(seq(0, 1, 0.1), \(da) simular_cirugia(1000, da = da))
```

```{r, fig.width = 5, fig.height=3.5}
ggplot(simular_dias_c, aes(x = desabasto_agua, y = unidades)) + 
  geom_point() + geom_smooth()
```

Podemos también resumir promediando:

```{r}
efecto_verdadero_desabasto <- simular_dias_c |> 
  group_by(desabasto_agua) |> 
  summarise(media_unidades = mean(unidades)) |> 
  rename(desabasto = desabasto_agua)
ggplot(efecto_verdadero_desabasto,
       aes(x = desabasto, y = media_unidades)) + 
  geom_point() + geom_smooth()
```


Y este es el efecto causal del desabasto de agua. No tenemos
medidas de incertidumbre pues conocemos todos los parámetros de los modelos.
La media condicional
parece ser lineal, así que podríamos resumir con un modelo lineal:

```{r}
# Modelo 1 (con datos de intervención)
lm(unidades ~ desabasto_agua, simular_dias_c)
```
Aproximadamente, cada incremento en puntos porcentuales de 10% en desabasto incrementa las
ventas en unas 800 unidades. Compara con el análisis donde no estratificamos o
controlamos por la temperatura:

```{r}
# Modelo 2
lm(unidades ~ desabasto_agua, simular_dias)
```

Otra forma de estratificar es ajustando un modelo que incluye la variable de temperatura.
Podríamos hacer

```{r}
# Modelo 3
lm(unidades ~ desabasto_agua + t_maxima, simular_dias)
```

## Fórmula de ajuste

En resumen, tenemos la primera regla de Pearl de inferencia causal:

::: callout-note
# Fórmula de ajuste (Pearl)

Sea $G$ donde los padres de $X$ son $Z_1,Z_2$. El efecto causal total de $X$ en $Y$ se puede calcular como

$$p(y|do(x)) = \int p(y|x, z_1,z_2) p(z_1,z_2)\, dz_1dz_2$$
Es decir, condicionamos al valor de $x$ y todos los padres de $X$ para
calcular $p(y|x,z_1,z_2)$, y después marginalizamos sobre los padres.

:::

Esta fórmula se extiende a más de dos padres $Z_1,Z_2,Z_3,\ldots, Z_k$.

::: callout-tip

A este proceso se llama de diferentes maneras en distintos contextos:

- Estamos calculando el efecto causal **estratificando** por las variables $z$.
- **Controlamos**  por las variables $z$ para calcular el efecto causal.

:::

Podemos pensar en esta fórmula de dos maneras: en primer lugar,
si estamos modelando toda nuestra gráfica causal, podemos
simular de la conjunta de la gráfica mutilada:

1. Fijando el nivel del tratamiento $T$
2. Simulando $p(z_1,z_2,\ldots, z_k)$ (marginalizando
estas variables), 
3. Usar $t$ y las $z$ simuladas para simular $y$

El otro enfoque busca sólo construir modelos para la
parte que nos interesa:

1. Construir un modelo 
separado para $p(z_1, z_2,\ldots, z_k) = p(z)$
(que puede ser difícil si tenemos muchas variables) a partir los datos
2. Construir un modelo  $p(y|t, z)$ para simular la $y$ a partir
de los datos.
3. Ignoramos el resto de nuestra gráfica en este caso.

Finalmente, si tenemos un modelo $p(y| t, z)$ podemos también
investigar cómo se comporta $E[y|t_2,z] - E[y|t_1,z]$ para distintos
combinaciones de valores de $Z$.


**Nota 1**: Con este principio podemos resolver algunos problemas, pero
no todos. Veremos que en algunos casos existen padres que no son observados,
por ejemplo, no es posible condicionar para usar la fórmula de ajuste y es necesario desarrollar otras estrategias.

**Nota 2**: En regresión lineal, cuando incluímos una variable en el modelo (que consideramos una variable control), estamos
estratificando por ella: por ejemplo, en el modelo lineal $U\sim N(m_u(d,t), \sigma_u)$,
donde 

$$m_u = \beta_0 +\beta_1 d + \beta_2 t$$
Estamos calculando un estimador para cada valor de $T=t$, que es:

$$m_u = (\beta_0 + \beta_2 t) + \beta_1 d = \gamma_0 + \gamma_1 d$$
Esta es una de las maneras más simples de obtener el efecto de $d$ estratificando por,
o controlando por $t$, *siempre y cuando los modelos lineales sean apropiados*.

Nótese que en este último caso, tenemos que el efecto de $d$
no depende de las covariables, de forma que no es necesario hacer
el promedio sobre la conjunta, es decir, suponemos que
el efecto causal es el mismo independientemente de los valores de 
las variables de control. Sin embargo, este no siempre es el caso.

**Nota 3** Sin nuestro modelo $p(y|t,z)$ es lineal, y nos interesa calcular
el efecto causal promedio de la variable $t$, no es necesario promediar por
la conjunta de $p(z)$. Bajo estas condiciones, el efecto causal promedio está simplemente 
por el coeficiente de $t$ en el modelo lineal. Sin embargo, si este no es el caso,
entonces para estimar el efecto causal promedio es necesario promediar apropiadamente
según la fórmula de ajuste.



## Simulación para estimar efectos causales

La estrategia más general y conceptualmente simple (aunque técnicamente
puede ser difícil por la multitud de modelos necesarios) para usar la idea de la fórmula
de ajuste es utilizar simulación:

::: callout-note
# Fórmula de ajuste con simulación

- Para calcular efectos causales de $X$ en $Y$ , podemos simular según el proceso
generador de la gráfica mutilada donde quitamos todas las aristas que
llegan a $X$. 
En la práctica, esto implica fijar $X$, ignorar el proceso generador
de $X$, y seguir el proceso generador
original de nuestro modelo para el resto de los nodos.
- Sin embargo, también es posible utilizar la fórmula formula de ajuste, y modelar
sólo con las variables relevantes que aparecen en ella-

:::

Nótese que cuando hacemos las simulaciones siguiendo el proceso generador, marginalizar
es simple: si queremos la conjunta de $x_1$ y $x_2$ por ejemplo, simplemente extraemos
las variables $x_1$ y $x_2$ y examinamos su relación.  


En los ejemplos de arriba, todos los procesos generadores locales estaban
determinados. Cuando tenemos tenemos parámetros desconocidos, es necesario 
estimarlos antes de usar la fórmula de ajuste, y tomar en cuenta 
la incertidumbre en la estimación. 


Podemos ver cómo haríamos esto con modelos bayesianos.
En primer lugar, empezamos con el diagrama causal original, y establecemos
nuestros modelos locales

```{r}
library(cmdstanr)
mod_agua <- cmdstan_model("../src/agua-1.stan")
print(mod_agua)
```

Tomamos una muestra simulada como datos para hacer la estimación (de modo
que es no es necesario preocuparnos por el ajuste de modelos locales).

```{r}
set.seed(128)
sim_dias <- simular_t(250)
N <- nrow(sim_dias)
desabasto_do <- seq(0, 1, 0.1)
datos_lista <- list(N = N, t_maxima = sim_dias$t_maxima,
                    unidades = sim_dias$unidades,
                    desabasto_agua = sim_dias$desabasto_agua,
                    desabasto_do = desabasto_do)
ajuste <- mod_agua$sample(data = datos_lista, refresh = 1000,
                          init = 0.1, step_size = 0.1)
```


```{r}
sims <- ajuste$draws(format = "df")
resumen <- ajuste$summary(
  c("alpha_u", "beta_t", "beta_d", "mu_t", "alpha", "beta",
    "sigma_t", "sigma_d", "sigma_unidades"))
resumen |> select(variable, median, q5, q95)
```

Donde podemos checar que aproximadamente recuperamos los parámetros originales.

Como explicamos según el concepto de cálculo-do, queremos simular de una
distribución distinta para estimar el efecto causal de desabasto sobre
unidades vendidas. Para esto utilizamos las simulaciones de nuestro modelo
(que ajustamos con datos observacionales), pero en la sección de simulación
hacemos un cálculo diferente:

```{r}
#| warning: false
#| message: false
sim_intervenciones <- 
  ajuste$draws(format = "df") |> 
  select(".draw", contains("unidades_sim")) |> 
  pivot_longer(cols = contains("unidades_sim")) |> 
  separate(name, sep = "[\\[\\]]", into = c("variable", "indice"),
           convert = TRUE, extra = "drop") |> 
  left_join(tibble(desabasto = desabasto_do, indice = seq_along(desabasto_do)))
```


```{r}
sim_intervenciones |> group_by(desabasto) |> 
  summarise(media_unidades = mean(value), 
            q5 = quantile(value, 0.05),
            q95 = quantile(value, 0.95)) |> 
ggplot(aes(x=desabasto, y = media_unidades)) +
  geom_point(colour = "red") +
  geom_linerange(aes(ymin = q5, ymax = q95),colour = "red") +
  geom_point(data = efecto_verdadero_desabasto)
```
Esta gráfica puede ser difícil de interpretar, porque puede haber correlación
entre los distintos estimadores que estamos presentando. Sin embargo, vemos
cómo nuestra estimación (en rojo) está cercana a los valores teóricos.

Para comparar entre niveles del factor que manipulamos, 
lo mejor es hacer contrastes. Comparamos con la situación
de 0 desabasto, por ejemplo, y calculamos el incremento estimado:

```{r}
#| message: false
sim_nivel_0 <- filter(sim_intervenciones, desabasto == 0) |> 
  select(.draw, value_0 = value)
sim_intervenciones |> left_join(sim_nivel_0) |> 
  mutate(dif = value - value_0) |> 
  group_by(desabasto) |> 
  summarise(diferencia_media = mean(dif), 
            q5 = quantile(dif, 0.05),
            q95 = quantile(dif, 0.95)) |> 
ggplot(aes(x=desabasto, y = diferencia_media, 
           ymin = q5, ymax = q95)) +
  geom_point(colour = "red") +
  geom_linerange(colour = "red")
```

Claramente todos los estimadores están bien separados de 0. Diez puntos
porcentuales de incremento en desabasto incrementan las ventas en alrededor
de 8 mil unidades.

---

Recordemos que en todos estos ejemplos nos estamos concentrando en 
la *identificación* de un efecto causal que nos interesa, así que nos
estamos saltando algunos pasos en el proceso de modelación y estimación
que en el trabajo usual debemos seguir:

::: callout-note 
# Modelación y estimadores

El procedimiento general es (@rethinking):

1. Definir la cantidad a estimar
2. Construir un modelo causal gráfico (puede incluir variables no medidas)
3. Definir un modelo generativo basado en el modelo causal (puede tener parámetros
desconocidos, que se estimarán con datos), recorriendo los nodos y definiendo  los modelos individuales. Hacer validación a priori.
4. Definir el cálculo del estimador (por ejemplo, con la fórmula de ajuste)
5. Ajustar el modelo completo a los datos, hacer
validación posterior y calcular el estimador del paso anterior.
:::

En 2 y 3 está la mayor parte del trabajo. La parte 3 es parte de un curso de
estadística bayesiana, y para esta parte usamos un flujo bayesiano de construcción
de modelos (ver [aquí](https://arxiv.org/abs/2011.01808) o [aquí](https://betanalpha.github.io/assets/case_studies/principled_bayesian_workflow.html)).

## Ejemplo: estaturas (versión 1)

Consideramos el ejemplo donde queremos entender el **efecto de sexo en el peso
de personas**. Usaremos los siguientes datos (@rethinking), que son datos recolectados
de una población particular (Kalahari !Kung San). Tomamos sólo a los adultos
(definidos por más de 18 años).


```{r}
howell <- read_delim("../datos/Howell1.csv", delim = ";") |> 
  filter(age >= 18)
head(howell)
```

```{r}
ggplot(howell, aes(x = height, y = weight, colour = male)) +
  geom_point()
```

Empezaremos con el siguiente modelo causal:

```{r}
#| code-fold: true
grViz("
digraph {
  graph [ranksep = 0.2]
  node [shape=plaintext]
    S
    H
    W 
  node [shape = circle]
    U
  edge [minlen = 3]
    S -> H
    S -> W
    H -> W
    U -> H
    U -> W
{rank = same; S;H}
}
")

```

- En primer lugar, tenemos una flecha $H\to W$. La razón es que podemos pensar
en varias intervenciones que afectan el peso pero que no cambian la estatura. 
- En segundo lugar, $S$ es causa de $H$, pero también puede afectar directamente 
peso $W$ junto con la estatura $H$.
- $H$ y $W$ pueden tener otras causas comunes no observadas (nutrición por ejemplo), que
no influyen en $S$.

Ahora veamos cómo calcular el efecto causal **total** de sexo sobre peso.

*Podemos ver que no hay ninguna flecha que llegue a $S$, de modo que para el
efecto total no es necesario hacer cirugía ni usar la fórmula de ajuste.* 

::: callout-tip
# Condicionando equivocadamente

De hecho, en este ejemplo sería mala idea condicionar a la estatura $H$, pues cerramos
un camino causal por el que $S$ influye en $W$, y al mismo tiempo abrimos un
camino no causal que pasa por $U$.

:::

El análisis detallado de la gráfica es:

- Existen dos rutas causales de sexo a peso: una que está mediada por la estatura
y otra que es efecto directo sobre peso. **No** queremos bloquear condicionando
a la estatura $H$.
- Existe una ruta no causal de sexo sobre peso, y es el camino $S\to H \gets U \to W$.
Sin embargo, esta ruta está bloqueada por $H$, la estatura, que es un colisionador. 



Comenzamos ahora el proceso de modelado. Excluiremos a $U$ en nuestro modelo,
pues no tiene relevancia para la inferencia acerca del efecto total de $S$ sobre $W$,
como discutimos arriba.

::: callout-tip
# Ojo: interpetación de modelos

Nótese que la decisión de excluir de nuestro análisis la variable $U$
sólo tiene sentido si lo que queremos estimar es el efecto total de sexo
sobre peso. Esto implica que nuestras estimaciones que corresponden
a $H\to W$ **no** tienen interpretación causal. Una estrategia de identificación
para un efecto no implica que todo lo que salga de nuestras estimaciones
es causal.

:::


Empezamos entonces con el modelo de estatura:

$$H|S=s \sim N(m_h, \sigma_h)$$
con 

$$m_h = \alpha_0 + \alpha_1 s $$
Y el modelo de peso:


$$W|S=s,H=h \sim N(m_w, \sigma_w)$$
$$m(s,a,h) = \gamma_0 + \gamma_1 s  + \gamma_2 h$$



Lo escribimos en stan:

```{r}
mod_1 <- cmdstanr::cmdstan_model("../src/peso-estatura-inferencia-1.stan")
print(mod_1)
```

```{r}
datos_lista <- list(N = nrow(howell), s= howell$male, a = howell$age, 
                    h = howell$height, w = howell$weight)
ajuste <- mod_1$sample(data = datos_lista, refresh = 1000)
sims <- ajuste$draws( format = "df")
resumen <- ajuste$summary(c( "dif_male"))
options(scipen = 9999)
resumen |> select(variable, mean, q5, q95) |> 
  mutate(across(where(is.numeric), round, 2))
```

```{r}
sims |> ggplot(aes(x = dif_male)) + 
  geom_histogram(bins = 40)
```

Esta es nuestra estimación del diferencia causal promedio de sexo sobre el peso para 
personas adultas: está aproximadamente entre 5.5 y 8.5 kilos aproximadamente.

Sin embargo, dada la discusión que tuvimos arriba,
podemos hacer un modelo más simple para estimar el efecto total,
ignorando $W$:

```{r}
mod_2 <- cmdstanr::cmdstan_model("../src/peso-estatura-inferencia-simple.stan")
print(mod_2)
```
```{r}
datos_lista <- list(N = nrow(howell), s= howell$male, 
                    w = howell$weight)
ajuste <- mod_2$sample(data = datos_lista, refresh = 1000)
sims <- ajuste$draws( format = "df")
resumen <- ajuste$summary(c( "dif_male"))
options(scipen = 9999)
resumen |> select(variable, mean, q5, q95) |> 
  mutate(across(where(is.numeric), round, 2))
```

```{r}
sims |> ggplot(aes(x = dif_male)) + 
  geom_histogram(bins = 40)
```
Y obtenemos el mismo resultado con un modelo más simple. El modelo
anterior lo usaremos después para explorar el concepto de *mediación*.

## Bloqueando puertas traseras

En las partes anteriores vimos que estratificando por los padres
de la variable de tratamiento $X$ podemos construir un estimador del
efecto de $X$ sobre otra variable $Y$, pasando de una distribución 
observacional a una conceptualmente experimental (dado que los supuestos
causales sean aproximadamente correctos).

Sin embargo, esta aplicación de la fórmula de ajuste no funciona
si existen padres que no fueron observados, y por tanto no podemos estratificar por ellos. El siguiente método (ajuste por "puerta trasera")
nos da una técnica adicional que podemos usar dado ciertos tipos
de estructura en nuestro modelo causal, y presenta una
mejoría sobre la fórmula de ajuste simple (veremos también por ejemplo, que a veces podemos usar menos variables que padres de la variable de interés). Nótese que una vez más,
este criterio sólo depende de la gráfica causal $G$ asociada a nuestro
modelo, y no los modelos locales que utilizemos para modelar la
condicional de cada nodo.

::: callout-note
# Ajuste de puerta trasera (Pearl)

Si tenemos dos variables $T$ y $Y$ en una gráfica $G$, un conjunto $Z$
de variables satisface el **criterio de puerta trasera** relativo
a $T$ y $Y$ cuando $Z$ bloquea cualquier camino entre $T$ y $Y$ que 
tenga una arista que incida en $T$, y ninguna variable de $Z$ es 
descendiente de $T$.

En tal caso, podemos utilizar la fórmula de ajuste, pero en lugar de
estratificar por los padres de $T$, estratificamos por las variables en $Z$
:::

La idea es:

1. Queremos bloquear todos los caminos no causales entre $T$ y $Y$.
2. Queremos no perturbar todos los caminos dirigidos de $T$ a $Y$ (caminos causales).
3. No queremos activar caminos no causales entre $T$ y $Y$ al condicionar.

Cumplimos 1 al estratificar por variables que bloquean los caminos
que son causas de $T$, pues estos caminos no son causales y distorsionan
la relación entre $T$ y $Y$. Al mismo tiempo, no bloqueamos caminos
causales porque ningúna variable de $Z$ es descendiente de $T$,
de modo que se satisface el criterio 2 (todos los caminos causales
comienzan con $T\to$). Finalmente, al excluir descendientes de $T$
también implica que no condicionamos a 
colisionadores del tipo $T\to \cdots \to Z_1\gets  Y$, pues 
esto activa un camino no causal entre $T$ y $Y$ (se cumple 3). 

### Ejemplo (Pearl) {-}

Consideramos primero este ejemplo simple, donde queremos
evaluar la efectividad de un tratamiento en cierta enfermedad.
Los datos que tenemos disponibles son si una persona
recibió o no un tratamiento,  y si se recuperó o no.
No se registró el nivel socioeconómico, pero sabemos que el tratamiento
es caro, de forma que fue accedido más por gente de NSE más alto. 
También que sabemos que para este tipo de tratamiento, el peso de la
persona es un factor importante.
Nuestros supuestos están en la siguiente gráfica:

```{r}
#| code-fold: true
grViz("
digraph {
  graph [ranksep = 0.2, rankdir = LR]
  node [shape=plaintext]
    Trata
    Res
  node [shape = circle]
    NSE
    Peso
    U
  edge [minlen = 3]
    NSE -> Peso
    NSE -> Trata
    Trata -> Res
    Peso -> Res
    U -> NSE
    U -> Peso
}
")

```

Observamos que no podemos directamente usar la fórmula de ajuste pues NSE no
es una variable observada.

En esta circunstancia no podríamos identificar el efecto causal, pues
existen un caminos abiertos no causales. Quizá el tratamiento no es 
muy efectivo, y parece ser bueno pues fue aplicado a personas
con menor peso que las que no recibieron el tratamiento, a través
del efecto de NSE. Sin embargo, supón que tuviéramos disponible
la variable Peso:

```{r}
#| code-fold: true
grViz("
digraph {
  graph [ranksep = 0.2, rankdir = LR]
  node [shape=plaintext]
    Trata
    Res
    Peso
  node [shape = circle]
    NSE
    U
  edge [minlen = 3]
    NSE -> Peso
    NSE -> Trata
    Trata -> Res
    Peso -> Res
    U -> NSE
    U -> Peso
}
")

```
En este caso, todavía no podemos aplicar la fórmula original de ajuste
pues no conocemos $NSE$. Sin embargo, podemos bloquear los caminos
no causales estratificando por Peso, y entonces podemos usar el
criterio de puerta trasera para identificar el efecto del tratamiento,
aún cuando no tengamos NSE.

### Ejemplo {-}

Primero consideramos un modelo generador:

```{r}
simular_bd <- function(n = 10){
  nse <- sample(c(0, 1), n, replace = TRUE)
  peso <- rnorm(n, 70 - 7 * nse, 12 + 2 * nse)
  trata <- rbinom(n, 1, 0.8 * nse + 0.2 * (1 - nse))
  p_trata <- inv_logit(1 * trata - 0.2 * (peso - 70))
  res <- rbinom(n, 1, p_trata)
  tibble(nse, peso, trata, res)
}
datos_bd <- simular_bd(10000)
head(datos_bd)
```
Veamos qué sucede si cruzamos tratamiento con resultado (es una muestra
grande y el error de estimación no es importante):

```{r}
datos_bd |> 
  count(trata, res) |>
  group_by(trata) |> 
  mutate(p = n / sum(n)) |> 
  filter(res == 1) |> 
  ungroup() |> 
  mutate(dif = p - lag(p))
```
Sabemos que esta diferencia en respuesta puede estar confundida
por un camino no causal. El verdadero efecto casual podemos
calcularlo en nuestras simulaciones como sigue a partir 
de nuestro modelo (igualmente, usamos una muestra muy grande):

```{r}
simular_efecto <- function(n = 10, peso = NULL){
  # cómo es la población
  nse <- sample(c(0, 1), n, replace = TRUE)
  if(is.null(peso)){
    peso <- rnorm(n, 70 - 7 * nse, 12 + 2 * nse)
  }
  # asignar al azar
  trata <- rbinom(n, 1, 0.5)
  p_trata <- inv_logit(1 * trata - 0.2 * (peso - 70))
  res <- rbinom(n, 1, p_trata)
  tibble(nse, peso, trata, res)
}
sims_efecto <- simular_efecto(20000)
resumen <- sims_efecto |> 
  count(trata, res) |>
  group_by(trata) |> 
  mutate(p = n / sum(n)) |> 
  filter(res == 1) |> 
  ungroup() |> 
  mutate(dif = p - lag(p))
dif_real <- resumen$dif[2]
resumen
```
La estimación ingenua del cruce simple es mucho más grande que el verdadero efecto.

Podemos también calcular el efecto para un peso particular:

```{r}
sims_efecto <- simular_efecto(20000, peso = 70)
res_70 <- sims_efecto |> 
  count(trata, res) |>
  group_by(trata) |> 
  mutate(p = n / sum(n)) |> 
  filter(res == 1) |> 
  ungroup() |> 
  mutate(dif = p - lag(p))
dif_70 <- res_70$dif[2]
res_70
```


Suponiendo nuestro diagrama, queremos
estimar estratificando por peso. Podríamos usar un sólo
modelo logístico, pero pueden ser más simples los cálculos
si construimos nuestro modelo en stan. En este caso,
podríamos calcular las diferencias para un peso particular,
por ejemplo 70 kg (en lugar de modelar estaturas para producir
una estimación de diferencia promedio).

Usaremos una muestra de 2 mil personas:

```{r}
mod_trata <- cmdstan_model("../src/trata-backdoor.stan")
print(mod_trata)
```

```{r}
set.seed(915)
datos_bd <- simular_bd(2000)
datos_lista <- list(N = nrow(datos_bd),
  trata = datos_bd$trata, res = datos_bd$res,
  peso = datos_bd$peso)
ajuste <- mod_trata$sample(data = datos_lista, refresh = 1000)
sims <- ajuste$draws( format = "df")
resumen <- ajuste$summary(c( "dif_trata"))
```

```{r}
resumen |> select(variable, mean, q5, q95)
sims |> select(dif_trata) |> 
  ggplot(aes(x = dif_trata)) + geom_histogram() +
  geom_vline(xintercept = dif_70, colour = "red")
```

Y obtenemos una estimación correcta del efecto en 70 kg. Podríamos
también calcular el efecto en distintos pesos (nuestro estimador
es una curva), promediar estimando una distribución de pesos modelada, o tomar una distribución fija de pesos para modelar (cada una de
estas estrategias tiene propósitos diferentes).

Si queremos tener un efecto promedio, podemos modelar los pesos. Otra
estrategia es promediar sobre los valores observados de la muestra. Nótese
que esto ignora una parte de la incertidumbre proveniente de la muestra
particular usada.

```{r}
mod_trata <- cmdstan_model("../src/trata-backdoor-promedio.stan")
print(mod_trata)
```

```{r}
datos_lista <- list(N = nrow(datos_bd),
  trata = datos_bd$trata, res = datos_bd$res,
  peso = datos_bd$peso)
ajuste <- mod_trata$sample(data = datos_lista, refresh = 1000)
sims <- ajuste$draws(c("dif_trata"), format = "df")
```


```{r}
resumen <- ajuste$summary(c( "dif_trata"))
resumen |> select(variable, mean, q5, q95)
sims |> select(dif_trata) |> 
  ggplot(aes(x = dif_trata)) + geom_histogram() +
  geom_vline(xintercept = dif_real, colour = "red")
```

Y recuperamos nuevamente el efecto verdadero que mostramos arriba.

## Reglas del cálculo-do (opcional)

Existen tres axiomas básicos del cálculo-do de las que se 
derivan los demás resultados, como veremos en el siguiente
ejemplo del criterio de la puerta delantera. 


Antes de verlas, un resumen rápido de las reglas es el siguiente: 

- La regla 1 nos dice que las distribuciones
asociadas a intervenciones satisfacen también la equivalencia
de $d$-separación e independencia condicional: si $Y$ y $Z$ están
$d$-separadas dado en la gráfica manipulada, entonces $p(y | do(x), z) = p(y|do(x))$.

- La regla 2 es el criterio de la puerta trasera: si condicionamos
a variables $W$ que bloquean toda puerta trasera de $X$ a $Y$, podemos cambiar $do(x)$ por $x$: $p(y | do(x), w) = p(y | x, w)$.

- La regla 3 expresa que si no hay caminos causales de $X$ a $Y$, entonces $p(y|do(x)) = p(y)$.

::: callout-tip
# Completitud (Shpitser, Pearl)
Si un efecto causal es identificable (puede expresarse en términos de cantidades observacionales), entonces puede
derivarse una estrategia de identificación a partir de las
tres reglas del cálculo-do.
:::


**Nota**: esto no excluye que bajo ciertas hipótesis adicionales a las
de nuestra gráfica causal (por ejemplo cómo se comportan las distribuciones particulares qeu componen el modelo), sea posible identificar efectos
causales con otros medios que van más allá del cálculo-do.


Con más generalidad, abajo están estas reglas (donde condicionamos a más variables o hacemos más intervenciones, y afinamos las condiciones):

Denotamos por $G_m$ la gráfica mutilada por $do(x)$, donde
quitamos todas las aristas que entran en $X$. Los tres axiomas son:


**Regla 1** Ignorar observaciones:
Si $Y$ y $Z$ están $d$-separados por $X$ y $W$ en $G_m$,

$$ p(y|do(x), z, w) = p(y|do(x), w)$$
O en otras palabras, si $p_m$ es la conjunta para $G_m$,

$$p_m(y|x,z,w) = p_m(y|x, w)$$
es cierto si $Y$ y $Z$ están $d$-separados por $X$ y $W$ en $G_m$
(condicionalmente independientes). Así que esta regla es independencia
condicional dado $d$-separación, pero para la gráfica intervenida.

**Regla 2** Usando observaciones como intervenciones:

Si $Y$ y $Z$ están $d$-separados por $X$ y $W$ en $G_m$ quitándole 
todas las aristas que salen de $Z$, entonces

$$ p(y|do(x), do(z), w) = p(y|do(x), z, w)$$
**Regla 3** Ignorar intervenciones:

Si $Z$ y $Y$ están $d$-separadas por $X$ y $W$ en la gráfica
$G_m$ donde además quitamos cualquier arista a $Z$ si $Z$ no es antecesor de $W$ en $G_m$, entonces:

$$ p(y|do(x), do(z), w) = p(y|do(x), w)$$



## El criterio de puerta delantera

En algunos casos, puede ser que no sea posible bloquear algún camino
no causal con variables observadas. Un ejemplo clásico es el de la discusión acerca de la relación de fumar con cáncer de pulmón. Algunos estadísticos
plantearon que los estudios de asociación entre fumar y cáncer de pulmón
podrían tener efectos gravemente confundidos, por ejemplo, por aspectos genéticos que hacen a una persona propensa a fumar al mismo tiempo que
aumenta su probabilidad de fumar:

```{r}
#| code-fold: true
grViz("
digraph {
  graph [ranksep = 0.2]
  node [shape=plaintext]
    F
    C
  node [shape = circle]
    U
  edge [minlen = 3]
    U -> F
    U -> C
    F -> C
{rank= same; C; F}
}
")

```

En este caso, el efecto de fumar ($F$) sobre cáncer ($C$) no es identificable
pues no podemos condicionar a la variable de Genotipo ($U$). Supongamos que
tenemos una medida adicional, que es la cantidad de depósitos de alquitrán
den los pulmones de los pacientes. Este es es afectado por $F$, y 
a su vez, el alquitrán incrementa la probabilidad de cáncer:

```{r}
#| code-fold: true
grViz("
digraph {
  graph [ranksep = 0.2]
  node [shape=plaintext]
    F
    C
    A
  node [shape = circle]
    U
  edge [minlen = 3]
    U -> F
    U -> C
    F -> A
    A -> C
{rank= same; C; F; A}
}
")

```

La idea es primero estimar el efecto de $F$ sobre $A$, y después
estimar el efecto de $A$ sobre $C$. La "composición" de estos dos
efectos, dado el diagrama, debe darnos el estimador correcto. 
Primero consideramos el efecto de $F$ sobre $A$, y tenemos que (regla 2)

$$p(a|do(f)) = p(a|f),$$
La igualdad se debe a que una vez que condicionamos a $F$ no hay
puertas traseras entre $F$ y $A$ (pues no condicionamos a $C$). Esta dependencia causal la podemos entonces estimar de los datos.

El efecto de $A$ sobre $C$ también es identificable, pues el camino no
causal se bloquea cuando condicionamos a $A$, de forma
que por la fórmula de ajuste:

$$p(c|do(a)) = \int p(c|a, f') p(f')\, df'$$


Ahora encadenamos estas dos ecuaciones: 

$$p(c|do(f)) = \int p(c|do(a))p(a|f)\,da$$

que equivale en simulación a: dado un valor de $F$, simulamos $A=a$ 
con nuestro modelo ajustado con datos naturales. 
Ahora intervenimos $A$ con el valor a que obtuvimos y simulamos $C$.
Sin embargo, para hacer este último paso con datos naturales, necesitamos usar
el criterio de puerta trasera como explicamos arriba: simulamos entonces $f´$ de $p(f)$, y después simulamos $C$ en función de
$a$ y $f´$ (con una distribución construida a partir de datos).

Requerimos en este caso construir y estimar la condicional
$p(c|a, f)$ basado en los datos.

En fórmula, en general, se escribe como:

::: callout-note 
# Criterio de fuerta delantera (Pearl)
Decimos que un conjunto de variables 
$A$ satisface el criterio de puerta delantera en relación
a las variables $F$ y $C$ cuando:

1. $A$ intercepta todos las cadenas dirigidos de $F$ a $C$
2. No hay ningún camino activo de puerta trasera de $F$ a $A$
3. Todos los caminos de puerta trasera de $A$ a $C$ están bloqueados
por $F$.


Si $A$ satisface el criterio de puerta delantera en relación
a $F$ y $C$, entonces el efecto causal de $F$ en $C$ es identificable
y está dado por la fórmula:

$$p(c|do(f)) = \int \left [ \int p(c|a,f´)p(f´)\,df´ \right ] p(a|f)\,da$$
:::

Todas estas cantidades puede estimarse de los datos. 

### Ejemplo: proceso generador {-}

Antes de aplicar este nuevo procedimiento, describamos 
el proceso generador que utilizaremos:


```{r}
# simular distribución natural
simular_fd <- function(n = 10, efecto_a = 0.3){
  ## causa común
  u <- rnorm(n, 0, 1);
  # cantidad que fuma
  f <- exp(rnorm(n, 1 + 0.2 * u, 0.1))
  # acumulación de alquitrán
  a <- rnorm(n,  4 * f, 2)
  # probabilidad de cancer
  p_c <- inv_logit(-6 + efecto_a * a +  2 * u)
  c <- rbinom(n, 1, p_c)
  tibble(f, a, c, u)
}
# simular datos intervenidos (suponiendo que conocemos todo)
sim_int_f <- function(n = 100, do_f = 0.3, efecto_a = 0.3){
  a <- rnorm(n,  4 * do_f, 2)
  u <- rnorm(n, 0, 1)
  p_c <-  inv_logit(-6 + efecto_a * a +  2 * u)
  c <- rbinom(n, 1, p_c)
  tibble(do_f = do_f, media_c = mean(c))
}
```


```{r}
set.seed(4481)
sims_fd <- simular_fd(5000)
sims_fd_1 <- simular_fd(10000)
qplot(sims_fd$f, sims_fd$a)
```
¿Cómo se ve la relación de fumador con cáncer? En esta gráfica
mostramos también el valor de la variable no observada $U$. Nótese
que parte de la correlación positiva que existe es debido a esta
variable $U$.

```{r}
ggplot(sims_fd, aes(x = f, y = c, colour = u)) + 
  geom_jitter() + scale_colour_continuous(type = "viridis")
```

Ahora veamos cómo se ve el efecto de $F$ sobre $C$ y
también cómo se ve el cruce de $F$ y $C$ en los datos naturales:

```{r}
sims_1 <- map_df(seq(1, 4, 0.5), ~ sim_int_f(100000, .x))

sims_1 |> 
  ggplot() + geom_line(aes(x = do_f, y = media_c)) +
  geom_smooth(data = sims_fd_1, aes(x = f, y = c), method = "loess", span = 0.3, se = FALSE, colour ="red") + xlab("Grado de tabaquismo") +
  xlim(c(1,4))
```

En efecto causal promedio de fumar, en cada nivel, sobre la incidencia de cáncer de pulmón, suponiendo nuestro proceso generador. Nótese que la relación no
es tan fuerte como observamos en los datos naturales (en rojo). 
Esto se debe a que en los
datos naturales, las personas existe una causa común entre no fumar
y prevenir cáncer de pulmón. 


### Ejemplo: estimación con puerta delantera {-}


Veamos cómo sería la estimación si tuviéramos datos disponible, y
si es que podemos recuperar el efecto correcto dados los datos observados y la técnica de puerta delantera.

Nótese que sólo necesitamos
$p(c|a, f), p(a|f)$ y $p(f)$. Estos son modelos estadísticos con el 
que podemos identificar el efecto que nos interesa. Una vez que los estimemos,
podemos usar simulación:

0. Fijamos una $f$.
1. Simulamos una $a$ del modelo $p(a|f)$
2. Para calcular $\int p(c|a,f')p(f')$, tenemos que simular un valor
$f'$ de la marginal de $p(f)$, y luego, sustituir junto la $a$ de 1 para
simular una $c$ de $p(c|a, f')$.
3. Consideramos solamente $c$ y $f$ para resumir el efecto.




```{r}
set.seed(481)
sims_fd <- simular_fd(2000)
mod_front_door <- cmdstan_model("../src/front-door-2.stan")
print(mod_front_door)
```

```{r}
do_f <- seq(1, 4, 0.1)
n_f <- length(do_f)
sims <- mod_front_door$sample(data = list(N = nrow(sims_fd),
      f = sims_fd$f, a = sims_fd$a,
      c = sims_fd$c, do_f = do_f, n_f = n_f),
  init = 0.01, step_size = 0.01, 
  refresh = 1000,
  parallel_chains = 4)
```


```{r}
#| warning: false
sims_efecto_tbl <- sims$draws("mean_c", format = "df") |> 
  pivot_longer(cols = contains("mean_c"), values_to = "media_c") |> 
  separate(name, c("nom", "id"), 
    sep = "[\\[\\]]", convert = TRUE, extra = "drop") |> 
  left_join(tibble(f = do_f) |> 
  mutate(id = seq_along(f))) 
resumen_tbl <- sims_efecto_tbl |> 
  group_by(id, f) |> 
  summarise(media = mean(media_c), 
    q5 = quantile(media_c, 0.05),
    q95 = quantile(media_c, 0.95))
```


```{r}
ggplot(resumen_tbl) + 
  geom_linerange(aes(x= f, ymax = q95, ymin = q5), colour = "red") + 
  geom_point(aes(x = f, y = media), colour = "red") +
  geom_line(data = sims_1, aes(x = do_f, y = media_c)) +
  xlab("Nivel de tabaquismo") + ylab("Prop afectada")
```

Y parece que hemos obtenido una estimación razonable del efecto
causal de fumar sobre cáncer. Recordemos también que debemos
ser cuidadosos al comparar intervalos que salen del mismo modelo
por su nivel de traslape.

Por ejemplo, si quisiéramos calcular contrastes con el nivel 2 de tabaquismo:

```{r}
efecto_2 <- sims_efecto_tbl |> filter(f == 2) |> 
  select(.draw, efecto_2 = media_c)
comp_tbl <- left_join(sims_efecto_tbl, efecto_2) |> 
  mutate(dif_2 = media_c - efecto_2)
comp_tbl |> group_by(f) |> 
  summarise(media = mean(dif_2), q5 = quantile(dif_2, 0.05),
            q95 = quantile(dif_2, 0.95)) |> 
ggplot() + geom_linerange(aes(x= f, ymax = q95, ymin = q5)) + geom_point(aes(x = f, y = media))  +
  xlab("Nivel de tabaquismo") + ylab("Prop afectada")
  
```

**Nota**: nótese como en este ejemplo hemos evitado
incluir en nuestro modelo la variable no observada $U$, gracias al procedimiento de puerta delantera descrito arriba.

Es posible sin embargo intentar un modelo completo bayesiano, sin necesidad de recordar la fórmula. El procedimiento,
que es más difícil de ajustar: considera una variable latente $U$ no observada, y es necesario definir cómo puede
ser su relación con sus descendientes. Es necesario más cuidado en definir 
formas funcionales e iniciales apropiadas para que los muestreadores funcionen apropiadamente.

## Mediación y datos de Berkeley

Cuando existen distintas rutas causales entre una variable
que intervenimos y un resultado, muchas veces es relevante intentar
separar los efectos directos del tratamiento de aquellos que están
mediados por otras variables.

En general, entender separar efectos directos o mediados requiere
más supuestos que entender efectos totales sobre todas las posibles rutas
causales.

### Ejemplo: Admisiones de Berkeley


En 1973 se recolectaron datos agregados de solicitantes para estudiar en Berkeley para
los 6 departamentos más grandes, clasificados por sexo del solicitante y
si fue admitido o no. Los resultados se muestran a continuación:

```{r}
data("UCBAdmissions")
adm_original <- UCBAdmissions |> as_tibble() |> 
   pivot_wider(names_from = Admit, values_from = n) 
adm_indiv <- UCBAdmissions |> as_tibble() |> 
  mutate(Gender = ifelse(Gender=="Female", 2, 1)) |> 
  mutate(Dept = factor(Dept) |> as.integer()) |> 
  mutate(Admit = ifelse(Admit == "Admitted", 1, 0)) |> 
  uncount(n)
adm_indiv |> head() 
```

Comenzaremos construyendo nuestro modelo causal: 

- Género es una causa con el departamento que seleccionan los aplicantes, en primer
lugar porque ya sea por educación o otras razones distintos géneros prefieren distintas
carreras
- Los departamentos también son una causa de aceptación de aplicantes. Algunos
departamentos tienen más aplicantes o menos capacidad, y los que deciden son diferentes personas.
- Consideramos que Género también puede ser una causa directa de admisión, y puede haber favoritismo por algún género.

Nuestro primer diagrama, *que criticaremos más adelante*, se ve cómo sigue:

```{r}
#| code-fold: true
grViz("
digraph {
  graph [ranksep = 0.2]
  node [shape=plaintext]
    G
    D
    A 
  #node [shape = circle]
  #  U
  edge [minlen = 3]
    G -> D
    G -> A
    D -> A
{rank = same; G;A}
}
")

```

Bajo estos supuestos, podemos calcular el efecto total de género en admisiones:
para esto es importante **no** condicionar a departamento. Nuestro modelo es
el siguiente:

```{r}
mod_1_berkeley <- cmdstan_model("../src/berkeley-1.stan")
print(mod_1_berkeley)
```

```{r}
#| warning: false
datos_lista <- list(N = nrow(adm_indiv), n_d = 6,
  admit = adm_indiv$Admit, gender = adm_indiv$Gender,
  dept = adm_indiv$Dept)
ajuste <- mod_1_berkeley$sample(data = datos_lista, 
          iter_warmup = 200, iter_sampling = 500,
          refresh = 1000, parallel_chains = 4)
resumen_mod <- ajuste$summary() |> select(variable, mean, q5, q95)
resumen_mod
```


```{r}
sims_contraste <- ajuste$draws("contraste_m_h", format = "df")
ggplot(sims_contraste, aes(x = contraste_m_h)) +
  geom_histogram()
```


Y nuestra conclusión aquí es que el efecto total de género sobre
admisión favorece a los hombres, y la diferencia es entre 20 y 8 puntos
porcentuales aproximadamente.

Sin embargo, en este ejemplo vale la pena entender que estamos
estimando el efecto de dos caminos causales (ver McElreath, Statistical Rethinking):

- Posible discriminación directa general porque una aplicación está identificada como "mujer". Este es un efecto directo, lo que más propiamente llamaríamos discriminación de personas.
- Posible discriminación estructural por las carreras que escogen las personas. En este caso, quizá por ejemplo los departamentos de ingeniería son más fáciles de acceder, pero tradicionalmente 
no se alienta a las mujeres escoger ese tipo de carreras. Este efecto está mediado por la selección de departamento.
- El efecto total es el que experimentan las personas, por cualquiera
de las dos razones de arriba.


Cada una de estas razones son muy diferentes y llevan a distintas conclusiones
acerca de los datos. Veremos ahora cómo, bajo el modelo que tenemos ahora,
podemos intentar estimar el efecto directo de discriminación. En este
caso, *necesitamos bloquear la variable departamento*, para ver sólo el efecto
directo, y esto lo logramos estratificando por departamento.

Calcularemos ahora $p(a | do(g = 1, d = d))$ para cada departamento. 
El modelo no cambia, pero simulamos diferente:

```{r}
mod_2_berkeley <- cmdstan_model("../src/berkeley-2.stan")
```

```{r}
datos_lista <- list(N = nrow(adm_indiv), n_d = 6,
  admit = adm_indiv$Admit, gender = adm_indiv$Gender,
  dept = adm_indiv$Dept)
ajuste <- mod_2_berkeley$sample(data = datos_lista, 
          iter_warmup = 200, iter_sampling = 500,
          refresh = 1000, parallel_chains = 4)
resumen_mod <- ajuste$summary() |> select(variable, mean, q5, q95)
resumen_mod
```

```{r}
sims_contraste <- ajuste$draws("contraste_m_h", format = "df") |> 
  pivot_longer(cols = contains("contraste")) |> 
  separate(name, into = c("nombre", "dept"), sep = "[\\[\\]]", extra = "drop")
ggplot(sims_contraste, aes(x = value, fill = dept)) +
  geom_density(alpha = 0.5)
```

Donde vemos que los departamentos varían en la diferencia de aceptación
de hombres y mujeres. 

El efecto directo (en este caso se llama *efecto directo controlado*) 
no es conclusivo, aunque parece favorecer ligeramente a mujeres.

En algún momento de la discusión, este argumento fue mostrado para
decir que no había discriminación en Berkeley específicamente orientado hacia las mujeres, aún cuando quedaba por investigar por qué el contraste de tasas de aceptación es tan diferente en cada departamento (puede haber muchas razones). Sin embargo, otros investigadores apuntaron al hecho de que la selección de departamentos y la tasa de aceptación puede tener una causa común: por ejemplo, la habilidad general.

```{r}
#| code-fold: true
grViz("
digraph {
  graph [ranksep = 0.2]
  node [shape=plaintext]
    G
    D
    A 
  node [shape = circle]
    U
  edge [minlen = 3]
    G -> D
    G -> A
    D -> A
    U -> D
    U -> A
{rank = same; G;A}
{rank = same; U}
}
")

```

::: callout-tip
# Mediación con variables confusoras

Si existen variables confusoras entre la variable $D$ que media el efecto
de otra variable y el resultado $A$, $D$ se convierte en un colisionador.
Cuando condicionamos a $D$ para estimar el efecto directo (que es un **colisionador**), activamos
una ruta no causal entre $G$ y $A$ que va a través de $U$. En este caso,
el efecto directo no está identificado.

:::

Aunque podemos calcular el efecto total de género sobre admisión, no
es posible extraer en este caso el efecto directo. Por ejemplo (McElreath), una hipótesis que se ha planteado es la siguiente:

- Supongamos que existen departamentos que se sabe que discriminan o 
tienen prácticas discriminatorias. Las personas que aplican a esos departamentos que son suceptibles a esta discriminación tienden a ser personas de mayor habilidad que el aplicante típico, pues sólo en ese caso están dispuestas
a sufrir tal discriminación. Esto implica que también su tasa de aceptación
sin discriminación sería más alta por su mayor habilidad, pero en los datos no lo vemos. 
En este caso, puede haber discriminación directa que acaba enmascarada por esa autoselección.

En este caso no tenemos la variable de habilidad, pero podríamos
hacer análisis de sensibilidad. En el siguiente modelo, consideramos
*hipotéticamente* qué pasaría si en el departamento 2 tuviera la imagen (justificada o no)
de ser un ambiente discriminatorio:


```{r}
mod_3_berkeley <- cmdstan_model("../src/berkeley-3.stan")
print(mod_3_berkeley)
```
::: callout-tip
# Variables latentes

En este modelo, $u$ es una variable a nivel individuo. 
No conocemos su valor pero
influye en $D$ y $A$ directamente. Si sabemos algo de la naturaleza de 
esta influencia, es posible extraer informacion acerca de los valores $u$
de cada individuo.

Desde el punto de vista bayesiano, los valores que toma esta variable
son parámetros a estimar.

:::

Por ejemplo, si una mujer es aceptada a un departamento que 
aparenta actividades descriminatorias, por las razones explicadas
arriba podemos deducir que su nivel de habilidad es en general
mayor que el aplicantes hombres, y eso puede explicar por qué
aún cuando las tasas de aceptación el departamento sean similares,
existe una componente de discriminación.

En este ejercicio haremos un análisis de sensibilidad de nuestras
hipótesis. Supondremos que los niveles de habilidad en general
ayudan a entrar en cualquier departamento, pero que la probabilidad
de que una mujer aplique a un departamento discriminatorio sólo
es alta si su nivel de habilidad es alto (ver los variables 
delta y eta en el siguiente modelo):



```{r}
#| warning: false
datos_lista <- list(N = nrow(adm_indiv), n_d = 6,
  admit = adm_indiv$Admit, gender = adm_indiv$Gender,
  dept = adm_indiv$Dept)
## incluimos coeficientes fijos para la relación de habilidad
## con selección de departamente y adimisión
datos_lista <- c(datos_lista,
  #habilidad ayuda en todos los departamentos
  list(delta = c(1, 1),
  #pero los de habilidad alta intentan a aplicar al departamento 2.
  eta = matrix(c(c(0, 0, 0, 0, 0, 0), c(0, 0, 0, 0, 2, 0)), nrow= 2, byrow = T))
)
ajuste_disc <- mod_3_berkeley$sample(data = datos_lista, 
          iter_warmup = 300, iter_sampling = 1000,
          refresh = 1000, parallel_chains = 4)
resumen_disc_mod <- ajuste_disc$summary() |> select(variable, mean, q5, q95)
resumen_disc_mod
```


```{r}
sims_contraste_disc <- ajuste_disc$draws("contraste_m_h", format = "df") |> 
  pivot_longer(cols = contains("contraste")) |> 
  separate(name, into = c("nombre", "dept"), sep = "[\\[\\]]", extra = "drop")

sims_2 <- sims_contraste_disc |> mutate(tipo = "Con habilidad (hipotético)") |> 
  bind_rows(sims_contraste |> mutate(tipo = "Ingorando habilidad"))

ggplot(sims_2, aes(x = value, fill = dept)) +
  geom_density(alpha = 0.5) + facet_wrap(~ tipo, ncol = 1)
```

Notamos que los resultados para el "departamento discriminatorio"
efectivamente indica un efecto directo más grande que favorece a hombres.
Nótese como en este ejemplo el efecto de selección de departamento
para mujeres es relativamente fuerte (alta habilidad
tiende a ir a departamento 5), los efectos para el resto de los departamentos
son contrarios: algunos se mueven a la derecha, es decir, parece haber
má ventaja para mujeres. Esto es porque el departamento 5 absorbe desproporcionadamente a mujeres de habilidad alta, lo que implica q
ue la habilidad promedio de mujeres en otros departamentos es más baja 
que la de los hombres.


::: callout-note
# Análisis de sensibilidad

Si existe la posibilidad de variables confusoras, podemos hacer
ejericicios de modelación/simulación para estimar qué tan fuertes
tendría que ser la relación de la variable confusora para producir
resultados que cambien nuestras conclusiones.

:::


### Ejemplo (Burks, Pearl) {-}

Este ejemplo es mencionado por Pearl en The Book of Why. 
En 1926 Burks recolectó datos sobre qué tanto podría esperarse
que la inteligencia de padres se hereda a los hijos (medido según
una prueba de IQ). Construyó un diagrama parecido al de abajo:

```{r}
#| code-fold: true
grViz("
digraph {
  graph [ranksep = 0.2]
  node [shape = circle]
    U
  node [shape=plaintext]
  edge [minlen = 3]
    IntPadres -> NSE
    NSE -> IntHijos
    U -> NSE
    U -> IntHijos
    IntPadres -> IntHijos
{rank = same; U}
}
")

```

Como el NSE es del hogar (una medida general de estatus social), 
se consideró en principio como una variable pre-tratamiento a la inteligencia
de los niños por la
que tradicionalmente se controlaba. Burks notó que hacer esto tenía como
consecuencia cortar parte del efecto total de la inteligencia 
sobre el la inteligencia de los hijos. Adicionalmente, condicionar
a NSE abre un camino no causal entre Inteligencia de Padres e Hijos.

## Controles buenos y malos

En los análisis anteriores muchas veces buscamos construir modelos estadísticos
$p(y|t, z)$, donde $z$ son variables por las que controlamos (o estratificamos)
para obtener el efecto causal de $t$ sobre $y$ (es decir, estimar $p(y|t, z)$).

Arriba mostramos (criterio de puerta trasera) que las variables $z$ deben
bloquear puertas traseras al tratamiento, no bloquear efectos causales de $t$,
y no activar caminos no causales.

En @Pearl2022gb, Pearl et al. [A Crash Course in Good and Bad Controls](https://ftp.cs.ucla.edu/pub/stat_ser/r493.pdf) muestran
diversos ejemplos de buenos y malos
controles (variables para incluir en $z$). Estas ideas aplican tanto a 
datos observacionales como experimentales.















