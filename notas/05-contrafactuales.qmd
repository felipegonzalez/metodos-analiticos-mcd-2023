# Contrafactuales

El punto de vista de contrafactuales (o resultados potenciales), también
llamado enfoque de Neyman-Rubin comienza abordando el problema de inferencia
causal desde el punto de vista a nivel individual, en lugar de poblacional.

Recordemos que anteriormente consideramos calcular cantidades como $E(y|do(x))$. Este
es un valor promedio sobre la población de interés. Ahora consideraremos unidades
individuales que hemos observado. Podríamos preguntarnos, por ejemplo, dado que
la persona $i$ recibió el tratamiento, y respondió con resultado $y_i$, ¿qué hubiera
pasado con esta persona si no la hubiéramos tratado? Esta es una pregunta distinta,
pues tenemos información acerca del resultado de esta persona bajo condiciones del
tratamiento y depende de características específicas de esa
persona. 

Aunque seguiremos utilizando DAGs para expresar, transparentar y comunicar nuestros
supuestos causales, el concepto de contrafactuales va más allá del cálculo-do.


## Efectos causales a nivel individuo.

Supongamos que nos interesa una respuesta $Y$ a un tratamiento $T$. Por 
simplicidad, empezamos considerando que $T$ puede tomar los valores 0 o 1.

En el 
modelo causal de Rubin, consideramos, para cada individuo de la población
de interés, las dos cantidades: 

$$y_{i}^1, y_{i}^0,$$
que se definen la siguiente manera: Si $y_i$ es la respuesta observada para una unidad,
entonces: 

- $y_i = y_{i}^1$ cuando $t_i=1$, es decir, la unidad recibió el tratamiento, o
- $y_i = y_{i}^0$ cuando $t_i=0$, la unidad no recibió el tratamiento.

Podemos escribir también como

$$y_i = y_{i}^1 t_i + y_{i}^0 (1 - t_i)$$
El primer avance, entonces, es establecer que para cada unidad hay dos posibles
*resultados potenciales*, pero nosotros solamente observamos uno: $y_i$. Esta notación
más específica nos permite definir:

::: callout-note
# Contrafactuales

- Cuando observamos $y_i=y_i^1$, decimos que su observación contrafactual
es $y_i^0$, es decir, qué hubiéramos observado si esta unidad no hubiera
recibido el tratamiento.
- Cuando observamos $y_i=y_i^0$, decimos que su observación contrafactual
es $Y_i^1$, es decir, qué hubiéramos observado si esta unidad  hubiera
recibido el tratamiento.
- En algunos casos, escribiremos como $y_i^{obs}$ la respuesta observada,
y como $y_i^{mis}$ el contrafactual. Para cada unidad siempre hay una respuesta 
faltante.

:::

**Nota**: En general, podemos definir $y_i^t = y_i(t)$ como el contrafactual
para la unidad $i$ cuando recibe el tratamiento $T=t$.

### Ejemplo {-}

Supongamos que nos interesa el tratamiento de tomar aspirina, y queremos
ver su efecto en dolor de cabeza. En este caso tenemos un experimento
donde el tratamiento se asignó al azar. Consideramos la intensidad del dolor
(inicial y final) en una escala continua, con el dolor inicial estandarizado.-

Entonces podríamos ver algo como lo que sigue:

```{r}
#| warning: false
#| message: false
library(tidyverse)
library(DiagrammeR)
library(kableExtra)
```


```{r}
mecanismo_aspirina <- function(dat_tbl){
    # esta función contiene el mecanismo de funcionamiento
    # del tratamiento, en términos probabilísticos
    res_tbl <- dat_tbl |>  
      mutate(u = rnorm(n, 0, 1)) |> 
      mutate(Y_1 = 0.8 * intensidad - 0.5 + 0.5 * u) |> 
      mutate(Y_0 = 0.8 * intensidad + 2 * u) |> 
      mutate(Y = ifelse(T, Y_1, Y_0))  |> 
      mutate(across(where(is.numeric), ~ round(.x, 3))) |> 
      select(T, Y, Y_1, Y_0, everything())
    res_tbl
}
```



```{r}
n <- 1200
set.seed(13233)
ejemplo_1 <- tibble(.rows = n) |>  
    mutate(intensidad = rnorm(n, 0, 1)) |> 
    mutate(T = rbernoulli(n, 0.5)) 
resultados_1 <- ejemplo_1 |> 
  mecanismo_aspirina() 
obs_1 <- resultados_1 |> 
  mutate(Y_1 = ifelse(T, Y_1, NA)) |> 
  mutate(Y_0 = ifelse(T, NA, Y_0)) |> 
  select(T, intensidad, Y, Y_1, Y_0)
obs_1 |> head() |> knitr::kable() |> kableExtra::kable_paper()
```
Nótese que nunca observamos al mismo tiempo $y_i^1$ y $y_i^0$. 
Nuestros resultados completos se verían como:

```{r}
resultados_1 |> 
  select(T, intensidad, Y_1, Y_0) |> 
  mutate(efecto_causal_ind = (Y_1 - Y_0)) |> 
  head()
```

Podemos definir el efecto causal a nivel unidad de la siguiente forma, aunque
esto no nos dice directamente cómo calcularlo con los datos observados:


```{r}
resultados_1 |> 
  mutate(efecto_causal_ind = Y_1 - Y_0) |> 
  summarise(ATE = mean(efecto_causal_ind), 
            ee = sd(efecto_causal_ind)/sqrt(n()))
```


::: callout-note
# Efectos causales a nivel de unidad

Definimos el efecto del tratamiento $T$ sobre el individuo $i$ como la cantidad:

$$\delta_i = y_{i}^1 - y_{i}^0,$$
Aunque también podríamos definirlo como cambio porcentual, o cociente, por ejemplo

:::

Bajo este esquema, cantidades como el efecto promedio
sobre la población pueden calcularse. Promediando sobre la población,
escribiríamos

$$\delta = \frac{1}{N}\sum_i \delta_i = \frac{1}{N}\sum_i y_{i}^1 - \frac{1}{N}\sum_i y_{i}^0$$
que también podemos escribir, si $Y,  Y_{}^1,  Y_{}^0$ indican los valores correspondientes
a una persona tomada al azar de la población, como

$$\delta = E[Y^1] - E[Y^0]$$
En términos de nuestra notación de la sección anterior, esto es lo mismo que

$$\delta = E[Y|do(T=1)] - E[Y|do(T=0)].$$
y estos valores esperados son bajo la distribución $p(y|do(t))$. Nótese sin embargo,
que en cálculo-do siempre tratamos con las distribuciones poblacionales, y 
el enfoque de contrafactuales nos permite conectarlos con *efectos individuales*.

Para que las definiciones de arriba tengan sentido y podamos
trabajar con ellas de manera relativamente simple, es
necesario hacer algunos supuestos. Los primeros se denominan *SUTVA*,
o Stable Unit Treatment Value Assumption), ver (@rubin2005):


::: callout-note
# SUTVA 

El supuesto de valores estables de tratamientos de las unidades consiste en:

- Los resultados potenciales $y_{i}^1, y_{i}^0$ no son afectados por el tratamiento
que recibe la unidad, o ninguna otra unidad. 
- Los resultados potenciales $y_{i}^1, y_{i}^0$ no dependen de cómo se asignó el tratamiento.

:::

En otro caso, es difícil establecer qué significado tienen los contrafactuales.
Este supuesto muchas veces es apropiado, excepto cuando hay interacciones importantes
entre las unidades. Por ejemplo: Un cambio en una plataforma para 
compartir documentos para una unidad A puede tener
efectos en las $Y$'s correspondientes a unidades que comparten documentos con A. Otro
ejemplo es si consideramos una enfermedad contagiosa: la intervención sobre una unidad
puede tener efecto sobre los resultados potenciales de otra persona cercana.
En esos casos, es necesario considerar distintos tipos de unidades (por ejempo, intervenciones
a nivel red de contactos, escuelas, etc.), o utilizar modelos más complejos.


Con estos conceptos, Rubin (@rubin2005) 
llama al modelo $p(x, y^1, y^0)$ el modelo "científico" (este modelo
es construido por conocimiento experto) 
mientras que el modelo de asignación es $p(t|x, y^0, y^1)$, separando claramente
la "ciencia" del mecanismo de asignación del tratamiento, que puede ser un
experimento aleatorio, una asignación basada en políticas, autoselección de las personas,
etc. 

- Nótese que en general, la asignación del tratamiento puede depender de los dos
valores potenciales (por ejemplo, las personas que deciden tomar algún tratamiento
son justamente aquellas para las que $Y^0$ es similar a $Y_1$).

Igual que en el marco de modelos causales estructurales (DAGs),
 es necesario hacer supuestos considerables acerca de estos dos modelos.

En cuanto al proceso de asignación del tratamiento, Rubin introduce el concepto de
ignorabilidad: 

::: callout-note
# Ingorabilidad

Si $P(t|x, y^0, y^1) = P(t|x)$, es decir, los resultados no influyen en la asignación
de tratamiento dadas las covariables $x$, decimos que el mecanismo de asignación
es **ignorable**. 

En este caso, es posible simular contrafactuales usando
la distribución $P(y^{mis}| x, y^{obs})$ que se deduce del modelo "científico" bajo
ignorabilidad.
:::

### Ejemplo simple (Rubin) {-}

En nuestro ejemplo de aspirinas, consideramos por ejemplo que $x$ es la intensidad
del dolor inicial. Establecemos el modelo "científico":
$$y^0_i = \alpha_0 + \alpha x+ \sigma_1 u_i^0$$
y 
$$y^1_i = \alpha_0 + \alpha x + \beta + \sigma_2 u_i^1$$
Y podríamos suponer que $(u_i^0, u_i^1)$ tienen una distribución normal bivariada estándar
con media en 0. Aunque podemos estimar las varianzas, no es posible estimar la 
correlación, y tendríamos
que ponerla en algún valor consistente con el conocimiento experto (por ejemplo,
los casos extremos son $\rho = 1$ o $\rho = 0$). Supondremos en este ejemplo
que $\rho = 1$ (ver @imbens_rubin_2015 por ejemplo para más casos).

Como el tratamiento es ignorable (este es un experimento), entonces para simular $y_i^{mis}$ hacemos los siguiente:

- Denotamos por $\theta$ a los parámetros $\alpha_0,\alpha, \beta,\sigma_1,\sigma_2,\rho$.
- Obtenemos la posterior de los parámetros $\theta$ dada los datos $(x_i, y_i^{obs}, t_i)$.
- Simulamos un conjunto de parámetros $\theta$ de esta posterior.
- Con parámetros fijos, simulamos la observación contrafactual.
- Calculamos el resumen de interés a partir de la diferencia de observado y contrafactual.

Y ahora, con todos los pares posibles de observación y contrafactual, calculamos el
resumen del efecto causal que nos interese (por ejemplo, media de la diferencia).

```{r}
library(cmdstanr)
mod_aspirina <- cmdstan_model("../src/contrafactual-simple.stan")
print(mod_aspirina)
```

```{r}
ajuste <- mod_aspirina$sample(data = list(N = nrow(obs_1), 
  t = as.numeric(obs_1$T),
  intensidad = obs_1$intensidad, y_obs = obs_1$Y), 
  init = 0.1, step_size = 0.1, refresh = 1000)
```

```{r}
ajuste$summary(c("sigma", "alpha_0", "alpha", "beta", "efecto_trata"))
```



::: callout-note
# Modelos e Ignorabilidad

- La ignorabilidad de asignación del tratamiento es un supuesto complejo. Las DAGs 
ayudan en el sentido de que transparentan las razones por las que asumimos ignorabilidad
(por ejemplo, el criterio de puerta trasera).
- La construcción del modelo que Rubin llama "ciencia" puede ser asistido y
quizá más claramente explicado con DAGs.

:::


## Asignación no ignorable

El concepto de contrafactual también nos permite entender por otro camino por
qué la comparación simple de grupos no resulta necesariamente en efectos causales.

Supongamos primero que el tratamiento se asignó al azar. Si este
es el caso, nótese que entonces

$$
\begin{align} 
\delta_{ing} & =  E[Y|T=1] - E[Y|T=0] \\
& = E[Y^1|T=1] - E[Y^0|T=0] \\
& = E[Y^1] - E[Y^0] = ATE = \delta
\end{align}
$$
pues por definición $T$ es independiente de $Y, Y^1, Y_0$ (ignorabilidad). El lado izquierdo
lo podemos estimar como es usual:

$$\delta_{ing} = \frac{1}{n_1} \sum_{t_i = 1} y_i - \frac{1}{n_0} \sum_{t_i = 0} y_i$$

que llamamos **el estimador ingenuo** del efecto causal $\delta$. Esto ya lo sabíamos
del cálculo-$do$, pues la independencia de $T$ y $Y,Y_1,Y_0$ puede deducirse
del hecho de que no hay puertas traseras activas al tratamiento $T$ con la respuesta $Y$, pues $T$ no depende de ninguna otra variable de nuestra gráfica.

Si embargo, en general **la ecuación de arriba no necesariamente se cumple cuando
el tratamiento no se asigna al azar**. En este caso podemos por ejemplo escribir:


$$\delta_{ing} =  (E[Y^1|Y=1] - E[Y^0|Y=1]) + (E[Y^0|T=1] - E[Y^0|T=0]) $$
$$\delta_{ing} =  ATT + (E[Y^0|T=1] - E[Y^0|T=0]) $$


- **ATT**: el primer término es el efecto causal del tratamiento sobre los tratados (ATT). 
- **Sesgo de selección**: el segundo término compara el grupo de tratados con el de no tratados
*en ausencia de ningún tratamiento*. Esto quiere decir que si los grupos muy diferentes,
el estimador ingenuo puede depender más de cómo son diferentes los grupos de tratados
que los de los no tratados que del efecto casual del tratamiento.
- Nótese que sin más supuestos, ninguna de las dos cantidades de la derecha pueden calcularse
directamente, pues dependen de situaciones contrafactuales.

Por ejemplo, podríamos comparar las personas que beben alcohol moderadamente 
(tratamiento) con
aquellos que no beben alcohol. Quizá observamos que la salud de los
que beben alcohol moderadamente es mejor que los que no beben alcohol. Sin embargo,
no podemos concluir que beber alcohol moderadamente ayuda en la salud. La razón
puede estar en que las personas que padecen enfermedades de distintos tipos
evitan el alcohol, y en ese caso el término de la derecha 
$E[Y^0|T=1] - E[Y^0|Y=0]$ fuera muy grande, lo cual haría nuestro estimador 
ingenuo $\delta_{ing}$ podría ser muy grande, aún cuando $E[Y^1|Y=1] - E[Y^0|Y=1]$ fuera cercano a cero
si $Y=1$ es beber moderadamente.

**Ejercicio**: describe esta situación mediante un DAG.

Igualmente, podemos escribir

$$\delta_{ing} =  (E[Y^1|T=0] - E[Y^0|T=0]) + (E[Y^1|T=1] - E[Y^1|T=0])  $$
$$\delta_{ing} =  ATU + (E[Y^1|T=1] - E[Y^1|T=0])  $$


- **ATU**: el primer término es el efecto causal del tratamiento sobre los no tratados. 
- **Sesgo de selección**: el segundo término compara el grupo de tratados con el de no tratados
*con tratamiento*. Esto quiere decir que si los grupos muy diferentes,
el estimador ingenuo puede depender más de cómo son responden de manera diferente 
los grupos de tratados que los de los no tratados que del efecto casual del tratamiento.

Combinando estas dos, si $\pi$ es la proporción de tratados,

$$
\begin{align*}
\delta_{ing} & = ATE \\
 & + \pi (E[Y^0|T=1] - E[Y^0|T=0])\\
 & + (1-\pi)(E[Y^1|T=1] - E[Y^1|T=0]) 
\end{align*}
$$

Que podemos reescribir como

$$
\begin{align*}
\delta_{ing} & = ATE \\
 & +  (E[Y^0|T=1] - E[Y^0|T=0])\\
 & + (1-\pi)(E[Y^1 -Y^0|T=1] - E[Y^1-Y^0|T=0]) 
\end{align*}
$$

Y el estimador ingenuo es diferente del efecto causal promedio (ATE) por:

- Sesgo base: las unidades tratadas comienzan peor o mejor que las no tratadas
- Sesgo de tratamiento diferencial: las unidades que se seleccionan para ser tratadas
son más o menos propensas a tener mejoras o desmejoras.


Por ejemplo, supongamos que estamos comparando el efecto de la educación
en la abilidad mental de personas adultas, y el tratamiento es ir a la universidad.
Entonces, si comparamos habilidad mental de personas que van a la universidad
vs los que no van a la universidad, tenemos dos posibles fuentes de confusión:

- Para empezar, los que van a la universidad tenían más habilidad que los
que no fueron (efecto base)
- En segundo lugar, aquellos que tienen más habilidad se benefician más con
la educación universitaria que aquellos que no (efecto diferencial de tratamiento).
- En este caso, la comparación ingenua estimaría considerablemente el efecto promedio del
tratamiento.

Desde le punto de
vista del DAG, este sesgo aparece pues no hemos bloqueado una puerta
trasera $HabilidadFinal \gets HabilidadInicial \to Universidad$. 
Una vez que estratificamos por
Habilidad Inicial, este sesgo desaparece.


Una ventaja de esta aproximación de contrafactuales es que términos como
$ATT$ son fácilmente accesibles. Esta última cantidad, sin embargo, no podemos 
definirla exclusivamente desde el punto de vista 
el cálculo-do, pues tenemos que considerar cuál es el efecto del tratamiento de universidad
sólo para aquellos que naturalmente hubieran asistido a la universidad. 


## Mediacion con contrafactuales

Usando el concepto de contrafactuales es posible hacer una mejor definición
de efectos directos e indirectos (@pearl2016causal). Consideramos el diagrama:

```{r}
#| code-fold: true
grViz("
digraph {
  graph [ranksep = 0.2, rankdir = LR]
  node [shape=circle]
  node [shape=plaintext]
  

  edge [minlen = 3]
  T -> Y
  T -> M
  M -> Y
#{ rank = same; A; D }
}
", width = 200, height = 50)
```

En primer lugar tenemos los primeros dos conceptos que revisamos en el ejemplo
de admisiones de Berkeley:

1. El **efecto total**,

$$ATE= E[Y^1 - Y^0] = E[Y|do(T=1)] - E[Y|do(T=0)] $$

2. El **efecto total controlado**

$$CDE(m) = E[Y|do(T=1, M=m)] - E[Y|do(T=0, M=m)]$$
que vimos en el ejemplo de Berkeley de la sección anterior. Depende de en qué fijamos
el valor de $M$, sin fijarnos en el valor que toma $T$.

3. El **efecto natural directo**:

$$NDE = E[Y^{1,M_0} - Y^{0,M_0}]$$
En este caso, $Y^{1,M_0}$ quiere decir: qué valor tomaría $Y$ si $T=1$, 
y tomamos la distibución de $M_0$ como si $T=0$.

Esta cantidad mide el incremento en $Y$ cuando cambiamos el tratamiento de 0 a 1, 
mientras que la variable medidadora toma el valor que hubiera tomado antes del cambio
(es decir, bajo $T=0$). Por ejemplo: vemos el estado de aceptación de una mujer, dado
que selecciona departamento como si fuera un hombre y contrastamos el estado de aceptación
de un hombre como normalmente selecciona departamento. De esta manera bloqueamos
el efecto del tratamiento en la selección de departamento.

4. El **efecto natural indirecto** :

$$NIE = E[Y^{0,M_1} - Y^{0,M_0} ]$$
En este caso, mantenemos $T=0$, pero observamos qué pasaría si $M$ se escoge
 bajo $T=1$ o bajo $T=0$. Captura la porción del efecto que se explica sólo por la
mediación (quitando la capacidad de que $T$ afecte a $Y$). En términos del ejemplo
de Berkeley, fijamos $t=0$ (hombre), y comparamos que pasaría si seleccionara
departamento como una mujer vs. como normalmente lo haría.


### Caso donde no hay variables confusoras

En el caso donde no hay variables confusoras (ver el diagrama de arriba), 
el efecto natural directo está identificado por:

$$NDE = \int (E[Y|T=1, M = m]- E[Y|T=0, M = m] )p(m|t=0)dm $$
Cada integral la podemos estimar simulando y promediando. Por ejemplo,
para la primer integral, simulamos $M=m$ dado que $T=0$, y luego simulamos $Y$ dado
$T=1$ y $M=m$ con la $m$ que obtuvimos en le paso anterior. Igualmente para
la segunda integral.

El efecto indirecto es:

$$NIE = \int E[y|T=0, M = m]p(m|t=1)dm - \int E[y|T=0, M = m]p(m|t=0)dm$$
Que igualmente podemos calcular simulando. 


::: callout-tip
Excepto para modelos lineales sin interacciones,
no es cierto que la suma del efecto directo más el indirecto es el efecto total.
:::

Esto se debe a interacciones que puede haber entre el tratamiento y la variable 
mediadora. Tomando un caso extremo, podemos pensar en una medicina que tienen un efecto total
positivo sobre algún resultado. Existe una variable mediadora (por ejemplo, baja
el colesterol). Sin embargo, si el colesterol no es bajo,
otros efectos de la medicina no pueden darse, de modo que $Y^{1, M_0} = Y^{0, M_0}$ 
(el efecto natural directo es 0). Por otra parte, el efecto de sólo bajar el
colesterol (sin tomar la medicina) no tiene un efecto considerable 
$Y^{0,M_1} \approx Y^{0,M_0}$. 


En el caso lineal es más simple:  si $M = a+bT$ y $Y = c + dM + eT$, entonces
el efecto natural directo es $NDE = (c+ da + e) - (c + da) = e$ el efecto natural indirecto
es $NIE = (c + d(a+b)) - (c + da) = bd$, y el efecto total es $ATE = (c+ d(a+b) + e) - (c + da) = bd +e$.





### Ejemplo {-}

Este ejemplo es de @pearl2016causal. 
Un tratamiento impulsa a alumnos a hacer la tarea, y queremos calcular el efecto
del tratamiento en la probabilidad de aprobar el curso. También nos interesa si es
que el aumento en la tarea es la razón de este efecto, 
independientemente del programa de entrenamiento.

Las distribuciones observadas son

_
```{r}
tabla_1 <- tibble(t = c(1, 1, 0, 0), tarea = c(1, 0, 1, 0), prob_exito = c(0.80, 0.40, 0.30, 0.20))
tabla_1
```

Y tenemos para el nodo de tarea, el tratamiento incrementa la probabilidad de hacer tarea considerablemente:

```{r}
tabla_2 <- tibble(t = c(0, 1), prob_tarea = c(0.4, 0.75))
tabla_2
```

Aunque es posible hacer todos los cálculos de manera analítica, en este
ejemplo calcularemos con simulación. El efecto total es

```{r}
sim_total <- function(n =100000){
  # tratados
  sim_tarea <- rbinom(n, 1, 0.75)
  sim_exito_trata <- rbinom(n, 1, 0.8*sim_tarea + 0.4*(1-sim_tarea))
  # no tratados
  sim_tarea <- rbinom(n, 1, 0.4)
  sim_exito_sin_trata <- rbinom(n, 1, 0.3*sim_tarea + 0.2*(1-sim_tarea))
  # contraste
  mean(sim_exito_trata - sim_exito_sin_trata)
}
ate <- sim_total()
ate
```


El efecto natural directo es 

```{r}
sim_nde <- function(n =100000){
  # simulamos tarea sin tratamiento
  sim_tarea <- rbinom(n, 1, 0.4)
  # simulamos éxito con tarea anterior, suponiendo tratamiento
  sim_exito_trata <- rbinom(n, 1, 0.8*sim_tarea + 0.4*(1-sim_tarea))
  # simulamos éxito con tarea anterior, sin tratamiento
  sim_exito_sin_trata <- rbinom(n, 1, 0.3*sim_tarea + 0.2*(1-sim_tarea))
  parte_1 <- mean(sim_exito_trata)
  parte_2 <- mean(sim_exito_sin_trata)
  parte_1 - parte_2
}
nde <- sim_nde()
nde
```
Y el efecto natural indirecto es:

```{r}
sim_nie <- function(n =100000){
  # simulamos tarea con tratamiento
  sim_tarea <- rbinom(n, 1, 0.75)
  # simulamos éxito sin tratamiento
  sim_exito_sin_trata <- rbinom(n, 1, 0.3*sim_tarea + 0.2*(1-sim_tarea))
  parte_1 <- mean(sim_exito_sin_trata)
  
  # simulamos tarea sin tratamiento
  sim_tarea<- rbinom(n, 1, 0.4)
  # simulamos éxito sin tratamiento
  sim_exito_sin_trata <- rbinom(n, 1, 0.3*sim_tarea + 0.2*(1-sim_tarea))
  parte_2 <- mean(sim_exito_sin_trata)
  # calculamos la diferencia entre las dos medias
  parte_1 - parte_2
}
nie <- sim_nie()
nie
```

Tenemos:

```{r}
ate
1 - nde/ate
nie/ate
```

- El programa incrementa en 46 puntos porcentuales la tasa de éxito
- 30% de este incremento se debe a la capacidad del programa de estimular esfuerzos
en la tarea.
- Pero sólo 8% de este incremento se puede explicar por un incremento en tareas por sí
solas sin el beneficio del programa.

Nuestra conclusión es que incidir solamente en la variable $Tarea$, quizá de una
manera más barata, y a niveles similares a los de este programa, no tendría un
resultado cercano en efectividad.


### Ejemplo (Admisiones de Berkeley)

En el ejemplo Berkeley, suponiendo siguiente diagrama, calcularemos los efectos naturales
directos e indirectos:

```{r}
#| code-fold: true
grViz("
digraph {
  graph [ranksep = 0.2]
  node [shape=plaintext]
    G
    D
    A 
  #node [shape = circle]
  #  U
  edge [minlen = 3]
    G -> D
    G -> A
    D -> A
{rank = same; G;A}
}
")

```

```{r}
data("UCBAdmissions")
adm_original <- UCBAdmissions |> as_tibble() |> 
   pivot_wider(names_from = Admit, values_from = n) 
adm_indiv <- UCBAdmissions |> as_tibble() |> 
  mutate(Gender = ifelse(Gender=="Female", 2, 1)) |> 
  mutate(Dept = factor(Dept) |> as.integer()) |> 
  mutate(Admit = ifelse(Admit == "Admitted", 1, 0)) |> 
  uncount(n) |> filter(Dept < 5)
adm_indiv |> head() 
```

```{r}
mod_efectos_berkeley <- cmdstan_model("../src/berkeley-efectos-naturales.stan")
print(mod_efectos_berkeley)
```

```{r}
#| warning: false
datos_lista <- list(N = nrow(adm_indiv), n_d = 4,
  admit = adm_indiv$Admit, gender = adm_indiv$Gender,
  dept = adm_indiv$Dept)

ajuste <- mod_efectos_berkeley$sample(data = datos_lista, 
          iter_warmup = 300, iter_sampling = 1000,
          refresh = 1000, parallel_chains = 4)
resumen_mod <- ajuste$summary(
  c( "efecto_nat_dir", "efecto_nat_ind", "efecto_total")) |> 
  select(variable, mean, q5, q95)
resumen_mod
```

En este caso, el efecto total (que favorece al género 1) puede explicarse principalmente,
mediante el efecto natural indirecto (la selección de departamento), y el efecto directo natural
favorece al género 2. **Nótese que esto supone que no hay variables confusoras
entre departamento y admisión**. Como vimos en la sección anterior, esto no es necesariamente 
cierto.

**Ejercicio**: bajo este modelo y considerando los efectos que acabamos de estimar,
¿ayudaría en algo hacer que las aplicaciones fueran "ciegas", en el sentido de quitar
nombres o otras maneras de editar las aplicaciones para que no se pueda saber el
género del aplicante (si fuera posible)?





::: callout-tip
# Identificación de NDE y NIE

Los efectos naturales directos e indirectos nos siempre son identificables,
aún cuando algunos casos pueden resolverse estratificando por algunas variables.
Para más detalles, ver 4.5 en @pearl2016causal.

Por ejemplo, en el caso de un experimento
($T$ no tiene padres), entonces es suficiente identificar estos efectos si enocntramos un
conjunto $W$ de variables observadas que no sean descendientes de $T$ y que bloqueen
los caminos de puerta trasera de $M$ a $Y$ (sin contar $T\to M$ y $T\to Y$).
:::

- Por ejemplo, en nuestro diagrama de Berkeley donde existía el confusor $D\gets U\to A$,
no es posible identificar estos efectos directos e indirectos, pues no podemos bloquear
el camino de puerta trasera entre mediador $D$ y la respuesta $A$ que pasa por $U$.




