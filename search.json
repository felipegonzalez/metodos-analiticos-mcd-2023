[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Métodos analíticos",
    "section": "",
    "text": "Temario y referencias\nTodas las notas y material del curso estarán en este repositorio.\n\nParte 1: Inferencia causal\n\nIntroducción a inferencia causal\nModelos probabilísticos gráficos\nEstimación de efectos causales\nExperimentos y controles\nContrafactuales de Rubin\nOtros métodos de inferencia causal\n\nParte 2: Análisis de series de tiempo y pronósticos\n\nDescomposición de series de tiempo\nIngeniería de entradas para datos de series de tiempo\nMétodos clásicos para pronósticos\nModelo de espacio de estados\nInferencia causal para series de tiempo\n\n\n\nEvaluación\n\nTareas semanales (20%)\nExamen parcial (40% teórico)\nUn examen final (40% práctico)\n\n\n\nMaterial\nCada semestre las notas cambian, en algunas partes considerablemente. Las de este semestre están en este repositorio, incluyendo ejemplos, ejercicios y tareas.\n\n\nReferencias principales\n\nParte 1\n\nStatistical Rethinking\nCausal Inference in Statistics: a primer\nCounterfactuals and Causal Inference: Methods and Principles for Social Research\n\nParte 2:\n\nForecasting: Principles and Practice\nTime Series Analysis by State Space Methods\n\n\n\n\nOtras referencias\n\nPattern Recognition and Machine Learning, Bishop (2006)\nThe Book of Why\nData Analysis Using Regression and Multilevel/Hierarchical Models\nAn Introduction to State Space Time Series Analysis ### Software: R y Rstudio {-}\n\nPara hacer las tareas y exámenes pueden usar cualquier lenguaje o flujo de trabajo que les convenga (R o Python, por ejemplo) - el único requisito esté basado en código y no point-and-click.\n\n\n\n\nBishop, Christopher M. 2006. Pattern Recognition and Machine Learning (Information Science and Statistics). Secaucus, NJ, USA: Springer-Verlag New York, Inc."
  },
  {
    "objectID": "01-introduccion.html#qué-es-inferencia-causal",
    "href": "01-introduccion.html#qué-es-inferencia-causal",
    "title": "1  Introducción (Parte 1)",
    "section": "1.1 ¿Qué es inferencia causal?",
    "text": "1.1 ¿Qué es inferencia causal?\nLa inferencia causal consiste en predecir los posibles efectos de intervenciones, y entender qué pasaría si las condiciones que observamos fueran diferentes, es decir, condiciones contrafactuales. Tanto en ciencia como en industria, estos dos conceptos son muy importantes:\nIntervenciones (acciones):\n\n¿Qué efecto tiene sobre las ventas reducir el presupuesto de publicidad?\n¿Qué efecto tienen sobre la salud de una persona administrarle un medicamento?\n¿Cuáles son las expectativas de un hogar que ponemos en un programa gubernamental relacionado con la educación o la salud?\n\nContrafactuales (no necesariamente intervenciones que podemos controlar o ejecutar, sino escenarios hipotéticos):\n\n¿Cuánto ha contribuido a las ventas de un producto el gasto en publicidad?\n¿Cuál sería el ingreso de una persona si tuviera un año más de estudios?\n¿Cómo sería la salud de una persona que ha fumado durante 10 años si no hubiera fumado?\n\nEste tipo de preguntas centrales en la industria y la ciencia generalmente no pueden contestarse únicamente usando términos estadísticos y datos disponibles. Las razones son:\n\nAsociaciones entre variables observadas no implican relaciones causales entre las variables.\nLa ausencia de asociación entre variables observadas no implica que no hay relación causal entre ellas.\nRelaciones causales no están en los datos: están en el conocimiento experto o teoría científica.\n\nLa evaluación de intervenciones y de contrafactuales tienen una lógica similar, pero su naturaleza conceptual es diferente: en un caso"
  },
  {
    "objectID": "01-introduccion.html#preguntas-y-datos",
    "href": "01-introduccion.html#preguntas-y-datos",
    "title": "1  Introducción (Parte 1)",
    "section": "1.2 Preguntas y datos",
    "text": "1.2 Preguntas y datos\nPara entender y poder usar datos para contestar preguntas de interés, el paso inicial más importante es entender bajo que proceso se generan los datos. Veremos cómo estos procesos generadores se expresan en términos causales.\n\nCuanto más sepamos de este proceso, mejor podemos contestar preguntas de interés\nEn muchos casos, tenemos qué hacer supuestos basados en conocimiento experto acerca de este proceso generador para poder producir (o no) respuestas.\n\nEn particular, en inferencia causal:\n\nSi no tenemos los supuestos y hechos relevantes que definen el proceso generador de datos, no es posible dar respuestas a preguntas causales\n\n\nEjemplo (cálculos renales)\nEste es un estudio real acerca de tratamientos para cálculos renales (Julious y Mullee (1994)). Pacientes se asignaron de una forma no controlada a dos tipos de tratamientos para reducir cálculos renales. Para cada paciente, conocemos el tipo de ćalculos que tenía (grandes o chicos) y si el tratamiento tuvo éxito o no.\nLa tabla original tiene 700 renglones (cada renglón es un paciente)\n\ncalculos <- read_csv(\"../datos/kidney_stone_data.csv\")\nnames(calculos) <- c(\"tratamiento\", \"tamaño\", \"éxito\")\ncalculos <- calculos |> \n   mutate(tamaño = ifelse(tamaño == \"large\", \"grandes\", \"chicos\")) |> \n   mutate(resultado = ifelse(éxito == 1, \"mejora\", \"sin_mejora\")) |> \n   select(tratamiento, tamaño, resultado)\nnrow(calculos)\n\n[1] 700\n\n\ny se ve como sigue (muestreamos algunos renglones):\n\ncalculos |> \n   sample_n(10) |> kable() |> \n   kable_paper(full_width = FALSE)\n\n\n\n \n  \n    tratamiento \n    tamaño \n    resultado \n  \n \n\n  \n    A \n    grandes \n    sin_mejora \n  \n  \n    B \n    chicos \n    mejora \n  \n  \n    B \n    chicos \n    mejora \n  \n  \n    A \n    grandes \n    mejora \n  \n  \n    B \n    chicos \n    sin_mejora \n  \n  \n    A \n    grandes \n    sin_mejora \n  \n  \n    A \n    grandes \n    mejora \n  \n  \n    A \n    grandes \n    mejora \n  \n  \n    B \n    chicos \n    mejora \n  \n  \n    A \n    grandes \n    sin_mejora \n  \n\n\n\n\n\nAunque estos datos contienen información de 700 pacientes, los datos pueden resumirse sin pérdida de información contando como sigue:\n\ncalculos_agregada <- calculos |> \n   group_by(tratamiento, tamaño, resultado) |> \n   count()\ncalculos_agregada |> kable() |> \n   kable_paper(full_width = FALSE)\n\n\n\n \n  \n    tratamiento \n    tamaño \n    resultado \n    n \n  \n \n\n  \n    A \n    chicos \n    mejora \n    81 \n  \n  \n    A \n    chicos \n    sin_mejora \n    6 \n  \n  \n    A \n    grandes \n    mejora \n    192 \n  \n  \n    A \n    grandes \n    sin_mejora \n    71 \n  \n  \n    B \n    chicos \n    mejora \n    234 \n  \n  \n    B \n    chicos \n    sin_mejora \n    36 \n  \n  \n    B \n    grandes \n    mejora \n    55 \n  \n  \n    B \n    grandes \n    sin_mejora \n    25 \n  \n\n\n\n\n\nComo en este caso nos interesa principalmente la tasa de éxito de cada tratamiento, podemos mejorar mostrando como sigue:\n\ncalculos_agregada |> pivot_wider(names_from = resultado, values_from = n) |> \n   mutate(total = mejora + sin_mejora) |> \n   mutate(prop_mejora = round(mejora / total, 2)) |> \n   select(tratamiento, tamaño, total, prop_mejora) |> \n   arrange(tamaño) |> \n   kable() |> \n   kable_paper(full_width = FALSE)\n\n\n\n \n  \n    tratamiento \n    tamaño \n    total \n    prop_mejora \n  \n \n\n  \n    A \n    chicos \n    87 \n    0.93 \n  \n  \n    B \n    chicos \n    270 \n    0.87 \n  \n  \n    A \n    grandes \n    263 \n    0.73 \n  \n  \n    B \n    grandes \n    80 \n    0.69 \n  \n\n\n\n\n\nEsta tabla descriptiva es una reescritura de los datos, y no hemos resumido nada todavía. Pero es apropiada para empezar a contestar la pregunta:\n\n¿Qué indican estos datos acerca de qué tratamiento es mejor? ¿Acerca del tamaño de cálculos grandes o chicos?\n\nSupongamos que otro analista decide comparar los pacientes que recibieron cada tratamiento, ignorando la variable de tamaño:\n\ncalculos |> group_by(tratamiento) |> \n   summarise(prop_mejora = mean(resultado == \"mejora\") |> round(2)) |> \n   kable() |> \n   kable_paper(full_width = FALSE)\n\n\n\n \n  \n    tratamiento \n    prop_mejora \n  \n \n\n  \n    A \n    0.78 \n  \n  \n    B \n    0.83 \n  \n\n\n\n\n\ny parece ser que el tratamiento \\(B\\) es mejor que el \\(A\\). Esta es una paradoja (un ejemplo de la paradoja de Simpson) . Si un médico no sabe que tipo de cálculos tiene el paciente, ¿entonces debería recetar \\(B\\)? ¿Si sabe debería recetar \\(A\\)? Esta discusión parece no tener mucho sentido.\nPodemos investigar por qué está pasando esto considerando la siguiente tabla, que solo examina cómo se asignó el tratamiento dependiendo del tipo de cálculos de cada paciente:\n\ncalculos |> group_by(tratamiento, tamaño) |> count() |> \n   kable() |> \n   kable_paper(full_width = FALSE)\n\n\n\n \n  \n    tratamiento \n    tamaño \n    n \n  \n \n\n  \n    A \n    chicos \n    87 \n  \n  \n    A \n    grandes \n    263 \n  \n  \n    B \n    chicos \n    270 \n  \n  \n    B \n    grandes \n    80 \n  \n\n\n\n\n\nNuestra hipótesis aquí es que la decisión de qué tratamiento usar depende del tamaño de los cálculos. En este caso, hay una decisión pues A es una cirugía y B es un procedimiento menos invasivo, y se prefiere utilizar el tratamiento \\(A\\) para cálculos grandes, y \\(B\\) para cálculos chicos. Esto quiere decir que en la tabla total el tratamiento \\(A\\) está en desventaja porque se usa en casos más difíciles, pero el tratamiento \\(A\\) parece ser en general mejor. La razón es probablemente un proceso de optimización de recursos y riesgo que hacen los doctores.\n\nUna mejor respuesta a la pregunta de qué tratamiento es mejor es la que presenta los datos desagregados\nLa tabla desagregada de asignación del tratamiento nos informa acerca de cómo se está distribuyendo el tratamiento en los pacientes.\n\n\n\n\n\n\n\nNota\n\n\n\nLos resúmenes descriptivos acompañados de hipótesis causales acerca del proceso generador de datos, nos guía hacia descripciones interpretables de los datos.\n\n\nLas explicaciones no son tan simples y, otra vez, interviene el comportamiento de doctores, tratamientos, y distintos tipos de padecimientos.\nPodemos codificar la información causal con un diagrama:\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n  node [shape=plaintext]\n    T \n    M \n    C\n  edge [minlen = 3]\n    T -> M\n    C -> T\n    C -> M\n{ rank = same; M; T }\n}\n\", width = 200, height = 50)\n\n\n\n\n\n\nEs decir, el tamaño de los cálculos es una causa común de tratamiento (T) y resultado (M). Veremos más adelante que la decisión de condicionar a el tipo de cálculos proviene de un análisis relativamente simple de este diagrama causal, independientemente de los métodos que usemos para estimar las proporciones de interés (en este ejemplo, examinar las tablas cruzadas es equivalente a hacer estimaciones de máxima verosimlitud).\n\n\nEjemplo (cálculos renales 2)\nContrastemos el ejemplo anterior usando exactamente la misma tabla de datos, pero con el supuesto de un proceso generador diferente. En este caso, los tratamientos son para mejorar alguna enfermedad del corazón. Sabemos que parte del efecto de este tratamiento ocurre gracias a una baja en presión arterial de los pacientes, así que después de administrar el tratamiento, se toma la presión arterial de los pacientes. Ahora tenemos la tabla agregada y desagregada como sigue:\n\ncorazon <- calculos |> \n  select(tratamiento, presión = tamaño, resultado) |> \n  mutate(presión = ifelse(presión == \"grandes\", \"alta\", \"baja\"))\ncorazon_agregada <- corazon |> \n   group_by(tratamiento, presión, resultado) |> \n   count()\ncorazon_agregada |> pivot_wider(names_from = resultado, values_from = n) |> \n   mutate(total = mejora + sin_mejora) |> \n   mutate(prop_mejora = round(mejora / total, 2)) |> \n   select(tratamiento, presión, total, prop_mejora) |> \n   arrange(presión) |> \n   kable() |> \n   kable_paper(full_width = FALSE)\n\n\n\n \n  \n    tratamiento \n    presión \n    total \n    prop_mejora \n  \n \n\n  \n    A \n    alta \n    263 \n    0.73 \n  \n  \n    B \n    alta \n    80 \n    0.69 \n  \n  \n    A \n    baja \n    87 \n    0.93 \n  \n  \n    B \n    baja \n    270 \n    0.87 \n  \n\n\n\n\n\n\ncorazon |> group_by(tratamiento) |> \n   summarise(prop_mejora = mean(resultado == \"mejora\") |> round(2)) |> \n   kable() |> \n   kable_paper(full_width = FALSE)\n\n\n\n \n  \n    tratamiento \n    prop_mejora \n  \n \n\n  \n    A \n    0.78 \n  \n  \n    B \n    0.83 \n  \n\n\n\n\n\n¿Cuál creemos que es el mejor tratamiento en este caso? ¿Deberíamos usar la tabla agregada o la desagregada por presión?\n\nEn este caso, la tabla agregada es más apropiada (B es mejor tratamiento).\nLa razón es que presión en este caso es una consecuencia de tomar el tratamiento, y como las tablas muestran, B es más exitoso en bajar la presión de los pacientes.\nSi sólo comparamos dentro de los grupos de presión baja o de presión alta, ignoramos lo más importante del tratamiento en la probabilidad de mejorar.\n\nNuestros supuestos causales podemos mostrarlos con el siguiente diagrama:\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n  node [shape=plaintext]\n    P\n    T \n    M \n  edge [minlen = 3]\n    T -> P\n    P -> M\n    T -> M\n{ rank = same; M; T}\n}\n\", width = 200, height = 50)\n\n\n\n\n\n\n\n\nEjemplo (admisiones de Berkeley)\nUna ejemplo al que regresaremos más adelante es el siguiente: en 1973 se recolectaron datos agregados de solicitantes para estudiar en Berkeley para los 6 departamentos más grandes, clasificados por sexo del solicitante y si fue admitido o no. Los resultados se muestran a continuación:\n\ndata(\"UCBAdmissions\")\nadm_original <- UCBAdmissions |> as_tibble() |> \n   pivot_wider(names_from = Admit, values_from = n) \nadm_original |> knitr::kable() |> \n   kable_paper(full_width = FALSE)\n\n\n\n \n  \n    Gender \n    Dept \n    Admitted \n    Rejected \n  \n \n\n  \n    Male \n    A \n    512 \n    313 \n  \n  \n    Female \n    A \n    89 \n    19 \n  \n  \n    Male \n    B \n    353 \n    207 \n  \n  \n    Female \n    B \n    17 \n    8 \n  \n  \n    Male \n    C \n    120 \n    205 \n  \n  \n    Female \n    C \n    202 \n    391 \n  \n  \n    Male \n    D \n    138 \n    279 \n  \n  \n    Female \n    D \n    131 \n    244 \n  \n  \n    Male \n    E \n    53 \n    138 \n  \n  \n    Female \n    E \n    94 \n    299 \n  \n  \n    Male \n    F \n    22 \n    351 \n  \n  \n    Female \n    F \n    24 \n    317 \n  \n\n\n\n\n\ny las proporciones de admisión por sexo y departamente son las siguientes:\n\nadm_tbl <- adm_original |> \n   mutate(prop_adm = round(Admitted / (Admitted + Rejected), 2), total = Admitted + Rejected) |> \n   select(Gender, Dept, prop_adm, total) |> \n   pivot_wider(names_from = Gender, values_from = prop_adm:total)\nadm_tbl |> knitr::kable() |> \n   kable_paper(full_width = FALSE)\n\n\n\n \n  \n    Dept \n    prop_adm_Male \n    prop_adm_Female \n    total_Male \n    total_Female \n  \n \n\n  \n    A \n    0.62 \n    0.82 \n    825 \n    108 \n  \n  \n    B \n    0.63 \n    0.68 \n    560 \n    25 \n  \n  \n    C \n    0.37 \n    0.34 \n    325 \n    593 \n  \n  \n    D \n    0.33 \n    0.35 \n    417 \n    375 \n  \n  \n    E \n    0.28 \n    0.24 \n    191 \n    393 \n  \n  \n    F \n    0.06 \n    0.07 \n    373 \n    341 \n  \n\n\n\n\n\nComplementamos con las tasas de aceptación a total por género, y tasas de aceptación por departamento:\n\nadm_original |> group_by(Gender) |> \n   summarise(Admitted = sum(Admitted), Rejected = sum(Rejected)) |> \n   mutate(prop_adm = round(Admitted / (Admitted + Rejected),2)) |> \n   kable() |> \n   kable_paper(full_width = FALSE)\n\n\n\n \n  \n    Gender \n    Admitted \n    Rejected \n    prop_adm \n  \n \n\n  \n    Female \n    557 \n    1278 \n    0.30 \n  \n  \n    Male \n    1198 \n    1493 \n    0.45 \n  \n\n\n\n\n\nLa pregunta que queremos hacer es: ¿existe discriminación por sexo en la selección de candidatos? Examinando las tablas no está clara cuál es la respuesta.\n\nadm_original |> group_by(Dept) |> \n   summarise(Admitted = sum(Admitted), Rejected = sum(Rejected)) |> \n   mutate(prop_adm = round(Admitted / (Admitted + Rejected),2)) |> \n   kable() |> \n   kable_paper(full_width = FALSE)\n\n\n\n \n  \n    Dept \n    Admitted \n    Rejected \n    prop_adm \n  \n \n\n  \n    A \n    601 \n    332 \n    0.64 \n  \n  \n    B \n    370 \n    215 \n    0.63 \n  \n  \n    C \n    322 \n    596 \n    0.35 \n  \n  \n    D \n    269 \n    523 \n    0.34 \n  \n  \n    E \n    147 \n    437 \n    0.25 \n  \n  \n    F \n    46 \n    668 \n    0.06 \n  \n\n\n\n\n\nDiscutiremos este ejemplo con más detalle más adelante. La interpretación debe ser hecha con cuidado, y debemos establecer claramente los supuestos que fundamentan nuestra decisión de mostrar cada tabla y de qué forma mostrarlas."
  },
  {
    "objectID": "01-introduccion.html#resumen-de-ejemplos",
    "href": "01-introduccion.html#resumen-de-ejemplos",
    "title": "1  Introducción (Parte 1)",
    "section": "1.3 Resumen de ejemplos",
    "text": "1.3 Resumen de ejemplos\nNótese que en los dos casos anteriores, los datos son exactamente los mismos, pero la respuesta correcta es diferente en cada caso. En la tabla de datos no está la respuesta acerca de qué resumen es el correcto. Solamente conocimiento externo de cómo se generan los datos sugieren cómo debemos tratar y explicar lo que observamos en cada caso.\nA se conocimiento externo es una combinación de\n\nConocimiento de dominio o teorías científicas, y\nEntendimiento de cómo fueron recolectados y procesados los datos, lo cual también es información causal.\n\nEstos ejemplos también muestran adicionalmente que:\n\nIncluso desde un punto de vista puramente descriptivo, es necesario entender algo de la estructura causal del problema para poder dar descripciones interpretables\nSi no tenemos la información correcta, es difíl producir estimaciones causales.\n\nEn el primer ejemplo de cálculos renales fue importante saber saber el hecho de que los doctores seleccionaban el tratamiento según la severidad y que tuviéramos una medición de esa variable. En el segundo ejemplo de presión no era necesaria esa medición adicional.\n\nMás adelante hablaremos de experimentación. Veremos que aquí también entender el proceso generador de datos es importante. Por ejemplo, ¿qué variables podemos usar cómo controles para mejorar la estimación y qué variables no?\nModelos causales nos ayudan a diseñar estudios (experimentales o no) y a decidir qué datos es necesario recolectar."
  },
  {
    "objectID": "01-introduccion.html#más-de-asociación-no-causal",
    "href": "01-introduccion.html#más-de-asociación-no-causal",
    "title": "1  Introducción (Parte 1)",
    "section": "1.4 Más de asociación no causal",
    "text": "1.4 Más de asociación no causal\nDiscutiremos otro ejemplo de los puntos mencionados arriba.\nAlgunos estudios fueron publicados en la primera mitad de 2020 que notaban que el porcentaje fumadores entre los casos positivos de COVID era menor que en la población general, y se hicieron algunas interpretaciones acerca de este hecho. Estos estudios se hicieron con personas que se hicieron una prueba.\nEn este ejemplo replicaremos cómo es que podemos encontrar esta asociación en este tipo de estudios aún cuando no exista tal asociación en la población general (ver este artículo). Usaremos datos sintéticos (simulados).\nPrimero vamos a razonar acerca del proceso generador de datos y a hacer algunos supuestos:\n\nEn primer lugar, ¿cuándo decide hacerse alguien una prueba? A principios de 2020, son principalmente personas que tienen síntomas considerables, y trabajadores de salud (tengan o no síntomas).\nSer trabajador de salud incrementa el riesgo de contagiarse.\nEn algunos países, fumar está asociado con ser trabajador de salud (no tienen la misma tasa de tabaquismo que la población general).\nSólo observamos a las personas que se hicieron una prueba.\nFumar no tiene efectos causales en este modelo.\nIngoramos por el momento que la relación entre covid y prueba positiva no es perfecta.\n\nPodemos resumir cualitativamente con el siguiente diagrama:\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2, rankdir = LR]\n  node [shape=plaintext]\n    Prueba\n    TrabSalud\n    Síntomas\n    Fumar\n    Covid\n  edge [minlen = 3]\n    #TrabSalud -> Covid\n    TrabSalud -> Prueba\n    TrabSalud -> Fumar\n    TrabSalud -> Covid\n    U -> Síntomas\n    Covid -> Síntomas\n    Síntomas -> Prueba\n}\n\")#, width = 200, height = 50)\n\n\n\n\n\n\nEl código para simular es el siguiente: todas las variables toman valores 0 o 1, pero con diferentes probabilidades y dependiendo de las variables que son padres en la gráfica de arriba.\n\nSimulamos un millón de personas de las cuales aproximadamente el 1% son trabajadores de salud.\nSuponemos que la probabilidad es de 5% de que un trabajador de salud resulte positivo y de 1% para el del resto de las personas.\nSuponemos que de las personas que tienen covid, el 50% tienen síntomas y de las personas que no tienen covid, el 1% tiene síntomas.\nSuponemos que de los trabadores de salud el 99% se hicieron prueba (sin importar si tenían o no síntomas) y el resto de las personas se divide en 2, de los no trabadores de salud con síntomas, el 85% se hicieron una prueba y de los no trabajdores de salud sin síntomas, el 1% se hizo una prueba\nDe los trabajadores de salud, el 20% fuman, del resto de las personas el 7% fuman.\n\n\n\nCódigo\nset.seed(8221)\n#simular población\nn <- 1e6\ntrab_salud <- rbinom(n, 1, 0.01)\ncovid <- rbinom(n, 1, ifelse(trab_salud==1, 0.05, 0.01))\ndatos <- tibble(trab_salud = trab_salud, covid) |> \n  mutate(sintomas = rbernoulli(n, ifelse(covid == 1, 0.5, 0.01))) |> \n  mutate(prueba = rbernoulli(n, ifelse(trab_salud ==1, 0.99, 0.84 * sintomas + 0.01))) |> \n  mutate(fumar = rbernoulli(n, ifelse(trab_salud == 1, 0.20, 0.07))) |> \n  mutate(covid = ifelse(covid ==1, \"positivo\", \"negativo\")) |> \n  mutate(fumar = ifelse(fumar, \"fuma\", \"no_fuma\"))\n\n\nSuponemos ahora que tomamos como muestra a todas aquellas personas que se hicieron una prueba. En primer lugar, la proporción de fumadores en la muestra es un poco más alta que la población, porque los trabajadores de salud están sobrerrepresentados:\n\ndatos_pruebas <- filter(datos, prueba == 1)\ntable(datos_pruebas$fumar) |> prop.table() |> round(2)\n\n\n   fuma no_fuma \n   0.11    0.89 \n\n\nY ahora vemos que bajo esta condición o filtro, están asociados fumar y tener covid:\n\ntable(datos_pruebas$covid, datos_pruebas$fumar) |> prop.table(margin = 2) |> \n  round(2) \n\n          \n           fuma no_fuma\n  negativo 0.90    0.85\n  positivo 0.10    0.15\n\n\nSin embargo, en la población (sin filtrar por los que se hicieron prueba) en general, esperaríamos una asociación positiva pero relativamente chica de fumar con tener covid (veremos por qué sabemos esto al consultar el diagrama):\n\ntable(datos$covid, datos$fumar) |> prop.table(margin = 2) |> \n  round(4)\n\n          \n             fuma no_fuma\n  negativo 0.9892  0.9896\n  positivo 0.0108  0.0104\n\n\nEsta tampoco es una relación causal. Discutiremos con detalle más adelante por qué condicionar a sólo los que hicieron una prueba produce una correlación fuerte entre estas dos variables que no están causalmente relacionadas.\n\n\n\n\nJulious, Steven A, y Mark A Mullee. 1994. «Confounding and Simpson’s paradox». BMJ 309 (6967): 1480-81. https://doi.org/10.1136/bmj.309.6967.1480."
  },
  {
    "objectID": "02-modelos-graficos.html#repaso-de-probabilidad",
    "href": "02-modelos-graficos.html#repaso-de-probabilidad",
    "title": "2  Modelos gráficos probabilísticos",
    "section": "2.1 Repaso de probabilidad",
    "text": "2.1 Repaso de probabilidad\nSi \\(X\\) es una variable aleatoria, abusaremos de la notación escribiendo \\(p(x)\\) para denotar su función de densidad (continua o discreta). Si \\(X\\) es discreta, \\(p(x)=P(X=x)\\), y si \\(X\\) es continua, entonces \\(p(x)\\) es la función de densidad, que utilizamos para calcular probabilidades usando integrales, por ejemplo\n\\[P(X \\in [a,b]) = \\int_a^b p(x)\\, dx\\] Ojo: en algunos casos, para evitar reescribir fórmulas, usaremos esta misma notación para denotar probabilidades de variables discretas, que más apropiadamente escribiríamos como \\(P(X\\in[a,b]) = \\sum_{x=a}^{b} P(X = x)\\).\nSi \\(X\\) y \\(Y\\) son variables aleatorias, entonces denotamos por \\(p(x,y)\\) a su densidad conjunta. Podemos calcular las distribuciones de x y y integrando sobre una de las variables\n\\[p(y) = \\int_{-\\infty}^{\\infty} p(x,y)dx = \\int p(x,y)dx\\] Nótese que abusamos algo de la notación quitando los límites de la integral de la derecha (y recordamos que si \\(X\\) es discreta, entonces usamos una suma en lugar de una integral). En este contexto, \\(p(x), p(y)\\) se llaman distribuciones marginales de \\(X\\) y \\(Y\\)\nDenotamos por \\(p(y|x)\\) y \\(p(x|y)\\) a las densidades condicionales de Y dado X y X dada Y respectivamente. Estas están definidas por\n\\[p(y|x) = \\frac{p(x, y)}{p(x)}\\] Esta densidad condicional nos dice cómo se distribuye \\(Y\\) cuando sabemos que \\(X=x\\).\nDe esta definición, tenemos la regla del producto que establece que\n\\[p(x,y) = p(y|x) p(x) = p(x|y)p(y) \\]\nCuando la distribución condicional de \\(p(y|x)\\) cambia dependiendo de la \\(x\\), decimos que \\(X\\) y \\(Y\\) está asociadas. Si no es el caso, decimos que son independientes. Esto quiere decir que\n\\[p(y|x) = p(y)\\] es decir, la condicional de \\(Y\\) dada \\(X\\) es igual a la marginal de \\(Y\\). Por definición, la independencia también se puede escribir como una versión simplificada de la regla del producto:\n\\[p(x,y) = p(x)p(y)\\] es decir, la conjunta se factoriza en una parte que sólo depende de \\(x\\) y otra que sólo dependen de \\(y\\).\n\n\n\n\n\n\nTip\n\n\n\nUna manera útil de construir modelos de probabilidad conjuntas con variables que tienen dependencias es utilizando una factorización de la regla del producto, lo cual nos permite concentrarnos en una variable a la vez.\n\n\nDependiendo del tipo de problema, puede ser más conveniente definir \\(p(x)\\) y \\(p(y|x)\\) o \\(p(y)\\) y \\(p(x|y)\\). En ambos casos podemos calcular la conjunta \\(p(x,y)\\) con la que podemos calcular cualquier probabilidad conjunta de interés o cantidad resumen que involucra a a estas dos variables aleatorias.\n\nEjemplo 1\nSupongamos que \\(X\\) es el resultado de una tirada de dado, y que \\(Y\\) es el número de soles que obtenemos en \\(X\\) volados de una moneda justa.\nEntonces podemos escribir \\(p(x) = 1/6\\) para \\(x=1,2,\\ldots, 6\\), es decir, \\(X\\) es Uniforme en \\(\\{1,2,3,4,5,6\\}\\), y \\(Y|X=x\\) son el número de soles en \\(x\\) volados, de modo que es Binomial con parámetros \\((x, 0.5)\\). Esto lo podemos escribir como\n\\[\\begin{equation}\n\\begin{split}\nY|X \\sim & Bin(X, 0.5) \\\\\nX  = & U(\\{1,2,3,4,5,6\\})\n\\end{split}\n\\end{equation}\\]\nEstas variables no son independientes, pues la condicional de \\(Y\\) cambia dependiendo del valor que toma \\(X\\).\nComo estas dos variables son discretas, la conjunta puede escribirse con la regla del producto como una tabla como sigue:\n\nprobs_x <- tibble(x = 1:6, p_x = 1/6)\nprobs_conjunta <-  crossing(probs_x, y = seq(0, 6, 1)) |> \n  mutate(p_cond_y = dbinom(y, size = x, prob = 0.5)) |> \n  mutate(p = p_cond_y * p_x) #producto\nprobs_conjunta |> select(x, y, p) |> \n  pivot_wider(names_from = x, values_from = p, names_prefix = \"x=\") |> \n  kable(digits = 4) |> kable_paper()\n\n\n\n \n  \n    y \n    x=1 \n    x=2 \n    x=3 \n    x=4 \n    x=5 \n    x=6 \n  \n \n\n  \n    0 \n    0.0833 \n    0.0417 \n    0.0208 \n    0.0104 \n    0.0052 \n    0.0026 \n  \n  \n    1 \n    0.0833 \n    0.0833 \n    0.0625 \n    0.0417 \n    0.0260 \n    0.0156 \n  \n  \n    2 \n    0.0000 \n    0.0417 \n    0.0625 \n    0.0625 \n    0.0521 \n    0.0391 \n  \n  \n    3 \n    0.0000 \n    0.0000 \n    0.0208 \n    0.0417 \n    0.0521 \n    0.0521 \n  \n  \n    4 \n    0.0000 \n    0.0000 \n    0.0000 \n    0.0104 \n    0.0260 \n    0.0391 \n  \n  \n    5 \n    0.0000 \n    0.0000 \n    0.0000 \n    0.0000 \n    0.0052 \n    0.0156 \n  \n  \n    6 \n    0.0000 \n    0.0000 \n    0.0000 \n    0.0000 \n    0.0000 \n    0.0026 \n  \n\n\n\n\n\nNótese adicionalmente que la forma en que planteamos el problema naturalmente nos da un modelo generativo, es decir, podemos simular fácilmente realizaciones de esta conjunta particular:\n\nsimular_juego <- function(n = 1, x = NULL){\n  if(is.null(x)){\n    x <- sample(1:6, n, replace = TRUE)\n  }\n  y <- rbinom(n, x, prob = 0.5)\n  tibble(n = seq_len(n), x = x, y = y)\n}\nset.seed(880)\nsimular_juego(n = 5)\n\n# A tibble: 5 × 3\n      n     x     y\n  <int> <int> <int>\n1     1     5     3\n2     2     5     1\n3     3     3     1\n4     4     6     4\n5     5     4     3\n\n\nY usando simulación podemos estimar cualquier cantidad de interés acerca de las variables \\(X\\) y \\(Y\\). Por ejemplo, su correlación la estimamos con\n\nsimular_juego(n = 10000) |> select(x, y) |> cor()\n\n          x         y\nx 1.0000000 0.6716973\ny 0.6716973 1.0000000\n\n\n\n\nEjemplo 2\nSupongamos que \\(W\\) es una el peso de una persona y \\(H\\) su estatura. Podemos comenzar con la factorización \\(p(w,h) = p(h)p(w|h)\\). Un modelo generativo podría ser el que sigue: \\(H\\) es Normal con media 165 y desviación estandar 12,\n\\[H \\sim N(170, 12) \\]\ny dada la estatura \\(H=h\\), el peso es\n\\[W|H=h \\sim N(m_h, 10)\\] donde\n\\[m_h = -50 + 0.7 h\\]\n\nsim_wh <- function(n = 10){\n  h <- rnorm(n, 170, 12)\n  m_h <- -50 + 0.7 * h\n  w <- rnorm(n, m_h, 10)\n  tibble(w = w, h = h)\n}\n\n\nset.seed(992)\nsims <- sim_wh(500)\nggplot(sims, aes(x = h, y = w)) + geom_point()\n\n\n\n\nTambién escribimos este modelo en stan:\n\nmod_peso <- cmdstanr::cmdstan_model(\"../src/peso_estatura.stan\")\nprint(mod_peso)\n\ndata {\n  int<lower=0> N;\n}\n\nparameters {\n}\n\ntransformed parameters {\n}\n\nmodel {\n\n}\ngenerated quantities {\n  real<lower=0> h;\n  real<lower=0> w;\n\n    h = normal_rng(170, 12);\n    real m_w = -50 + 0.7 * h;\n    w = normal_rng(m_w, 10);\n}\n\n\n\ndatos_lista <- list(N = 500)\najuste <- mod_peso$sample(data = datos_lista, refresh = 1000, fixed_param = TRUE)\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 Iteration:   1 / 1000 [  0%]  (Sampling) \nChain 1 Iteration: 1000 / 1000 [100%]  (Sampling) \nChain 1 finished in 0.0 seconds.\nChain 2 Iteration:   1 / 1000 [  0%]  (Sampling) \nChain 2 Iteration: 1000 / 1000 [100%]  (Sampling) \nChain 2 finished in 0.0 seconds.\nChain 3 Iteration:   1 / 1000 [  0%]  (Sampling) \nChain 3 Iteration: 1000 / 1000 [100%]  (Sampling) \nChain 3 finished in 0.0 seconds.\nChain 4 Iteration:   1 / 1000 [  0%]  (Sampling) \nChain 4 Iteration: 1000 / 1000 [100%]  (Sampling) \nChain 4 finished in 0.0 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.0 seconds.\nTotal execution time: 0.6 seconds.\n\nsims <- ajuste$draws(c(\"h\", \"w\"), format = \"df\")\nresumen <- ajuste$summary(c(\"h\", \"w\"))\nresumen |> select(variable, mean, q5, q95)\n\n# A tibble: 2 × 4\n  variable  mean    q5   q95\n  <chr>    <dbl> <dbl> <dbl>\n1 h        170.  151.  189. \n2 w         69.0  47.4  90.5\n\n\n\nggplot(sims, aes(x = h, y = w)) + geom_point()"
  },
  {
    "objectID": "02-modelos-graficos.html#caso-multivariado",
    "href": "02-modelos-graficos.html#caso-multivariado",
    "title": "2  Modelos gráficos probabilísticos",
    "section": "2.2 Caso multivariado",
    "text": "2.2 Caso multivariado\nSupongamos que tenemos \\(X_1,\\ldots, X_p\\) variables aleatorias. Denotamos su conjunta con \\[p(x_1, x_2, \\ldots, x_n)\\] En el caso particular de 3 variables p(x,y,z) la regla del producto se escribe como\n\\[p(x,y,z) = p(z|x,y)p(y|x)p(x)\\] que podemos escribir, dependiendo del problema, en cualquiera de las seis permutaciones posibles, por ejemplo:\n\\[p(x,y,z) = p(x|y,z)p(y|z)p(z)\\]\nEl proceso de simulación lo podemos mostrar gráficamente como sigue:\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n  node [shape=plaintext]\n    X \n    Y \n    Z\n  edge [minlen = 3]\n    Z -> Y\n    Y -> X\n    Z -> X\n{ rank = same; Z; Y }\n}\n\", width = 200, height = 50)\n\n\n\n\n\n\nNótese que este ejemplo puede aplicarse a cualquier conjunta nos interese, pues la factorización resulta de la regla del producto.\n\n2.2.1 Ejemplo\nSupongamos que escogemos al azar un número \\(X\\) entre 0 y 1, y luego tiramos dos veces cinco volados con probabilidad de sol \\(X\\). Medimos el número de soles en cada prueba como \\(S_1\\) y \\(S_2\\).\nEn este caso, es natural escribir la factorización:\n\\[p(x,s_1,x_2) = p(s_2|s_1,x)p(s_1|x)p(x).\\] Sin embargo, podemos simplificar aún más esta conjunta, pues en realidad una vez que sabemos X, el resultado de \\(S_1\\) no cambia la distribución de \\(S_2\\), de forma que para el proceso que describimos arriba,\n\\[p(x, s_1, s_2) = p(s_2|x)p(s_1|x)p(x).\\] En este caso, en nuestros supuestos está la independencia condicional de \\(S_1\\) y \\(S_2\\) dado \\(X\\), que explicaremos con detalle más adelante. El diagrama relevante es\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n  node [shape=plaintext]\n    X \n    S1 [label = <S<SUB>1</SUB>>]\n    S2 [label = <S<SUB>2</SUB>>]\n  edge [minlen = 3]\n    X -> S1\n    X -> S2\n{ rank = same; S1; S2 }\n}\n\", width = 200, height = 50)\n\n\n\n\n\n\nY podemos hacer simulaciones de este proceso generador:\n\nsimular_dos <- function(n = 10, x = NULL){\n  if(is.null(x)){\n    x <- runif(n)\n  }\n  s_1 <- rbinom(n, 5, prob = x)\n  s_2 <- rbinom(n, 5, prob = x)\n  tibble(x = x, s_1 = s_1, s_2 = s_2)\n}\nset.seed(116)\nsims_monedas <- simular_dos(5000)\nhead(sims_monedas)\n\n# A tibble: 6 × 3\n      x   s_1   s_2\n  <dbl> <int> <int>\n1 0.741     4     4\n2 0.336     5     2\n3 0.193     1     1\n4 0.281     1     2\n5 0.998     5     5\n6 0.534     3     5\n\n\nNótese que aún cuando simulamos independientemente \\(S_1\\) y \\(S_2\\) una vez que tenemos el dado, \\(S_1\\) y \\(S_2\\) no son independientes:\n\nggplot(sims_monedas, aes(x = s_1, y = s_2)) + geom_jitter(width = 0.25, height = 0.25)\n\n\n\n\n\nCuando no conocemos \\(X\\), saber \\(S_1\\) nos da información acerca de \\(S_2\\), porque saber \\(S_1\\) cambia la distribución de \\(X\\) (cuál es la probablidad de sol)\nSi no conocemos \\(X\\), la información puede fluir de \\(S_1\\) a \\(S_2\\).\n\n\n\n2.2.2 Ejemplo\nRegresamos al ejemplo de estatura y peso. Supongamos que agregamos una variable adicional \\(S\\) que vale 1 cuando la persona es hombre y 0 si no. Podemos discutir distintas maneras de construir nuestro modelo, por ejemplo, supongamos que usamos:\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n  node [shape=plaintext]\n    S \n    H \n    W\n  edge [minlen = 3]\n    S -> H\n    H -> W\n    S -> W\n{ rank = same; S; H; W }\n}\n\", width = 200, height = 50)\n\n\n\n\n\n\nEn este caso, para definir nuestro modelo generativo tenemos que definir \\(p(z)\\), \\(p(h|z)\\) y finalmente \\(p(w|h,z)\\). En este caso, consideramos que además de que los hombres tienen estatura mayor y por tanto mayor peso, existe un efecto adicional que, entre hombres y mujeres de la misma estatura, los hombres tienden a ser más un poco más pesados.\n\nEntender la diferencia y cuantificar el efecto de hombre-mujer sobre peso a través de estatura y el efecto directo es importante y veremos cómo hacerlo más adelante, y bajo qué condicinoes es posible.\n\nEn este modelo, podríamos argumentar que hay, por ejemplo:\n\nMuchas causas de sexo que podríamos considerar, pero no nos interesan pues nuestras preguntas están relacionadas con el efecto de sexo. Si esas variables pudieran influír causalmente tanto a sexo como a peso, entonces deberíamos incluirlas, como veremos más adelante.\nTambién sabemos que hay muchas causas comunes de altura y peso. Por ejemplo, nutrición o medio ambiente. Si esas causas no influyen también a sexo, entonces veremos más adelante por qué no es necesario que las incluyamos para la pregunta particular que estamos formulando en este ejemplo (el efecto total de sexo).\n\nDada el diagrama, consideramos un modelo generativo como sigue:\n\nmod_peso <- cmdstanr::cmdstan_model(\"../src/peso_estatura_2.stan\")\nprint(mod_peso)\n\ndata {\n  int<lower=0> N;\n}\n\nparameters {\n}\n\ntransformed parameters {\n}\n\nmodel {\n\n}\ngenerated quantities {\n  int<lower=0> s;\n  real<lower=0> h;\n  real<lower=0> w;\n\n    // simulamos hombre o mujer\n    s = bernoulli_rng(0.5);\n    // simular estatura dado el sexo\n    real m_h = 15 * s + 160;\n    h = normal_rng(m_h, 12);\n    // simular peso dado estatura y sexo\n    real m_w = -50 + 5 * s + 0.7 * h;\n    w = normal_rng(m_w, 10);\n}\n\n\n\ndatos_lista <- list(N = 500)\najuste <- mod_peso$sample(data = datos_lista, refresh = 1000, fixed_param = TRUE)\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 Iteration:   1 / 1000 [  0%]  (Sampling) \nChain 1 Iteration: 1000 / 1000 [100%]  (Sampling) \nChain 1 finished in 0.0 seconds.\nChain 2 Iteration:   1 / 1000 [  0%]  (Sampling) \nChain 2 Iteration: 1000 / 1000 [100%]  (Sampling) \nChain 2 finished in 0.0 seconds.\nChain 3 Iteration:   1 / 1000 [  0%]  (Sampling) \nChain 3 Iteration: 1000 / 1000 [100%]  (Sampling) \nChain 3 finished in 0.0 seconds.\nChain 4 Iteration:   1 / 1000 [  0%]  (Sampling) \nChain 4 Iteration: 1000 / 1000 [100%]  (Sampling) \nChain 4 finished in 0.0 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.0 seconds.\nTotal execution time: 0.5 seconds.\n\nsims <- ajuste$draws(c(\"s\", \"h\", \"w\"), format = \"df\")\nresumen <- ajuste$summary(c(\"h\", \"w\"))\nresumen |> select(variable, mean, q5, q95)\n\n# A tibble: 2 × 4\n  variable  mean    q5   q95\n  <chr>    <dbl> <dbl> <dbl>\n1 h        168.  144.  191. \n2 w         70.1  45.3  95.1\n\n\n\nggplot(sims, aes(x = h, y = w, colour = factor(s))) + geom_point() +\n  geom_smooth(se = FALSE)\n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\n\n\n\n\n\n\n\n\n\nModelos lineales\n\n\n\n\nEn estos ejemplos, estamos usando modelos lineales sin interacciones, pero en realidad podríamos incluír no linealidad (en forma de splines o modelos teóricos) o interacciones, por ejemplo\nEn todos los casos, es importante checar los modelos que hemos construido (ver flujo bayesiano).\n\n\n\nEjercicios:\n\nConstruye un modelo quitando la flecha \\(S\\to W\\).\nConstruye un modelo donde \\(H\\) y \\(S\\) interactúan para determinar \\(W\\).\n¿Qué modelos son más simples en términos de parámetros que son necesarios para definirlos?"
  },
  {
    "objectID": "02-modelos-graficos.html#variables-observadas-y-no-observadas",
    "href": "02-modelos-graficos.html#variables-observadas-y-no-observadas",
    "title": "2  Modelos gráficos probabilísticos",
    "section": "2.3 Variables observadas y no observadas",
    "text": "2.3 Variables observadas y no observadas\nNótese que en muchos casos, la estructura que genera los datos puede incluir variables que no hemos medido. No siempre es una buena idea quitar estas variables porque simplemente nos las conocemos. Dado el proceso generador, no tendría mucho sentido escribir \\(S_1 \\to S_2\\) o \\(S_2 \\to S_1\\) (aunque podríamos construir tales modelos).\nEn este caso, podríamos mejor escribir:\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n  node [shape=circle]\n    X\n  node [shape=plaintext]\n    S1 [label = <S<SUB>1</SUB>>]\n    S2 [label = <S<SUB>2</SUB>>]\n  edge [minlen = 3]\n    X -> S1\n    X -> S2\n{ rank = same; S1; S2 }\n}\n\", width = 200, height = 50)\n\n\n\n\n\n\nLa estructura del modelo junto con la naturaleza de las relaciones que conocemos nos permitirá hacer inferencia sobre esas variables no observadas, por ejemplo:\n\nmod_monedas <- cmdstanr::cmdstan_model(\"../src/monedas.stan\")\nprint(mod_monedas)\n\ndata {\n  int<lower=0> s_1;\n  int<lower=0> s_2;\n}\nparameters {\n  real<lower=0, upper = 1> x;\n}\nmodel {\n  x ~ uniform(0, 1);\n  s_1 ~ binomial(5, x);\n  s_2 ~ binomial(5, x);\n}\n\n\n\ndatos_lista <- list(s_1 = 5, s_2 = 3)\najuste <- mod_monedas$sample(data = datos_lista, refresh = 1000)\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 finished in 0.0 seconds.\nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 2 finished in 0.0 seconds.\nChain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 3 finished in 0.0 seconds.\nChain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 4 finished in 0.0 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.0 seconds.\nTotal execution time: 0.5 seconds.\n\nsims <- ajuste$draws(c(\"x\"), format = \"df\")\nresumen <- ajuste$summary(c(\"x\"))\nresumen |> select(variable, mean, q5, q95)\n\n# A tibble: 1 × 4\n  variable  mean    q5   q95\n  <chr>    <dbl> <dbl> <dbl>\n1 x        0.751 0.529 0.920\n\n\nDe modo que con alta probabilidad, escogimos una \\(X\\) entre .5 y 0.93.\n\n2.3.1 Ejemplo (estudio de Santa Clara)\nEn 2020 se hizo un estudio de seroprevalencia de COVID en Santa Clara, California.\nSe tomó una muestra de individuos (ver los detalles en el artículo original). Para propósitos de este análisis supondremos que la muestra puede considerarse como aleatoria simple.\nSe obtuvieron 3,300 individuos, y 50 de ellos resultaron con prueba positiva (1.5%). Sin embargo, el kit de prueba que estaban utilizando, tienen cierta especificidad y sensibilidad menores a 1. En pruebas de gold standard, el kit identificó correctamente como positivos a 103 de 122 personas infectadas, e identificó correctamente como negativos a 399 de 401 personas no infectadas.\nConstruiremos ahora una gráfica que indica cómo es el proceso generador de datos. En primer lugar, no interesa estimar la seropositividad en una población dada, que suponemos fue muestreada al azar. Nosotros solamente observamos si la prueba que usamos es positiva o negativa. Escribimos entonces para empezar:\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n  node [shape=circle]\n    prev\n    Inf\n  node [shape=plaintext]\n    Inf\n    Positivos\n    N\n    \n  edge [minlen = 3]\n    prev -> Inf\n    Inf -> Positivos\n    N -> Inf\n    \n}\n\", width = 150, height = 60)\n\n\n\n\n\n\nNótese que estamos pensando de forma causal al dibujar las aristas:\n\n\\(N\\) (el tamaño de muestra) es una variable que controlamos. No está determinada por la prevalencia. La flecha debe ser \\(prev \\to Inf\\), pues sabemos que si la prevalencia es diferente, entonces el número de personas con infección previa tiene una distribución diferente. Sin embargo, si intervenimos y cambiamos por alguna razón la variable \\(Inf\\), claramente esto no tiene ningún efecto en \\(p\\) ni en \\(N\\).\n\\(Inf\\) influye en la distribución de positivos, y el número de positivos está determinado solamente por las características de la prueba. Nótese que si sabemos \\(Inf\\), entonces el número de positivos no influye en en \\(p\\) ni en \\(N\\), y que cambiar la prueba por ejemplo, no cambia la distribución de la variable \\(Inf\\). De modo que la única flecha que debemos agregar es \\(Inf \\to Positivos\\).\nAunque podríamos agregar muchos factores que influyen en la prevalencia, estas variables no afectan directamente a otras variables de nuestro diagrama. Dado que no nos interesa contestar este tipo de preguntas, omitimos estas variables.\n\nUn camino sería ahora decidir que \\(Inf=Positivos\\), es decir no son releventes las características de la prueba, y proceder con la inferencia. Sin embargo, la pregunta qué tenemos qué hacer, es ¿puede ser que las características de la prueba influyan considerablemente en las estimaciones que obtenemos?\nAntes de proceder a incluir las características de la prueba, haremos el análisis pensando que el error de medición no es importante:\n\n#! message: false\nlibrary(cmdstanr)\n\nThis is cmdstanr version 0.5.3\n\n\n- CmdStanR documentation and vignettes: mc-stan.org/cmdstanr\n\n\n- CmdStan path: /home/runner/.cmdstan/cmdstan-2.31.0\n\n\n- CmdStan version: 2.31.0\n\nmod_sc <- cmdstan_model(\"../src/sclara-simple.stan\")\nprint(mod_sc)\n\ndata {\n  int<lower=0> N;\n  int<lower=0> n;\n}\n\nparameters {\n  real<lower=0, upper=1> p; //seroprevalencia\n\n}\n\ntransformed parameters {\n  real<lower=0, upper=1> prob_pos;\n\n  prob_pos = p;\n\n}\nmodel {\n  // modelo de número de positivos\n  n ~ binomial(N, prob_pos);\n  p ~ beta(1.0, 10.0);\n}\n\n\n\nn <- 50\nN <- 3300\ndatos_lista <- list(N = 3300, n = 50)\najuste <- mod_sc$sample(data = datos_lista, refresh = 1000)\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 finished in 0.0 seconds.\nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 2 finished in 0.0 seconds.\nChain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 3 finished in 0.0 seconds.\nChain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 4 finished in 0.0 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.0 seconds.\nTotal execution time: 0.5 seconds.\n\nsims <- ajuste$draws(c(\"p\"), format = \"df\")\nresumen <- ajuste$summary(c(\"p\"))\n\n\nresumen |> select(variable, mean, q5, q95)\n\n# A tibble: 1 × 4\n  variable   mean     q5    q95\n  <chr>     <dbl>  <dbl>  <dbl>\n1 p        0.0154 0.0120 0.0192\n\n\nY podemos graficar la posterior de la seroprevalencia:\n\nggplot(sims, aes(x = p)) + \n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nDonde parece ser que la prevalencia está muy probablemente por arriba de 1.2% Si este es el caso, esto implicaría que el subconteo de infecciones era muy grande, y que el IFR es más bajo de lo que se creía.\nSin embargo, observamos positivos en la prueba, y no realmente si alguien se ha infectado o no. Ahora incluimos sensibilidad y especificidad:\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n  node [shape=circle]\n    prev\n    Inf\n    sens\n    esp\n  node [shape=plaintext]\n    Inf\n    Positivos\n    N\n\n  edge [minlen = 3]\n    prev -> Inf\n    Inf -> Positivos\n    N -> Inf\n    sens -> Positivos\n    esp -> Positivos\n}\n\", width = 150, height = 60)\n\n\n\n\n\n\n\nNótese que sens y esp, si las modificamos, no cambian nada de \\(N\\), \\(Inf\\), ni la prevalencia. Igualmente, las flechas deben ir hacia \\(Inf\\), pues modificar esta cantidad no produce cambios en las características de la prueba.\nPara entender si tenemos que agregar una flecha de sensibilidad a especificidad tendríamos que pensar en el proceso que genera estas variables. Podemos pensar en primer lugar que una variable común que determina estas dos cantidades es, por ejemplo, la curva ROC de la prueba que produciría una asociación negativa en estas variables. En un ejercicio más adelante exploraremos esto, pero por el momento no consideramos esto (por ejemplo, podría ser que existiera una relación inversa entre especificidad y sensibilidad, que depende de la curva ROC).\n\nFinalmente, tenemos los datos de las pruebas de gold estándar que se hicieron para las pruebas. Esto incluye cuantos casos verificados positivos/negativos se les aplicó la prueba, cuántos casos fueron correctamente clasificados por la prueba en cada caso. Dibujamos entonces:\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n  node [shape=circle]\n    sens\n    esp\n    prev\n    Inf\n  node [shape=plaintext]\n    Inf\n    Positivos\n    npos\n    poskit\n    nneg\n    negkit\n    N\n    \n  edge [minlen = 3]\n    npos -> poskit\n    sens -> poskit\n    nneg -> negkit\n    esp -> negkit\n    prev -> Inf\n    Inf -> Positivos\n    sens -> Positivos\n    esp -> Positivos\n    N -> Inf\n    \n}\n\", width = 150, height = 60)\n\n\n\n\n\n\n\nLas flechas que acabamos de dibujar corresponden a la discusión que tenemos arriba. Por ejemplo, cambiar \\(esp\\) cambia la distribución de el número de negativos que obtuvimos, pero intervenir en el número de negativos (por ejemplo, escogiendo las personas que se ven sanas para hacerse la prueba y descartar a otro) no tiene efecto sobre \\(esp\\).\n\nAhora escribimos los modelos locales siguiendo los supuestos que acabamos de establecer, que en este caso están determinados:\n\nlibrary(cmdstanr)\nmod_sc <- cmdstan_model(\"../src/sclara.stan\")\nprint(mod_sc)\n\ndata {\n  int<lower=0> N;\n  int<lower=0> n;\n  int<lower=0> kit_pos;\n  int<lower=0> n_kit_pos;\n  int<lower=0> kit_neg;\n  int<lower=0> n_kit_neg;\n}\n\nparameters {\n  real<lower=0, upper=1> p; //seroprevalencia\n  real<lower=0, upper=1> sens; //sensibilidad\n  real<lower=0, upper=1> esp; //especificidad\n}\n\ntransformed parameters {\n  real<lower=0, upper=1> prob_pos;\n\n  prob_pos = p * sens + (1 - p) * (1 - esp);\n\n}\nmodel {\n  // modelo de número de positivos\n  n ~ binomial(N, prob_pos);\n  // modelos para resultados del kit\n  kit_pos ~ binomial(n_kit_pos, sens);\n  kit_neg ~ binomial(n_kit_neg, esp);\n  // iniciales para cantidades no medidas\n  p ~ beta(1.0, 10.0);\n  sens ~ beta(2.0, 1.0);\n  esp ~ beta(2.0, 1.0);\n}\n\n\n\nn <- 50\nN <- 3300\ndatos_lista <- list(N = 3300, n = 50,\n kit_pos = 103, n_kit_pos = 122,\n kit_neg = 399, n_kit_neg = 401)\najuste <- mod_sc$sample(data = datos_lista, refresh = 1000)\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 finished in 0.0 seconds.\nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 2 finished in 0.0 seconds.\nChain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 3 finished in 0.0 seconds.\nChain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 4 finished in 0.0 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.0 seconds.\nTotal execution time: 0.5 seconds.\n\nsims <- ajuste$draws(c(\"p\", \"sens\", \"esp\"), format = \"df\")\nresumen <- ajuste$summary(c(\"p\"))\n\n\nresumen |> select(variable, mean, q5, q95)\n\n# A tibble: 1 × 4\n  variable   mean      q5    q95\n  <chr>     <dbl>   <dbl>  <dbl>\n1 p        0.0102 0.00213 0.0176\n\n\nY podemos graficar la posterior de la seroprevalencia:\n\nggplot(sims, aes(x = p)) + \n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nY vemos que los datos son consistentes con el dato reportado por los autores (alrededor de 1.2%), pero que no podemos excluir valores de prevalencia muy bajos (por abajo de 0.3% por ejemplo). Por otro lado, también son consistentes valores muy altos de seroprevalencia, de manera que este estudio resultó ser poco informativo de la IFR del COVID.\nPodemos hacer diagnósticos adicionales acerca de la razón de esta variabilidad alta, si graficamos la relación entre especificidad de la prueba y estimación de prevalencia:\n\nggplot(sims, aes(x = esp, y = p)) + geom_point() +\n  xlab(\"Especificidad del kit\") + ylab(\"Prevalencia\") + geom_smooth()\n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\n\n\n\nLa asociación entre estas dos cantidades es interesante porque conceptualmente (y desde punto de vista del modelo), no hay relación entre estas dos variables: su asociación aparece porque son causas que compiten para explicar una observación.\nAunque aprender el flujo de construcción y validación de modelos en todos sus aspectos no es el objetivo de este curso, mostramos un resumen abajo:\n\n\n\n\n\n\nDesarrollo de modelos\n\n\n\n\nEstablecer la pregunta que queremos contestar\nEspecificar nuestros supuestos causales\nDefinir un modelo generativo dado el paso anterior\nDefinir una estrategia para contestar la pregunta de 1)\nProbar el modelo y nuestra estrategia usando el modelo generativo\nAnalizar datos con el modelo, checar supuestos y resumir."
  },
  {
    "objectID": "02-modelos-graficos.html#independencia-condicional",
    "href": "02-modelos-graficos.html#independencia-condicional",
    "title": "2  Modelos gráficos probabilísticos",
    "section": "2.4 Independencia condicional",
    "text": "2.4 Independencia condicional\nRecordamos el concepto de independencia condicional, que está relacionado a cómo se puede factorizar una conjunta:\n\n\n\n\n\n\nIndependencia condicional\n\n\n\nSean \\(X,Y,Z\\) variables aleatorias. Decimos que \\(X\\) y \\(Y\\) son condicionalmente independientes dado \\(Z\\) cuando se satisface \\[p(x,y|z) = p(x|z)p(y|z)\\] o equivalentemente, \\[p(x|y,z) = p(x|z)\\]\n\n\nEn palabras: si conocemos el valor de \\(Z\\), \\(X\\) y \\(Y\\) ya no están asociadas, o si ya condicionamos a z, entonces condicionar adicionalmente a \\(Y\\) no cambia la distribución condicional de \\(X\\). Para ver por qué las dos formas son equivalentes recuerda que cualquier regla de probabilidad general puede condicionarse a cualquier infromación y sigue siendo una regla válida. Como de mostramos que \\(p(x,y) = p(x)p(y)\\) si y sólo si \\(p(y|x) = p(y)\\), podemos obtener una regla válida condicionando todo a \\(Z\\).\nEste concepto en la modelación e interpretación, por ejemplo en el caso de Santa Clara, prevalencia y número de positivos son dependientes. Pero si conocemos el número de infectados, prevalencia y positivos son condicionalmente independientes, y esto es una idea importante este modelo.\nEn nuestro primer ejemplo de la sección anterior, observamos que una vez que sabíamos \\(X\\), la probabilidad de sol, no hay relación entre \\(S_1\\) y \\(S_2\\), aún cuando no es cierto que \\(p(s_1,s_2) = p(s_1)p(s_2)\\).\nPodemos checar esto en las simulaciones, por ejemplo:\n\nset.seed(812)\nsimular_dos(1e5, x = 0.4) |> \n  select(s_1, s_2) |> \n  group_by(s_1, s_2) |> \n  count() |> \n  group_by(s_1) |> \n  mutate(prop_cond = n / sum(n)) |> \nggplot(aes(x = s_2, y = prop_cond, colour = s_1, group = factor(s_1))) +\n  geom_line()\n\n\n\n\nLas condicionales son iguales en cada caso, de modo que \\(S_1\\) y \\(S_2\\) son independientes dada \\(X\\) (prueba con otros valores de \\(X\\))."
  },
  {
    "objectID": "02-modelos-graficos.html#gráficas-dirigidas-acíclicas",
    "href": "02-modelos-graficos.html#gráficas-dirigidas-acíclicas",
    "title": "2  Modelos gráficos probabilísticos",
    "section": "2.5 Gráficas dirigidas acíclicas",
    "text": "2.5 Gráficas dirigidas acíclicas\nPara representar gráficamente la construcción de modelos que hemos considerado, podemos usar las siguiente idea:\n\n\n\n\n\n\nNota\n\n\n\nDecimos que una gráfica dirigida \\(G\\) representa a una conjunta \\(p(x_1,\\ldots, x_p)\\) cuando podemos factorizar\n\\[p(x_1,\\ldots, x_p) = \\prod_{i=1}^p p(x_i | pa(x_i))\\]\ndonde \\(pa(x_i)\\) son los padres del nodo X_i en la gráfica G.\n\n\n\n2.5.0.1 Ejemplo\nConsideramos la siguiente gráfica:\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n  node [shape=plaintext]\n    Ob\n    Fuma\n    EC \n    Tos\n  edge [minlen = 3]\n   Ob -> EC\n   Fuma -> EC\n   Fuma -> Tos\n}\n\", width = 200, height = 50)\n\n\n\n\n\n\nEsta gráfica representa una conjunta \\(p(o,f,c,t)\\) cuando es posible factorizar\n\\[p(ob,f,ec,t) = p(f)p(o)p(ec|o,f)p(t|f),\\]\nde forma que podemos entender el proceso generador de este conjunto de variables como sigue: simulamos primero \\(F\\) y \\(Ob\\), usando el valor de \\(F\\) podemos simular \\(T\\), y usando el valor de \\(F\\) y \\(Ob\\) podemos simular \\(C\\). En este ejemplo podemos pensar que las variables son Obesidad, Fumador, Enfermedad de Corazón y Tos. Nótese que la distribución de Enfermedad de Corazón depende del estado de Obesidad y fumador. La probabilidad de tener tos depende directamente del estado de fumador.\nEl conjunto de independencias condicionales de una conjunta \\(p\\) está fuertemente ligado a la estructura de la gráfica que la representa:\n\n\n\n\n\n\nNota\n\n\n\nUna distribución \\(p\\) es representada por \\(G\\) si y sólo si para cada variable \\(W\\), cuando condicionamos a los padres \\(pa(W)\\) de \\(W\\), \\(W\\) es condicionalmente independiente de todas las variables que no son descendientes o padres de \\(W\\).\n\n\nEs decir, si condicionamos a los padres de una variable, esta variable es condicionalmente independiente del “pasado”, en el sentido del orden de la gráfica. Estas no son las únicas independencias condicionales que están presentes, veremos que para calcular éstas es necesario usar el concepto de d-separación. Antes discutiremos las estructuras básicas que nos interesan estudiar en una gráfica.\n\n\n2.5.1 Independencia condicional, parsimonia y supuestos\nLa independencia condicional es un concepto central para construir modelos probabilísticos, pues nos permite construir modelos parsimoniosos.\n\nEn una factorización dada, cada factor representa un modelo distinto, que puede tener parámetros que definen la relación entre la variable resultante y sus padres.\nSi en nuestro modelo existen independencias condicionales, podemos hacer modelos con menos parámetros, y cada relación es más simple.\n\nEn nuestro ejemplo anterior, si \\(T\\) tuviera más padres en lugar de tener que definir o estimar \\(p(t|f)\\), tendríamos que modelar \\(p(t|o,f,c)\\), que es un modelo más complicado: por ejemplo, puede tener interacciones complicadas y no linealidades más complejas que el modelo \\(f(t|f)\\)\nAdicionalmente, el conjunto de independencias condicionales también nos dice que implicaciones tiene el modelo que estamos considerando. Más adelante veremos cómo:\n\nCalcular todas las independencias condicionales dada nuestra gráfica\nEntender en qué lugares puede haber dependencias y explicar la razón de su existencia, por ejemplo, si la relación es causal o no.\n\nPor ejemplo, cuando consideramos las dos colecciones de volados (\\(S_1\\) y \\(S_2\\)) dada una misma moneda (\\(X\\)), podemos entender por qué \\(S_1\\) y \\(S_2\\) no son independientes: saber el resultado de \\(S_1\\), por ejemplo, nos da información acerca la \\(X\\), lo cual a su vez nos da información de \\(S_2\\). La información fluye a lo largo de la gráfica correspondiente dado el supuesto que hicimos que las dos series de volados se hacen con una moneda."
  },
  {
    "objectID": "02-modelos-graficos.html#estructuras-básicas-en-dags",
    "href": "02-modelos-graficos.html#estructuras-básicas-en-dags",
    "title": "2  Modelos gráficos probabilísticos",
    "section": "2.6 Estructuras básicas en DAGs",
    "text": "2.6 Estructuras básicas en DAGs\nVeremos que para razonar acerca de las asociaciones e independencias que pueden aparecer en una conjunta, podemos examinar la gráfica que la represente, o dicho de otra manera, entender bajo qué condiciones puede propagarse información de un nodo a otro.\nConsideremos entonces tres variables \\(X\\), \\(Y\\) y \\(Z\\). Las tres estructuras que tenemos que entender en primer lugar pueden verse también como métodos de razonamiento lógico derivados de las leyes de probabilidad:\n\n2.6.1 Cadenas o mediación\nEn este caso tenemos:\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2, rankdir=LR]\n  node [shape=plaintext]\n    X\n    Y\n    Z\n  edge [minlen = 3]\n   X -> Z\n   Z -> Y\n}\n\", width = 150, height = 20)\n\n\n\n\n\n\nEn este caso,\n\nExiste asociación entre \\(X\\) y \\(Y\\), pero no existe relación directa entre ellas.\nSi condicionamos a un valor de \\(Z\\), \\(X\\) y \\(Y\\) son condicionalmente independientes.\n\nPodemos pensar en \\(Z\\) como un mediador del efecto de \\(X\\) sobre \\(Y\\). Si no permitimos que \\(Z\\) varíe, entonces la información de \\(X\\) no fluye a \\(Y\\).\nPor ejemplo, si \\(X\\) tomar o no una medicina para el dolor de cabeza, \\(Z\\) es dolor de cabeza y \\(Y\\) es bienestar general, \\(X\\) y \\(Y\\) están relacionadas. Sin embargo, si condicionamos a un valor fijo de dolor de cabeza, no hay relación entre tomar la medicina y bienestar general.\nEn términos de factorización, podemos checar la independencia condicional: como \\(p(x,y,z) = p(x)p(z|x)p(y|z)\\), entonces\n\\[p(x, y | z) = p(x,y,z) / p(z) = (p(x)(z|x)) (p(y|z) / p(z))\\] y vemos que el lado izquierdo se factoriza en una parte que sólo involucra a \\(x\\) y \\(z\\) y otro factor que sólo tiene a \\(y\\) y \\(z\\): no hay términos que incluyan conjuntamente a \\(x\\), \\(y\\) y \\(z\\). Podemos de cualquier forma continuar notando\n\\[p(x)p(z|x)/p(z) = p(x,z)/p(z) = p(x | z)\\] de modo que\n\\[p(x, y | z) = p(x|z) p(y|z) \\]\nY mostramos un ejemplo simulado:\n\nrbern <- function(n, prob){\n  rbinom(n, 1, prob = prob)\n} \nsimular_mediador <- function(n = 10){\n  x <- rbern(n, p = 0.5) |> as.numeric()\n  z <- rbern(n, p = x * 0.8 + (1 - x) * 0.3)\n  y <- rbinom(n, 2, z * 0.7 + (1 - z) * 0.5)\n  tibble(x, z, y)\n}\nsims_mediador <- simular_mediador(50000)\n\n\\(X\\) y \\(Y\\) son dependientes:\n\nsims_mediador |> select(x, y) |> \n  count(x, y) |> \n  group_by(x) |> \n  mutate(p_cond = n / sum(n)) |>\n  select(x, y, p_cond) |> \nggplot(aes(x = y, y = p_cond, fill = factor(x))) +\n  geom_col(position = \"dodge\") +\n  labs(subtitle = \"Condicional de Y dada X\")\n\n\n\n\nSin embargo, si condicionamos a \\(Z\\), que puede tomar los valores 0 o 1:\n\nsims_mediador |> \n  count(x, y, z) |> \n  group_by(x, z) |> \n  mutate(p_cond = n / sum(n)) |>\n  select(x, y, z, p_cond) |> \nggplot(aes(x = y, y = p_cond, fill = factor(x))) +\n  geom_col(position = \"dodge\") + facet_wrap(~ z) +\n  labs(subtitle = \"Condicional de Y dada X y Z\")\n\n\n\n\nY vemos que la condicional de \\(Y\\) dada \\(Z\\) y \\(X\\) sólo depende de \\(Z\\). Una consecuencia es por ejemplo que la correlación debe ser cero:\n\ncor(sims_mediador |> filter(z == 1) |> select(x,y)) |> round(3)\n\n       x      y\nx  1.000 -0.004\ny -0.004  1.000\n\ncor(sims_mediador |> filter(z == 0) |> select(x,y)) |> round(3)\n\n      x     y\nx 1.000 0.004\ny 0.004 1.000\n\n\nPodemos también hacer un ejemplo continuo:\n\nsimular_mediador <- function(n = 10){\n  x <- rnorm(n, 100, 10)\n  prob <- 1 / (1 + exp(-(x - 100)/5))\n  z <- rbern(n, p = prob)\n  y <- rnorm(n, 100 + 30 * z, 15)\n  tibble(x, z, y)\n}\nsims_mediador <- simular_mediador(2000)\n\n\\(X\\) y \\(Y\\) son dependientes (por ejemplo si vemos la media condicional de \\(Y\\) dado \\(X\\):\n\nggplot(sims_mediador, aes(x = x, y = y, colour = z)) + geom_point() +\n  geom_smooth(span = 1)\n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\nWarning: The following aesthetics were dropped during statistical transformation: colour\nℹ This can happen when ggplot fails to infer the correct grouping structure in\n  the data.\nℹ Did you forget to specify a `group` aesthetic or to convert a numerical\n  variable into a factor?\n\n\n\n\n\nSi condicionamos a \\(Z\\), no hay dependencia entre \\(X\\) y \\(Y\\)\n\nggplot(sims_mediador, aes(x = x, y = y, colour = z, group = z)) + \n  geom_point() +\n  geom_smooth(span = 2)\n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\n\n\n\n\n\n2.6.2 Bifurcaciones o causa común\nEn el siguiente ejemplo, llamamos a \\(Z\\) una causa que es común a \\(X\\) y \\(Y\\).\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n  node [shape=plaintext]\n    X\n    Y\n    Z\n  edge [minlen = 3]\n   Z -> X\n   Z -> Y\n}\n\", width = 200, height = 50)\n\n\n\n\n\n\nEn este caso,\n\n\\(X\\) y \\(Y\\) tienen asociación\nSi condicionamos a \\(Z\\), entonces \\(X\\) y \\(Y\\) son condicionalmente independientes.\n\nEste tipo de estructura también se llama bifurcación, o decimos que \\(Z\\) es un confusor en esta gráfica. Variación en \\(Z\\) produce variación conjunta de \\(X\\) y \\(Y\\).\nPor ejemplo, podríamos encontrar que el uso de aspirina \\(X\\) está asociado a una mortalidad más alta \\(Y\\). Una causa común es enfermedad grave que produce dolor (\\(Z\\)). Sin embargo, si condicionamos a personas sanas, veríamos que no hay relación entre uso de aspirina y mortalidad, igualmente veríamos que entre las personas enfermas el uso de aspirina no les ayuda a vivir más tiempo.\nEn este caso, tenemos:\n\\[p(x, y, z) =  p(z)p(x|z)p(y|z)\\] Y como el lado izquierdo es igual (en general) a \\(p(x,y|z)p(z)\\), obtenemos la independiencia condicional de \\(X\\) y \\(Y\\) dado \\(Z\\).\n\nrbern <- function(n, prob){\n  rbinom(n, 1, prob = prob)\n} \nsimular_confusor <- function(n = 10){\n  z <- rbern(n, p = 0.5) |> as.numeric()\n  x <- rbern(n, p = z * 0.3 + (1 - z) * 0.8)\n  y <- rbinom(n, 4, z * 0.9 + (1 - z) * 0.3)\n  tibble(x, z, y)\n}\nsims_confusor <- simular_confusor(50000)\n\n\\(X\\) y \\(Y\\) son dependientes:\n\nsims_confusor |> select(x, y) |> \n  count(x, y) |> \n  group_by(x) |> \n  mutate(p_cond = n / sum(n)) |>\n  select(x, y, p_cond) |> \nggplot(aes(x = y, y = p_cond, fill = factor(x))) +\n  geom_col(position = \"dodge\") +\n  labs(subtitle = \"Condicional de Y dada X\")\n\n\n\n\nSin embargo, si condicionamos a \\(Z\\), que puede tomar los valores 0 o 1:\n\nsims_confusor |> \n  count(x, y, z) |> \n  group_by(x, z) |> \n  mutate(p_cond = n / sum(n)) |>\n  select(x, y, z, p_cond) |> \nggplot(aes(x = y, y = p_cond, fill = factor(x))) +\n  geom_col(position = \"dodge\") + facet_wrap(~ z) +\n  labs(subtitle = \"Condicional de Y dada X y Z\")\n\n\n\n\nY vemos que la condicional de \\(Y\\) dada \\(Z\\) y \\(X\\) sólo depende de \\(Z\\). Una consecuencia es por ejemplo que la correlación debe ser cero:\n\ncor(sims_confusor |> filter(z == 1) |> select(x,y)) |> round(3)\n\n      x     y\nx 1.000 0.008\ny 0.008 1.000\n\ncor(sims_confusor |> filter(z == 0) |> select(x,y)) |> round(3)\n\n      x     y\nx 1.000 0.015\ny 0.015 1.000\n\n\n\nsimular_bifurcacion <- function(n = 10){\n  z <- rbern(n, p = 0.5)\n  x <- rnorm(n, 100 + 20 * z, 15)\n  y <- rnorm(n, 100 + 30 * z, 20)\n  tibble(x, z, y)\n}\nsims_bifurcacion <- simular_bifurcacion(5000)\n\n\\(X\\) y \\(Y\\) son dependientes (por ejemplo si vemos la media condicional de \\(Y\\) dado \\(X\\):\n\nggplot(sims_bifurcacion, aes(x = x, y = y, colour = z)) + \n  geom_point(alpha = 0.2) +\n  geom_smooth(span = 1)\n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\nWarning: The following aesthetics were dropped during statistical transformation: colour\nℹ This can happen when ggplot fails to infer the correct grouping structure in\n  the data.\nℹ Did you forget to specify a `group` aesthetic or to convert a numerical\n  variable into a factor?\n\n\n\n\n\nSi condicionamos a \\(Z\\), no hay dependencia entre \\(X\\) y \\(Y\\)\n\nggplot(sims_bifurcacion, aes(x = x, y = y, colour = z, group = z)) + \n  geom_point(alpha = 0.2) +\n  geom_smooth(span = 2)\n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\n\n\n\n\n\n2.6.3 Colisionador o causas alternativas\nEn este caso, a \\(Z\\) también le llamamos un colisionador. Este es el caso que puede ser más difícil de entender en un principio.\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n  node [shape=plaintext]\n    X\n    Y\n    Z\n  edge [minlen = 3]\n   X -> Z\n   Y -> Z\n}\n\", width = 200, height = 50)\n\n\n\n\n\n\n\nEn este caso \\(X\\) y \\(Y\\) son independientes\nSin embargo, si condicionamos a \\(Z\\) entonces \\(X\\) y \\(Y\\) están asociados.\n\nPor ejemplo, si observamos que el pasto está mojado, entonces saber que no llovió implica que probablemente se encendieron los aspersores.\nComo la conjunta se factoriza como:\n\\[p(x,y,z) = p(x)p(y)p(z|x,y)\\] podemos integrar sobre \\(Z\\):\n\\[p(x,y) = \\int p(x,y,z)dz = p(x)p(y)\\int p(z|x,y)\\, dz\\] pero \\(p(z|x,y)\\) integra uno porque es una densidad, de forma que \\(x\\) y \\(y\\) son independientes.\nY mostramos un ejemplo simulado:\n\nsimular_colisionador <- function(n = 10){\n  x <- rbern(n, 0.5) \n  y <- rbinom(n, 2, 0.7)\n  z <- rbern(n, p = 0.1 + 0.7 * x * (y > 1)) \n  tibble(x, z, y)\n}\nsims_colisionador <- simular_colisionador(50000)\n\n\\(X\\) y \\(Y\\) son independientes:\n\nsims_colisionador|> select(x, y) |> \n  count(x, y) |> \n  group_by(x) |> \n  mutate(p_cond = n / sum(n)) |>\n  select(x, y, p_cond) |> \nggplot(aes(x = y, y = p_cond, fill = factor(x))) +\n  geom_col(position = \"dodge\") +\n  labs(subtitle = \"Condicional de Y dada X\")\n\n\n\n\nSin embargo, si condicionamos a \\(Z\\), que puede tomar los valores 0 o 1:\n\nsims_colisionador |> \n  count(x, y, z) |> \n  group_by(x, z) |> \n  mutate(p_cond = n / sum(n)) |>\n  select(x, y, z, p_cond) |> \nggplot(aes(x = y, y = p_cond, fill = factor(x))) +\n  geom_col(position = \"dodge\") + facet_wrap(~ z) +\n  labs(subtitle = \"Condicional de Y dada X y Z\")\n\n\n\n\nY vemos que la condicional de \\(Y\\) dada \\(Z\\) y \\(X\\) depende de \\(X\\) y de \\(Z\\).\nLas correlaciones condicionales, por ejemplo, no son cero:\n\nprint(\"Dado Z = 0\")\n\n[1] \"Dado Z = 0\"\n\ncor(sims_colisionador |> filter(z == 0) |> select(x,y)) |> round(3)\n\n       x      y\nx  1.000 -0.287\ny -0.287  1.000\n\nprint(\"Dado Z = 1\")\n\n[1] \"Dado Z = 1\"\n\ncor(sims_colisionador |> filter(z == 1) |> select(x,y)) |> round(3)\n\n      x     y\nx 1.000 0.373\ny 0.373 1.000\n\n\nOtro ejemplo con variables continuas:\n\nsimular_colisionador_2 <- function(n = 10){\n  x <- rnorm(n, 100, 20) \n  y <- rnorm(n, 100, 20)\n  z <- rbern(n, p = 0.92 * ((x + y) > 220) + 0.05) \n  tibble(x, z, y)\n}\nsims_colisionador <- simular_colisionador_2(1000)\n\n\\(X\\) y \\(Y\\) son independientes:\n\nggplot(sims_colisionador, aes(x = x, y = y)) + geom_point()\n\n\n\n\nSin embargo, si condicionamos a un valor de \\(Z\\), \\(X\\) y \\(Y\\) ya no son independientes:\n\nggplot(sims_colisionador, aes(x = x, y = y, group = z, colour = factor(z))) + \n  geom_point() + geom_smooth(method = \"lm\", se = FALSE) \n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nY vemos que condicional a \\(Z\\), \\(X\\) y \\(Y\\) no son dependientes.\n\n\n2.6.4 Razonamiento de descendientes de efecto común\nCondicionar a un descendiente de un colisionador también produce dependencias condicionales:\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n  node [shape=plaintext]\n    X\n    Y\n    Z\n    A\n  edge [minlen = 3]\n   X -> Z\n   Y -> Z\n   Z -> A\n}\n\", width = 200, height = 50)\n\n\n\n\n\n\nEn este caso,\n\n\\(X\\) y \\(Y\\) son independientes\n\\(X\\) y \\(Y\\) son dependientes si condicionamos a \\(A\\).\n\nDependiendo de la naturaleza de la asociación entre el colisionador \\(Z\\) y su descendiente \\(A\\), esta dependencia puede ser más fuerte o más débil.\nPor ejemplo, en nuestro ejemplo donde el pasto mojado es un colisionador entre cuánta agua dieron los aspersores y cuánta lluvia cayó, un descendiente del pasto mojado es el estado de las plantas del jardín. Aunque los aspersores trabajan independientemente de la lluvia, si observamos que las plantas se secaron entonces lluvia y aspersores están correlacionados: por ejemplo, si noto que los aspersores están descompuestos, entonces concluimos que no hubo lluvia.\n\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n  node [shape=plaintext]\n    X [label = lluvia]\n    Y [label = aspersores]\n    Z [label = humedad]\n    A [label = plantas]\n  edge [minlen = 3]\n   X -> Z\n   Y -> Z\n   Z -> A\n}\n\", width = 200, height = 50)\n\n\n\n\n\n\n\n2.6.5 Ejemplo: dependencias de colisionador\nVerificamos que en nuestro modelo de Santa Clara, efectivamente nuestro modelo no implica ninguna dependencia no condicional entre sensibilidad de la prueba y prevalencia. Eso debería ser claro de la simulación, pero de todas formas lo checamos\n\nlibrary(cmdstanr)\nmod_sc <- cmdstan_model(\"../src/sclara.stan\")\nprint(mod_sc)\n\ndata {\n  int<lower=0> N;\n  int<lower=0> n;\n  int<lower=0> kit_pos;\n  int<lower=0> n_kit_pos;\n  int<lower=0> kit_neg;\n  int<lower=0> n_kit_neg;\n}\n\nparameters {\n  real<lower=0, upper=1> p; //seroprevalencia\n  real<lower=0, upper=1> sens; //sensibilidad\n  real<lower=0, upper=1> esp; //especificidad\n}\n\ntransformed parameters {\n  real<lower=0, upper=1> prob_pos;\n\n  prob_pos = p * sens + (1 - p) * (1 - esp);\n\n}\nmodel {\n  // modelo de número de positivos\n  n ~ binomial(N, prob_pos);\n  // modelos para resultados del kit\n  kit_pos ~ binomial(n_kit_pos, sens);\n  kit_neg ~ binomial(n_kit_neg, esp);\n  // iniciales para cantidades no medidas\n  p ~ beta(1.0, 10.0);\n  sens ~ beta(2.0, 1.0);\n  esp ~ beta(2.0, 1.0);\n}\n\n\nEn este caso, no pondremos información acerca de positivos en la prueba:\n\ndatos_lista <- list(N = 0, n = 0,\n kit_pos = 103, n_kit_pos = 122,\n kit_neg = 399, n_kit_neg = 401)\najuste <- mod_sc$sample(data = datos_lista, refresh = 1000, iter_sampling = 400)\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 Iteration:    1 / 1400 [  0%]  (Warmup) \nChain 1 Iteration: 1000 / 1400 [ 71%]  (Warmup) \nChain 1 Iteration: 1001 / 1400 [ 71%]  (Sampling) \nChain 1 Iteration: 1400 / 1400 [100%]  (Sampling) \nChain 1 finished in 0.0 seconds.\nChain 2 Iteration:    1 / 1400 [  0%]  (Warmup) \nChain 2 Iteration: 1000 / 1400 [ 71%]  (Warmup) \nChain 2 Iteration: 1001 / 1400 [ 71%]  (Sampling) \nChain 2 Iteration: 1400 / 1400 [100%]  (Sampling) \nChain 2 finished in 0.0 seconds.\nChain 3 Iteration:    1 / 1400 [  0%]  (Warmup) \nChain 3 Iteration: 1000 / 1400 [ 71%]  (Warmup) \nChain 3 Iteration: 1001 / 1400 [ 71%]  (Sampling) \nChain 3 Iteration: 1400 / 1400 [100%]  (Sampling) \nChain 3 finished in 0.0 seconds.\nChain 4 Iteration:    1 / 1400 [  0%]  (Warmup) \nChain 4 Iteration: 1000 / 1400 [ 71%]  (Warmup) \nChain 4 Iteration: 1001 / 1400 [ 71%]  (Sampling) \nChain 4 Iteration: 1400 / 1400 [100%]  (Sampling) \nChain 4 finished in 0.0 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.0 seconds.\nTotal execution time: 0.5 seconds.\n\nsims <- ajuste$draws(c(\"p\", \"sens\", \"esp\"), format = \"df\")\nresumen <- ajuste$summary(c(\"p\"))\n\n\nggplot(sims, aes(x = p, y = sens)) + geom_point() +\n  scale_x_sqrt()\n\n\n\n\nNo vemos ninguna asocación entre estas dos variables. Podemos hacer algunas permutaciones al azar para checar que nuestra interpetación de la gráfica es correcta:\n\nlibrary(nullabor)\nggplot(lineup(null_permute(\"p\"), sims, n = 5), aes(x = p, y = sens)) +\n  geom_point(alpha = 0.3) + facet_wrap(~ .sample) +\n  scale_x_sqrt()\n\ndecrypt(\"0lta Uo1o uQ OhHu1uhQ DD\")\n\n\n\n\n\nDonde no notamos ninguna diferencia sistemática después de hacer permutaciones.\nSin embargo, al condicionar al valor de Positivos, creamos una relación que no podemos interpretar como casual. En este caso particular supondremos prácticamente fija la sensibilidad para ver solamente lo que sucede en el colisionador de especificidad y número de positivos (la especificidad en este ejemplo es más crítica):\n\ndatos_lista <- list(N = 3300, n = 50,\n kit_pos = 1030000, n_kit_pos = 1220000, # números grandes para que esté practicamente\n# fija la sensibilidad\n kit_neg = 399, n_kit_neg = 401)\najuste <- mod_sc$sample(data = datos_lista, refresh = 1000, iter_sampling = 400)\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 Iteration:    1 / 1400 [  0%]  (Warmup) \nChain 1 Iteration: 1000 / 1400 [ 71%]  (Warmup) \nChain 1 Iteration: 1001 / 1400 [ 71%]  (Sampling) \nChain 1 Iteration: 1400 / 1400 [100%]  (Sampling) \nChain 1 finished in 0.0 seconds.\nChain 2 Iteration:    1 / 1400 [  0%]  (Warmup) \nChain 2 Iteration: 1000 / 1400 [ 71%]  (Warmup) \nChain 2 Iteration: 1001 / 1400 [ 71%]  (Sampling) \nChain 2 Iteration: 1400 / 1400 [100%]  (Sampling) \nChain 2 finished in 0.0 seconds.\nChain 3 Iteration:    1 / 1400 [  0%]  (Warmup) \nChain 3 Iteration: 1000 / 1400 [ 71%]  (Warmup) \nChain 3 Iteration: 1001 / 1400 [ 71%]  (Sampling) \nChain 3 Iteration: 1400 / 1400 [100%]  (Sampling) \nChain 3 finished in 0.0 seconds.\nChain 4 Iteration:    1 / 1400 [  0%]  (Warmup) \nChain 4 Iteration: 1000 / 1400 [ 71%]  (Warmup) \nChain 4 Iteration: 1001 / 1400 [ 71%]  (Sampling) \nChain 4 Iteration: 1400 / 1400 [100%]  (Sampling) \nChain 4 finished in 0.0 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.0 seconds.\nTotal execution time: 0.5 seconds.\n\nsims <- ajuste$draws(c(\"p\", \"sens\", \"esp\"), format = \"df\")\nresumen <- ajuste$summary(c(\"p\"))\n\n\nggplot(sims, aes(x = p, y = esp)) + geom_point() \n\n\n\n\nY vemos que condiconando al colisionador, obtenemos una relación fuerte entre prevalencia y especificidad de la prueba: necesitaríamos más datos de especificidad para obtener una estimación útil.\n\nLa razón de que la especificidad es más importante en este ejemplo es que la prevalencia es muy baja al momento del estudio, y los falsos positivos pueden introducir más error en la estimación\nTambién repetimos nótese que el análisis correcto de estos datos no se puede hacer con intervalos separados para cada cantidad, sino que debe examinarse la conjunta de estos parámetros.\n\n\nCon estas tres estructuras elementales podemos entender de manera abstracta la existencia o no de asociaciones entre nodos de cualquier gráfica dirigida."
  },
  {
    "objectID": "02-modelos-graficos.html#d-separación",
    "href": "02-modelos-graficos.html#d-separación",
    "title": "2  Modelos gráficos probabilísticos",
    "section": "2.7 d-separación",
    "text": "2.7 d-separación\nAhora buscaremos describir todas las posibles independendencias condicionales y no condicionales que pueden aparecer en una gráfica, para entender cómo aparecen asociaciones entre variables de nuestro modelo, y dependiendo del tipo de condicionamiento que hacemos.\nVeremos que el criterio es algorítmico. Más adelante discutiremos cuáles de estas asociaciones se deben a efectos causales y cuáles no, y esto nos permitirá establecer estrategias de condicionamiento (qué variables controlar o no), recolección de datos para construir los estimadores correctos de los efectos causales de interés.\n\n\n\n\n\n\nd-separación: Caminos activos y bloqueados\n\n\n\n\nUn camino entre \\(X\\) y \\(Y\\) es una sucesión de aristas que conecta a \\(X\\) con \\(Y\\) (sin importar) la dirección de las aristas.\n\nAhora supongamos que \\(Z = \\{Z_1,Z_2,\\ldots, Z_q\\}\\) son una colección de nodos. Decimos que un camino \\(p\\) entre \\(X\\) y \\(Y\\) está activo condicional a los nodos en \\(Z\\) cuando:\n\nSiempre que hay un colisionador \\(X_i\\to U\\gets X_j\\) en el camino \\(p\\), entonces \\(U\\) o alguno de sus descendientes está en \\(Z\\)\nNingún otro nodo a lo largo de \\(p\\) está en \\(Z\\).\n\nEn caso contrario, decimos que el camino \\(p\\) está bloqueado.\nSi \\(Z\\) bloquea todos los caminos posibles entre \\(X\\) y \\(Y\\), decimos que \\(X\\) y \\(Y\\) están \\(d\\)-separados condicionalmente a \\(Z\\), o \\(d\\)-separados por \\(Z\\).\n\n\nSegún la discusión que tuvimos arriba de los modos de razonamiento en gráficas de modelos probabilísticos, el siguiente teorema no es sorpresa:\n\n\n\n\n\n\nCriterio de d-separación\n\n\n\nEn una DAG \\(G\\):\n\nSi dos variables están d-separadas por las variables \\(Z\\), entonces \\(X\\) y \\(Y\\) son condicionalmente independientes dadas las variables en \\(Z\\) para cualquier conjunta representada por \\(G\\).\nSi dos variables no están d-separadas por \\(Z\\), entonces existen conjuntas representadas por \\(G\\) tales que \\(X\\) y \\(Y\\) no tienen dependencia condicional dado \\(Z\\).\n\n\n\nNota 1: nótese que este teorema nos da una manera abstracta de razonar acerca de la asociación en un modelo gráfico: no es necesario saber la forma particular de las condicionales para utilizarlo.\nNota 2: Vale la pena mencionar que el segundo inciso en general es una implicación más fuerte: cuando no hay \\(d\\)-separación, existe algún tipo de dependencia casi seguro (en el sentido probabilístico de posible conjuntas).\nNota 3: Las independencias condicionales también pueden ser útiles para checar los supuestos de nuestro modelo: si encontramos asociaciones fuertes (condicionales o no) entre variables que nuestra estructura implica independencia condicional, entonces puede ser que nuestra estructura causal requiera revisión. Qué tanto podemos probar esto depende del tamaño de los datos que tengamos y de el tipo de condicionamiento que estamos haciendo.\nFinalmente (ver por ejemplo Koller y Friedman (2009), p 75), existe un algoritmo eficiente para encontrar todas las posibles independencias condicionales implicadas por una gráfica:\n\n\n\n\n\n\nCálculo de d-separación\n\n\n\nExiste un algoritmo de complejidad lineal en el tamaño de la gráfica para encontrar todos los nodos con caminos activos a un nodo \\(X\\) condicional a las variables \\(A\\).\n\n\nVer por ejemplo el sitio dagitty.net, donde podemos poner nuestra gráfica y enlistar todas los supuestos de independencia condicional implicados por un modelo.\n\nEjemplo\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n  node [shape=plaintext]\n    Z \n    W \n    X\n    Y \n    U\n  edge [minlen = 3]\n    Z -> W\n    X -> W\n    X -> Y\n    W -> U\n    S -> Y\n    UZ -> Z\n    V -> Z\n    V -> S\n}\n\")\n\n\n\n\n\n\nConsideremos la relación entre Z y Y. Primero vemos que hay dos caminos entre \\(Z\\) y \\(Y\\), que son \\(p_1:X\\gets V \\to S\\) y \\(p_2: Z\\to W \\gets X \\to Y\\)\n\nEn primer lugar, ¿son independientes si no condicionamos a ninguna variable? No, pues el camino \\(p_1\\) es activo, e induce correlación.\n¿Son condicionalmente independientes si condicionamos a \\(V\\)? En este caso, condicionar a \\(V\\) bloquea el camino \\(p_1\\). El camino \\(p_2\\) está bloqueado por el colisionador \\(W\\), así que todos los caminos están bloqueados si condicionamos a \\(V\\).\nSi condicionamos a \\(W y V\\), ¿son independientes? No. El camino \\(p_1\\) está bloqueado, así que ese no induce asociación. Sin embargo, al condicionar al colisionador \\(W\\) activamos el camino \\(p_2\\).\nAhora supongamos que tenemos datos condicionales a algún valor de \\(W\\) solamente. Condicionando a \\(V\\) bloqueamos el camino \\(p_1\\), pero el camino \\(p_2\\) está activo. ¿Qué pasaría si condicionamos adicionalmente a \\(X\\)? En este caso, el conjunto de condicionamiento es \\(\\{V, W, X\\}\\). El camino \\(p_2\\) está bloqueado. Y aunque condicionamos al colisionador, \\(X\\) bloque el camino. Por lo tanto \\(Z\\) y \\(Y\\) son condicionalmente independientes dado \\(\\{V, W, X\\}\\).\n\n\n\n2.7.1 Ejercicio\nRepite el ejemplo anterior para la siguiente gráfica. Analiza que pasa si condicionamos o no a valores de \\(T\\), y qué pasa si adicionalmente condicionamos a \\(W\\), y luego repite los pasos del ejemplo anterior.\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n  node [shape=plaintext]\n    Z \n    W \n    X\n    Y \n    U\n    T\n  edge [minlen = 3]\n    T -> Z\n    T -> Y\n    Z -> W\n    X -> W\n    X -> Y\n    W -> U\n    S -> Y\n    UZ -> Z\n}\n\")"
  },
  {
    "objectID": "02-modelos-graficos.html#relación-con-inferencia-causal",
    "href": "02-modelos-graficos.html#relación-con-inferencia-causal",
    "title": "2  Modelos gráficos probabilísticos",
    "section": "2.8 Relación con inferencia causal",
    "text": "2.8 Relación con inferencia causal\nSi el DAG que consideramos representa relaciones causales (mecanísticas) entre las variables, es decir, qué variable “escucha” a qué otras para decidir su valor, entonces podemos hacer una definición adicional\n\n\n\n\n\n\nCaminos causales\n\n\n\nEn un DAG, los caminos causales entre \\(X\\) y \\(Y\\) son de la forma \\(X\\to U_1\\to U_2 \\to \\cdots U_j \\to Y\\). Puede haber varios de ellos en un diagrama dado, y cada uno representa un mecanismo en que cambios en \\(X\\) producen cambios en \\(Y\\)\nSi nos interesa el efecto total de \\(X\\) sobre \\(Y\\),\n\nQueremos que todos los caminos causales de \\(X\\) a \\(Y\\) estén activos,\nQueremos condicionar para que todos los caminos no causales estén bloqueados, en particular, no queremos condicionar a colisionadores o sus descendientes que introduzcan relaciones no causales, y queremos bloquear caminos no casuales creados por bifurcaciones.\n\n\n\n\n\n\n\nKoller, D., y N. Friedman. 2009. Probabilistic Graphical Models: Principles and Techniques. MIT Press."
  },
  {
    "objectID": "03-modelos-causales.html#intervenciones",
    "href": "03-modelos-causales.html#intervenciones",
    "title": "3  Modelos causales e inferencia",
    "section": "3.1 Intervenciones",
    "text": "3.1 Intervenciones\n\n\nCódigo\nlibrary(tidyverse)\nlibrary(kableExtra)\nlibrary(DiagrammeR)\nggplot2::theme_set(ggplot2::theme_light())\ninv_logit <- \\(x) 1 / (1 + exp(-x)) \n\n\nDesde el punto de vista de Pearl, nuestro objeto principal de interés es la distribución condicional de la respuesta dada una manipulación, que define como \\[p(y | do(x))\\] Esto significa: ¿cómo se distribuye la \\(Y\\) dado que intervenimos en la población completa (aunque podemos también considerar subpoblaciones más adelante) para poner en \\(X=x\\)?. En primer lugar, notemos que esto no es lo mismo que la distribución\n\\[p(y|x)\\] que podemos estimar directamente de los datos.\n\nEjemplo (Pearl)\nSupongamos que tenemos el siguiente modelo del diagrama causal:\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n  node [shape=plaintext]\n\n  edge [minlen = 3]\n   U_t -> T\n   T -> A\n   T -> Z\n   U_a -> A\n   U_z -> Z\n   \n   \n}\n\")\n\n\n\n\n\n\ndonde \\(T\\) es la temperatura, \\(A\\) son las unidades de agua embotellada vendida y \\(Z\\) es la actividad de los mosquitos (medido con muestreo, por ejemplo). Mostramos también otras variables causales que pueden afectar a las variables de interés (muchas veces omitimos estas variables que solo afectan a una variable de interés), pero que no tienen efecto sobre otras variables del diagrama.\nNo interesa contestar la pregunta: ¿qué tanto influyen las ventas de agua embotellada en la actividad de los mosquitos? Del diagrama, sabemos que no hay ningún camino causal de \\(Z\\) a \\(A\\), por lo que nuestra respuesta debería ser igual a 0.\nSin embargo, sabemos que estas dos variables están asociadas (por el análisis de DAGs), de manera que describir cómo cambia \\(p(z|a)\\) cuando condicionamos a distintos valores de \\(a\\) no responde nuestra pregunta. La distribución \\(p(z|do(a))\\) nos dice cómo se distribuye \\(Z\\) cuando manipulamos \\(a\\) artificialmente. Por ejemplo, si cerramos todas las tiendas un día haciendo \\(do(a=0)\\), veríamos que esta variable no tiene efecto sobre la actividad de mosquitos, por ejemplo comparado con \\(do(a = 10000)\\).\nIlustramos la diferencia entre \\(p(y|x)\\) y \\(p(y|do(x))\\) simulando del ejemplo anterior. Supondremos que sólo consideramos un día del año a lo largo de varios años, para no modelar el comportamiento cíclo de la temperatura:\n\nsimular_t <- function(n = 10, dia = 150){\n  # simular un año, alrededor del día 160 (en junio)\n  t_maxima <- rnorm(n, 28, 2)\n  mosquitos <- rpois(n, 250 + 10 * (t_maxima - 28))\n  a_unidades <- rnorm(n, 20000 + 2000 * (t_maxima -  28), 2000)\n  tibble(t_maxima, a_unidades, mosquitos)\n}\nset.seed(128)\nsimular_dias <- simular_t(50)\n\nSi simulamos, vemos que \\(mosquitos\\) y \\(unidades\\) son dependientes, pues tenemos un camino abierto dado por la bifurcación en temperatura:\n\nggplot(simular_dias, aes(x = a_unidades, y = mosquitos)) + geom_point() +\n  geom_smooth(method = \"loess\", method.args = list(degree = 1)) +\n  xlab(\"Ventas de agua embotellada\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nSabemos que esta asociación no es causal, pues no hay caminos causales entre estas variables dos variables, pero que hay una dependencia debido a la bifurcación en \\(T\\). La gráfica muestra que la media condicional \\(E[M|A=a]\\) depende fuertemente de \\(a\\), lo que quiere decir que \\(p(m|a)\\) depende de \\(a\\) fuertemente."
  },
  {
    "objectID": "03-modelos-causales.html#ejemplo-una-intervención-simple",
    "href": "03-modelos-causales.html#ejemplo-una-intervención-simple",
    "title": "3  Modelos causales e inferencia",
    "section": "3.2 Ejemplo: una intervención simple",
    "text": "3.2 Ejemplo: una intervención simple\nEn este caso, nos interesaría saber qué sucede si alteramos artificalmente el número de botellas de agua vendidas (puedes imaginar distintas maneras de hacer esto).\nCuando hacemos esto, quitamos las aristas que van hacia \\(A\\), pues \\(A\\) ya no está determinado por el proceso generador de datos. Tenemos entonces la nueva gráfica:\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n  node [shape=plaintext]\n   A\n  edge [minlen = 3]\n   U_t -> T\n   T -> Z\n   U_m -> Z\n{ rank = same; A; Z }\n}\n\")\n\n\n\n\n\n\nEn esta nueva gráfica, \\(A\\) y \\(Z\\) son independientes, que es la respuesta correcta. Como cambiamos la gráfica, su proceso generador es diferente al original de los datos observados. Sin embargo, en este ejemplo puedes ver por qué es claro que el cambio que hicimos (manipular \\(A\\) en lugar de que esté determinado por su proceso generador original) no cambia el modelo de \\(Z\\), de manera que podemos simular de nuestro nuevo proceso generador donde manipulamos \\(A\\):\n\nsimular_cirugia <- function(n = 10, a_unidades = a_unidades){\n  # simular un año, alrededor del día 160 (en junio)\n  t_maxima <- rnorm(n, 28, 2)\n  #### cirugía #########\n  # ahora a_unidades es fijado por nosotros:\n  # a_unidades <- rnorm(n, 20000 + 2000 * (t_maxima -  28), 2000)\n  a_unidades <- a_unidades\n  ######################\n  mosquitos <- rpois(n, 250 + 10 * (t_maxima - 28))\n  tibble(t_maxima, a_unidades, mosquitos)\n}\n\nY ahora simulamos y graficamos \\(p(z|do(a))\\) para distintos valores de \\(u\\):\n\nset.seed(128)\nsimular_dias_2 <- map_df(seq(10000, 30000, 1000),\n  \\(u) simular_cirugia(50, a_unidades = u))\n\n\nggplot(simular_dias_2, aes(x = a_unidades, y = mosquitos)) +\n  geom_point() + geom_smooth()\n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\n\n\n\ny vemos, como esperaríamos, que no hay relación entre unidades de agua embotellada y tasa de crimen."
  },
  {
    "objectID": "03-modelos-causales.html#cálculo-do-de-pearl",
    "href": "03-modelos-causales.html#cálculo-do-de-pearl",
    "title": "3  Modelos causales e inferencia",
    "section": "3.3 Cálculo-do de Pearl",
    "text": "3.3 Cálculo-do de Pearl\nEl cálculo do nos da reglas para operar con probabilidades que incluyen nuestro operador do de intervención. En este ejemplo particular, veremos cómo es el argumento:\nNótese que al intervenir \\(A\\) hemos modificado el proceso generador. Si la conjunta original tiene distribución \\(p\\), escribimos \\(p_m\\) para la conjunta de la gráfica modificada, de manera que \\(p(z|do(a)) = p_m(z|a)\\).\nAunque intuitivamente vimos cómo simular de esta distribución arriba, especificamos abajo qué reglas son las que nos permiten hacer esto: ¿cómo calculamos \\(p_m\\)?\nEn primer lugar, consideremos \\(p_m(t)\\). Esta marginal es invariante a nuestra cirugía, pues la arista \\(T\\to A\\) que eliminamos \\(T\\) no afecta el proceso que determina \\(T\\). De modo que la marginal del proceso modificado es igual a la marginal observada:\n\\[p_m(t) = p(t)\\] En segundo lugar, tenemos que\n\\[p_m(z|t,a) = p(z|t,a),\\] Pues el proceso por el cual \\(Z\\) responde a \\(T\\) y \\(A\\) es el mismo, no importa si \\(A\\) fue modificada artificalmente o no.\nJuntamos estos argumentos. Primero, por definición,\n\\[p(z|do(a)) = p_m(z|a)\\]\nPor la regla de probabilidad total, podemos condicionar todo a \\(T\\) y marginalizar. La segunda igualdad la obtenemos por la independencia entre \\(T\\) y \\(Z\\) en nuestra gráfica modificada (están \\(d\\) separadas):\n\\[p_m(z|a) = \\int p_m(z|a,t)p_m(t|a)dt = \\int p_m(z|a,t)p_m(t)dt\\] En segunda igualdad, nótese que cambiamos \\(p_m(t|a) = p_m(t)\\), lo cual podemos verificar pues en la gráfica modificada \\(A\\) y \\(T\\) están \\(d\\)-separados.\nFinalmente, las últimas dos distribuciones podemos extraerlas de los datos, como explicamos arriba \\(p_m(z|t,a) = p(z|t,a)\\) y \\(p_m(t) = p(t),\\) y terminamos con la fórmula\n\\[p(z|do(a))=p_m(z|a) = \\int p(z|a,t)p(t)dt \\]\nLas dos distribuciones de la derecha pueden ser estimadas pues están en el contexto de \\(p\\), el proceso generador de datos. Así que podemos estimarlas de los datos observados.\n\nEste argumento justifica el proceso que hicimos arriba: simulamos primero \\(T\\) con su proceso generador, y después simulamos \\(Z\\) condicional a \\(A\\) y \\(T\\) según el proceso generador original, el cual no depende de \\(A\\) en este ejemplo.\n\nEn el caso de arriba, simulamos de la distribución para entender cómo se distribuía \\(Z\\) dependiendo de modificaciones a \\(A\\). Muchas veces nos interesa calcular solamente la esperanza condicional, es decir, cuál es el valor esperado de la variable de interés dado el nivel intervenido, es decir:\n\\(E(Z|do(a)) = E_m(Z|A =a),\\)\nque mostramos arriba con la línea ajustada. También quisiéramos calcular contrastes particulares, como qué pasaría si las ventas de agua las aumentamos en 10 mil unidades:\n\\[E(Z|do(30000)) - E(Z|do(20000)),\\] que podemos calcular de manera simple con simulación:\n\nsimular_contraste <- map_df(c(20000, 30000),\n  \\(u) simular_cirugia(1000, a_unidades = u)) |> \n  group_by(a_unidades) |> \n  summarise(media_mosquitos = mean(mosquitos))\nsimular_contraste\n\n# A tibble: 2 × 2\n  a_unidades media_mosquitos\n       <dbl>           <dbl>\n1      20000            250.\n2      30000            249.\n\n\nY vemos que no hay diferencia entre las dos medias.\n\nEjemplo\nAhora hagamos otro ejemplo donde hay una relación causal que queremos estimar. Imaginemos una ciudad en donde temperaturas altas producen desabasto de agua en algunos hogares, debido a un aumento del riego. Nos interesa estimar el efecto del desabasto en las compras de agua embotellada. Nuestro diagrama ahora es:\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n  node [shape=plaintext]\n\n  edge [minlen = 3]\n   U_t -> T\n   T -> A\n   T -> D\n   D -> A\n   U_a -> A\n   U_d -> D\n\n{ rank = same; A; D }\n\n}\n\")\n\n\n\n\n\n\n\nsimular_t <- function(n = 10, dia = 150){\n  # simular un año, alrededor del día 160 (en junio)\n  t_maxima <- rnorm(n, 28, 2)\n  u <- rnorm(n, 0, 1)\n  desabasto_agua <- 1/(1 + exp(-(t_maxima - 28) + u))\n  unidades <- rnorm(n, 20000 + 2000 * (t_maxima -  28) + 8000*desabasto_agua, 2000)\n  tibble(t_maxima, unidades, desabasto_agua)\n}\nset.seed(128)\nsimular_dias <- simular_t(150)\n\n\nggplot(simular_dias, aes(x = desabasto_agua, y = unidades)) + \n  geom_point() + geom_smooth()\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\nLa correlación parece muy fuerte, sin embargo, sabemos que hay un camino no causal de asociación entre estas dos variables.\nIgual que en ejemplo anterior, vamos a intervenir teóricamente en el desabasto de agua. Después de la cirugía, nuestro diagrama modificado es:\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n  node [shape=plaintext]\n\n  edge [minlen = 3]\n   U_t -> T\n   T -> A\n   D -> A\n   U_a -> A\n{ rank = same; A; D }\n\n}\n\")\n\n\n\n\n\n\nAhora queremos calcular \\(p(a|do(d)) = p_m(a|d)\\) en función de los datos. Siguiendo el mismo argumento que en el ejemplo anterior, sabemos que tenemos que estratificar o condicionar a \\(T\\) para poder usar nuestro proceso generador de observaciones, y obtenemos:\n\\[p(a|do(d))=p_m(a|d) = \\int p(a|d,t)p(t)dt \\] Aunque a veces es posible calcular analíticamente el lado derecho analíticamente, podemos simular como hicimos en los ejemplos anteriores:\n\nsimular_cirugia <- function(n = 10, da = 0){\n  # simular un año, alrededor del día 160 (en junio)\n  t_maxima <- rnorm(n, 28, 2)\n  ### cirugía ####\n  #u <- rnorm(n, 0, 1) \n  desabasto_agua <- da\n  ######\n  unidades <- rnorm(n, 20000 + 2000 * (t_maxima -  28) + 8000*desabasto_agua, 2000)\n  tibble(t_maxima, unidades, desabasto_agua)\n}\nset.seed(128)\nsimular_dias_c <- map_df(seq(0, 1, 0.1), \\(da) simular_cirugia(1000, da = da))\n\n\nggplot(simular_dias_c, aes(x = desabasto_agua, y = unidades)) + \n  geom_point() + geom_smooth()\n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\n\n\n\nPodemos también resumir promediando:\n\nefecto_verdadero_desabasto <- simular_dias_c |> \n  group_by(desabasto_agua) |> \n  summarise(media_unidades = mean(unidades)) |> \n  rename(desabasto = desabasto_agua)\nggplot(efecto_verdadero_desabasto,\n       aes(x = desabasto, y = media_unidades)) + \n  geom_point() + geom_smooth()\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\nY este es el efecto causal del desabasto de agua. No tenemos medidas de incertidumbre pues conocemos todos los parámetros de los modelos. La media condicional parece ser lineal, así que podríamos resumir con un modelo lineal:\n\n# Modelo 1 (con datos de intervención)\nlm(unidades ~ desabasto_agua, simular_dias_c)\n\n\nCall:\nlm(formula = unidades ~ desabasto_agua, data = simular_dias_c)\n\nCoefficients:\n   (Intercept)  desabasto_agua  \n         19831            8272  \n\n\nAproximadamente, cada incremento en puntos porcentuales de 10% en desabasto incrementa las ventas en unas 800 unidades. Compara con el análisis donde no estratificamos o controlamos por la temperatura:\n\n# Modelo 2\nlm(unidades ~ desabasto_agua, simular_dias)\n\n\nCall:\nlm(formula = unidades ~ desabasto_agua, data = simular_dias)\n\nCoefficients:\n   (Intercept)  desabasto_agua  \n         14102           19491  \n\n\nOtra forma de estratificar es ajustando un modelo que incluye la variable de temperatura. Podríamos hacer\n\n# Modelo 3\nlm(unidades ~ desabasto_agua + t_maxima, simular_dias)\n\n\nCall:\nlm(formula = unidades ~ desabasto_agua + t_maxima, data = simular_dias)\n\nCoefficients:\n   (Intercept)  desabasto_agua        t_maxima  \n        -35030            8648            1948"
  },
  {
    "objectID": "03-modelos-causales.html#fórmula-de-ajuste",
    "href": "03-modelos-causales.html#fórmula-de-ajuste",
    "title": "3  Modelos causales e inferencia",
    "section": "3.4 Fórmula de ajuste",
    "text": "3.4 Fórmula de ajuste\nEn resumen, tenemos la primera regla de Pearl de inferencia causal:\n\n\n\n\n\n\nFórmula de ajuste (Pearl)\n\n\n\nSea \\(G\\) donde los padres de \\(X\\) son \\(Z_1,Z_2\\). El efecto causal total de \\(X\\) en \\(Y\\) se puede calcular como\n\\[p(y|do(x)) = \\int p(y|x, z_1,z_2) p(z_1,z_2)\\, dz_1dz_2\\] Es decir, condicionamos al valor de \\(x\\) y todos los padres de \\(X\\) para calcular \\(p(y|x,z_1,z_2)\\), y después marginalizamos sobre los padres.\n\n\nEsta fórmula se extiende a más de dos padres \\(Z_1,Z_2,Z_3,\\ldots, Z_k\\).\n\n\n\n\n\n\nTip\n\n\n\nA este proceso se llama de diferentes maneras en distintos contextos:\n\nEstamos calculando el efecto causal estratificando por las variables \\(z\\).\nControlamos por las variables \\(z\\) para calcular el efecto causal.\n\n\n\nPodemos pensar en esta fórmula de dos maneras: en primer lugar, si estamos modelando toda nuestra gráfica causal, podemos simular de la conjunta de la gráfica mutilada:\n\nFijando el nivel del tratamiento \\(T\\)\nSimulando \\(p(z_1,z_2,\\ldots, z_k)\\) (marginalizando estas variables),\nUsar \\(t\\) y las \\(z\\) simuladas para simular \\(y\\)\n\nEl otro enfoque busca sólo construir modelos para la parte que nos interesa:\n\nConstruir un modelo separado para \\(p(z_1, z_2,\\ldots, z_k) = p(z)\\) (que puede ser difícil si tenemos muchas variables) a partir los datos\nConstruir un modelo \\(p(y|t, z)\\) para simular la \\(y\\) a partir de los datos.\nIgnoramos el resto de nuestra gráfica en este caso.\n\nFinalmente, si tenemos un modelo \\(p(y| t, z)\\) podemos también investigar cómo se comporta \\(E[y|t_2,z] - E[y|t_1,z]\\) para distintos combinaciones de valores de \\(Z\\).\nNota 1: Con este principio podemos resolver algunos problemas, pero no todos. Veremos que en algunos casos existen padres que no son observados, por ejemplo, no es posible condicionar para usar la fórmula de ajuste y es necesario desarrollar otras estrategias.\nNota 2: En regresión lineal, cuando incluímos una variable en el modelo (que consideramos una variable control), estamos estratificando por ella: por ejemplo, en el modelo lineal \\(U\\sim N(m_u(d,t), \\sigma_u)\\), donde\n\\[m_u = \\beta_0 +\\beta_1 d + \\beta_2 t\\] Estamos calculando un estimador para cada valor de \\(T=t\\), que es:\n\\[m_u = (\\beta_0 + \\beta_2 t) + \\beta_1 d = \\gamma_0 + \\gamma_1 d\\] Esta es una de las maneras más simples de obtener el efecto de \\(d\\) estratificando por, o controlando por \\(t\\), siempre y cuando los modelos lineales sean apropiados.\nNótese que en este último caso, tenemos que el efecto de \\(d\\) no depende de las covariables, de forma que no es necesario hacer el promedio sobre la conjunta, es decir, suponemos que el efecto causal es el mismo independientemente de los valores de las variables de control. Sin embargo, este no siempre es el caso.\nNota 3 Sin nuestro modelo \\(p(y|t,z)\\) es lineal, y nos interesa calcular el efecto causal promedio de la variable \\(t\\), no es necesario promediar por la conjunta de \\(p(z)\\). Bajo estas condiciones, el efecto causal promedio está simplemente por el coeficiente de \\(t\\) en el modelo lineal. Sin embargo, si este no es el caso, entonces para estimar el efecto causal promedio es necesario promediar apropiadamente según la fórmula de ajuste."
  },
  {
    "objectID": "03-modelos-causales.html#simulación-para-estimar-efectos-causales",
    "href": "03-modelos-causales.html#simulación-para-estimar-efectos-causales",
    "title": "3  Modelos causales e inferencia",
    "section": "3.5 Simulación para estimar efectos causales",
    "text": "3.5 Simulación para estimar efectos causales\nLa estrategia más general y conceptualmente simple (aunque técnicamente puede ser difícil por la multitud de modelos necesarios) para usar la idea de la fórmula de ajuste es utilizar simulación:\n\n\n\n\n\n\nFórmula de ajuste con simulación\n\n\n\n\nPara calcular efectos causales de \\(X\\) en \\(Y\\) , podemos simular según el proceso generador de la gráfica mutilada donde quitamos todas las aristas que llegan a \\(X\\). En la práctica, esto implica fijar \\(X\\), ignorar el proceso generador de \\(X\\), y seguir el proceso generador original de nuestro modelo para el resto de los nodos.\nSin embargo, también es posible utilizar la fórmula formula de ajuste, y modelar sólo con las variables relevantes que aparecen en ella-\n\n\n\nNótese que cuando hacemos las simulaciones siguiendo el proceso generador, marginalizar es simple: si queremos la conjunta de \\(x_1\\) y \\(x_2\\) por ejemplo, simplemente extraemos las variables \\(x_1\\) y \\(x_2\\) y examinamos su relación.\nEn los ejemplos de arriba, todos los procesos generadores locales estaban determinados. Cuando tenemos tenemos parámetros desconocidos, es necesario estimarlos antes de usar la fórmula de ajuste, y tomar en cuenta la incertidumbre en la estimación.\nPodemos ver cómo haríamos esto con modelos bayesianos. En primer lugar, empezamos con el diagrama causal original, y establecemos nuestros modelos locales\n\nlibrary(cmdstanr)\n\nThis is cmdstanr version 0.5.3\n\n\n- CmdStanR documentation and vignettes: mc-stan.org/cmdstanr\n\n\n- CmdStan path: /home/runner/.cmdstan/cmdstan-2.31.0\n\n\n- CmdStan version: 2.31.0\n\nmod_agua <- cmdstan_model(\"../src/agua-1.stan\")\nprint(mod_agua)\n\ndata {\n  int<lower=0> N;\n  array[N] real t_maxima;\n  array[N] real unidades;\n  array[N] real desabasto_agua;\n  array[11] real desabasto_do;\n}\n\ntransformed data {\n    array[N] real logit_desabasto_agua;\n\n    for(i in 1:N){\n      logit_desabasto_agua[i] = logit(desabasto_agua[i]);\n    }\n}\nparameters {\n  real alpha;\n  real beta;\n  real alpha_u;\n  real beta_t;\n  real beta_d;\n  real mu_t;\n  real<lower=0> sigma_d;\n  real<lower=0> sigma_t;\n  real<lower=0> sigma_unidades;\n}\n\ntransformed parameters {\n  array[N] real media_unidades;\n  array[N] real desabasto_agua_c;\n\n  for(i in 1:N){\n    desabasto_agua_c[i] = alpha + beta*(t_maxima[i] - 28);\n    media_unidades[i] = alpha_u + beta_t * (t_maxima[i] - 28) + beta_d * desabasto_agua[i];\n  }\n\n\n\n}\nmodel {\n  // modelo de número de temperatura\n  t_maxima ~ normal(mu_t + 28, sigma_t);\n  sigma_t ~ normal(0, 1);\n  mu_t ~ normal(0, 3);\n  // modelo de desabasto\n  logit_desabasto_agua ~ normal(desabasto_agua_c, sigma_d);\n  alpha ~ normal(0, 1);\n  beta ~ normal(0, 1);\n  sigma_d ~ normal(0, 1);\n  // modelo de ventas\n  for(i in 1:N){\n      unidades[i] ~ normal(10000 * media_unidades[i],\n        10000 * sigma_unidades);\n  }\n  sigma_unidades ~ normal(0, 0.5);\n  // iniciales para cantidades no medidas\n  alpha_u ~ normal(0, 1);\n  beta_t ~ normal(0, 1);\n  beta_d ~ normal(0, 1);\n}\n\ngenerated quantities{\n  array[11] real unidades_sim;\n\n  for(i in 1:11){\n    array[2000] real unidades_sim_1;\n    for(k in 1:2000){\n      // Extraemos una temperatura\n      real t_sim = normal_rng(mu_t + 28, sigma_t);\n      // calculamos la media dadas  temperatura y desabasto\n      real media_unidades_sim = alpha_u +\n      beta_t * (t_sim - 28) + beta_d * desabasto_do[i];\n      // simulamos unidades\n      unidades_sim_1[k] = normal_rng(10000 * media_unidades_sim,\n        10000 * sigma_unidades);\n    }\n   // promediamos si nos interesa el valor esperado de unidades\n    unidades_sim[i] = mean(unidades_sim_1);\n  }\n}\n\n\nTomamos una muestra simulada como datos para hacer la estimación (de modo que es no es necesario preocuparnos por el ajuste de modelos locales).\n\nset.seed(128)\nsim_dias <- simular_t(250)\nN <- nrow(sim_dias)\ndesabasto_do <- seq(0, 1, 0.1)\ndatos_lista <- list(N = N, t_maxima = sim_dias$t_maxima,\n                    unidades = sim_dias$unidades,\n                    desabasto_agua = sim_dias$desabasto_agua,\n                    desabasto_do = desabasto_do)\najuste <- mod_agua$sample(data = datos_lista, refresh = 1000,\n                          init = 0.1, step_size = 0.1)\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 finished in 5.1 seconds.\nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 2 finished in 5.2 seconds.\nChain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 3 finished in 5.2 seconds.\nChain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 4 finished in 5.3 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 5.2 seconds.\nTotal execution time: 21.0 seconds.\n\n\n\nsims <- ajuste$draws(format = \"df\")\nresumen <- ajuste$summary(\n  c(\"alpha_u\", \"beta_t\", \"beta_d\", \"mu_t\", \"alpha\", \"beta\",\n    \"sigma_t\", \"sigma_d\", \"sigma_unidades\"))\nresumen |> select(variable, median, q5, q95)\n\n# A tibble: 9 × 4\n  variable       median      q5   q95\n  <chr>           <dbl>   <dbl> <dbl>\n1 alpha_u        1.99    1.93   2.06 \n2 beta_t         0.205   0.185  0.225\n3 beta_d         0.770   0.643  0.897\n4 mu_t           0.171  -0.0399 0.388\n5 alpha          0.0763 -0.0220 0.177\n6 beta           1.02    0.969  1.07 \n7 sigma_t        2.07    1.93   2.23 \n8 sigma_d        0.972   0.906  1.04 \n9 sigma_unidades 0.204   0.191  0.220\n\n\nDonde podemos checar que aproximadamente recuperamos los parámetros originales.\nComo explicamos según el concepto de cálculo-do, queremos simular de una distribución distinta para estimar el efecto causal de desabasto sobre unidades vendidas. Para esto utilizamos las simulaciones de nuestro modelo (que ajustamos con datos observacionales), pero en la sección de simulación hacemos un cálculo diferente:\n\nsim_intervenciones <- \n  ajuste$draws(format = \"df\") |> \n  select(\".draw\", contains(\"unidades_sim\")) |> \n  pivot_longer(cols = contains(\"unidades_sim\")) |> \n  separate(name, sep = \"[\\\\[\\\\]]\", into = c(\"variable\", \"indice\"),\n           convert = TRUE, extra = \"drop\") |> \n  left_join(tibble(desabasto = desabasto_do, indice = seq_along(desabasto_do)))\n\n\nsim_intervenciones |> group_by(desabasto) |> \n  summarise(media_unidades = mean(value), \n            q5 = quantile(value, 0.05),\n            q95 = quantile(value, 0.95)) |> \nggplot(aes(x=desabasto, y = media_unidades)) +\n  geom_point(colour = \"red\") +\n  geom_linerange(aes(ymin = q5, ymax = q95),colour = \"red\") +\n  geom_point(data = efecto_verdadero_desabasto)\n\n\n\n\nEsta gráfica puede ser difícil de interpretar, porque puede haber correlación entre los distintos estimadores que estamos presentando. Sin embargo, vemos cómo nuestra estimación (en rojo) está cercana a los valores teóricos.\nPara comparar entre niveles del factor que manipulamos, lo mejor es hacer contrastes. Comparamos con la situación de 0 desabasto, por ejemplo, y calculamos el incremento estimado:\n\nsim_nivel_0 <- filter(sim_intervenciones, desabasto == 0) |> \n  select(.draw, value_0 = value)\nsim_intervenciones |> left_join(sim_nivel_0) |> \n  mutate(dif = value - value_0) |> \n  group_by(desabasto) |> \n  summarise(diferencia_media = mean(dif), \n            q5 = quantile(dif, 0.05),\n            q95 = quantile(dif, 0.95)) |> \nggplot(aes(x=desabasto, y = diferencia_media, \n           ymin = q5, ymax = q95)) +\n  geom_point(colour = \"red\") +\n  geom_linerange(colour = \"red\")\n\n\n\n\nClaramente todos los estimadores están bien separados de 0. Diez puntos porcentuales de incremento en desabasto incrementan las ventas en alrededor de 8 mil unidades.\n\nRecordemos que en todos estos ejemplos nos estamos concentrando en la identificación de un efecto causal que nos interesa, así que nos estamos saltando algunos pasos en el proceso de modelación y estimación que en el trabajo usual debemos seguir:\n\n\n\n\n\n\nModelación y estimadores\n\n\n\nEl procedimiento general es (McElreath (2015)):\n\nDefinir la cantidad a estimar\nConstruir un modelo causal gráfico (puede incluir variables no medidas)\nDefinir un modelo generativo basado en el modelo causal (puede tener parámetros desconocidos, que se estimarán con datos), recorriendo los nodos y definiendo los modelos individuales. Hacer validación a priori.\nDefinir el cálculo del estimador (por ejemplo, con la fórmula de ajuste)\nAjustar el modelo completo a los datos, hacer validación posterior y calcular el estimador del paso anterior.\n\n\n\nEn 2 y 3 está la mayor parte del trabajo. La parte 3 es parte de un curso de estadística bayesiana, y para esta parte usamos un flujo bayesiano de construcción de modelos (ver aquí o aquí)."
  },
  {
    "objectID": "03-modelos-causales.html#ejemplo-estaturas-versión-1",
    "href": "03-modelos-causales.html#ejemplo-estaturas-versión-1",
    "title": "3  Modelos causales e inferencia",
    "section": "3.6 Ejemplo: estaturas (versión 1)",
    "text": "3.6 Ejemplo: estaturas (versión 1)\nConsideramos el ejemplo donde queremos entender el efecto de sexo en el peso de personas. Usaremos los siguientes datos (McElreath (2015)), que son datos recolectados de una población particular (Kalahari !Kung San). Tomamos sólo a los adultos (definidos por más de 18 años).\n\nhowell <- read_delim(\"../datos/Howell1.csv\", delim = \";\") |> \n  filter(age >= 18)\n\nRows: 544 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \";\"\ndbl (4): height, weight, age, male\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nhead(howell)\n\n# A tibble: 6 × 4\n  height weight   age  male\n   <dbl>  <dbl> <dbl> <dbl>\n1   152.   47.8    63     1\n2   140.   36.5    63     0\n3   137.   31.9    65     0\n4   157.   53.0    41     1\n5   145.   41.3    51     0\n6   164.   63.0    35     1\n\n\n\nggplot(howell, aes(x = height, y = weight, colour = male)) +\n  geom_point()\n\n\n\n\nEmpezaremos con el siguiente modelo causal:\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n  node [shape=plaintext]\n    S\n    H\n    W \n  node [shape = circle]\n    U\n  edge [minlen = 3]\n    S -> H\n    S -> W\n    H -> W\n    U -> H\n    U -> W\n{rank = same; S;H}\n}\n\")\n\n\n\n\n\n\n\nEn primer lugar, tenemos una flecha \\(H\\to W\\). La razón es que podemos pensar en varias intervenciones que afectan el peso pero que no cambian la estatura.\nEn segundo lugar, \\(S\\) es causa de \\(H\\), pero también puede afectar directamente peso \\(W\\) junto con la estatura \\(H\\).\n\\(H\\) y \\(W\\) pueden tener otras causas comunes no observadas (nutrición por ejemplo), que no influyen en \\(S\\).\n\nAhora veamos cómo calcular el efecto causal total de sexo sobre peso.\nPodemos ver que no hay ninguna flecha que llegue a \\(S\\), de modo que para el efecto total no es necesario hacer cirugía ni usar la fórmula de ajuste.\n\n\n\n\n\n\nCondicionando equivocadamente\n\n\n\nDe hecho, en este ejemplo sería mala idea condicionar a la estatura \\(H\\), pues cerramos un camino causal por el que \\(S\\) influye en \\(W\\), y al mismo tiempo abrimos un camino no causal que pasa por \\(U\\).\n\n\nEl análisis detallado de la gráfica es:\n\nExisten dos rutas causales de sexo a peso: una que está mediada por la estatura y otra que es efecto directo sobre peso. No queremos bloquear condicionando a la estatura \\(H\\).\nExiste una ruta no causal de sexo sobre peso, y es el camino \\(S\\to H \\gets U \\to W\\). Sin embargo, esta ruta está bloqueada por \\(H\\), la estatura, que es un colisionador.\n\nComenzamos ahora el proceso de modelado. Excluiremos a \\(U\\) en nuestro modelo, pues no tiene relevancia para la inferencia acerca del efecto total de \\(S\\) sobre \\(W\\), como discutimos arriba.\n\n\n\n\n\n\nOjo: interpetación de modelos\n\n\n\nNótese que la decisión de excluir de nuestro análisis la variable \\(U\\) sólo tiene sentido si lo que queremos estimar es el efecto total de sexo sobre peso. Esto implica que nuestras estimaciones que corresponden a \\(H\\to W\\) no tienen interpretación causal. Una estrategia de identificación para un efecto no implica que todo lo que salga de nuestras estimaciones es causal.\n\n\nEmpezamos entonces con el modelo de estatura:\n\\[H|S=s \\sim N(m_h, \\sigma_h)\\] con\n\\[m_h = \\alpha_0 + \\alpha_1 s \\] Y el modelo de peso:\n\\[W|S=s,H=h \\sim N(m_w, \\sigma_w)\\] \\[m(s,a,h) = \\gamma_0 + \\gamma_1 s  + \\gamma_2 h\\]\nLo escribimos en stan:\n\nmod_1 <- cmdstanr::cmdstan_model(\"../src/peso-estatura-inferencia-1.stan\")\nprint(mod_1)\n\ndata {\n  int<lower=0> N;\n  vector[N]  s;\n  vector[N]  h;\n  vector[N]  w;\n\n}\n\ntransformed data {\n  vector[N] h_c;\n  real media_h;\n  int M;\n  // simulaciones\n  M = 1000;\n  // centrar\n  media_h = mean(h);\n  h_c = h - mean(h);\n}\n\nparameters {\n  real alpha_0;\n  real alpha_1;\n  real gamma_0;\n  real gamma_1;\n  real gamma_2;\n  real<lower=0> sigma_h;\n  real<lower=0> sigma_w;\n}\n\n\n\ntransformed parameters {\n  vector[N] m_h;\n  vector[N] m_w;\n\n  m_h = alpha_0 + alpha_1 * s;\n  m_w = gamma_0 + gamma_1 * s + gamma_2 * h_c;\n\n}\n\nmodel {\n  // modelo para estatura\n  h ~ normal(m_h, sigma_h);\n  alpha_0 ~ normal(150, 30);\n  alpha_1 ~ normal(10, 20);\n  sigma_h ~ normal(0, 30);\n\n  // modelo para peso\n  w ~ normal(m_w, sigma_w);\n  gamma_0 ~ normal(50, 30);\n  gamma_1 ~ normal(10, 20);\n  gamma_2 ~ normal(0, 2);\n  sigma_w ~ normal(0, 5);\n\n\n}\ngenerated quantities {\n  real w_mean_male;\n  real w_mean_female;\n  real dif_male;\n  array[M] real w_sim_male;\n  array[M] real w_sim_female;\n\n  // simular hombres\n  real do_s = 1;\n  for(i in 1:M){\n    real h_sim_media = alpha_0 + alpha_1 * do_s;\n    real h_sim = normal_rng(h_sim_media, sigma_h);\n    real w_sim_media = gamma_0 + gamma_1 * do_s + gamma_2 * (h_sim - media_h);\n    w_sim_male[i] = normal_rng(w_sim_media, sigma_w);\n  }\n\n  do_s = 0;\n  for(i in 1:M){\n    real h_sim_media = alpha_0 + alpha_1 * do_s;\n    real h_sim = normal_rng(h_sim_media, sigma_h);\n    real w_sim_media = gamma_0 + gamma_1 * do_s + gamma_2 * (h_sim - media_h);\n    w_sim_female[i] = normal_rng(w_sim_media, sigma_w);\n  }\n\n  w_mean_male = mean(w_sim_male);\n  w_mean_female = mean(w_sim_female);\n  dif_male = w_mean_male - w_mean_female;\n\n}\n\n\n\ndatos_lista <- list(N = nrow(howell), s= howell$male, a = howell$age, \n                    h = howell$height, w = howell$weight)\najuste <- mod_1$sample(data = datos_lista, refresh = 1000)\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 finished in 2.8 seconds.\nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 2 finished in 2.5 seconds.\nChain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 3 finished in 2.7 seconds.\nChain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 4 finished in 2.6 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 2.7 seconds.\nTotal execution time: 11.0 seconds.\n\nsims <- ajuste$draws( format = \"df\")\nresumen <- ajuste$summary(c( \"dif_male\"))\noptions(scipen = 9999)\nresumen |> select(variable, mean, q5, q95) |> \n  mutate(across(where(is.numeric), round, 2))\n\n# A tibble: 1 × 4\n  variable  mean    q5   q95\n  <chr>    <dbl> <dbl> <dbl>\n1 dif_male  6.77  5.73  7.81\n\n\n\nsims |> ggplot(aes(x = dif_male)) + \n  geom_histogram(bins = 40)\n\n\n\n\nEsta es nuestra estimación del diferencia causal promedio de sexo sobre el peso para personas adultas: está aproximadamente entre 5.5 y 8.5 kilos aproximadamente.\nSin embargo, dada la discusión que tuvimos arriba, podemos hacer un modelo más simple para estimar el efecto total, ignorando \\(W\\):\n\nmod_2 <- cmdstanr::cmdstan_model(\"../src/peso-estatura-inferencia-simple.stan\")\nprint(mod_2)\n\ndata {\n  int<lower=0> N;\n  vector[N]  s;\n  vector[N]  w;\n\n}\n\ntransformed data {\n  vector[N] h_c;\n  int M;\n  // simulaciones\n  M = 1000;\n  // centrar\n\n}\n\nparameters {\n  real gamma_0;\n  real gamma_1;\n  real gamma_2;\n  real<lower=0> sigma_w;\n}\n\n\n\ntransformed parameters {\n  vector[N] m_w;\n\n  m_w = gamma_0 + gamma_1 * s;\n\n}\n\nmodel {\n\n  // modelo para peso\n  w ~ normal(m_w, sigma_w);\n  gamma_0 ~ normal(50, 30);\n  gamma_1 ~ normal(10, 20);\n  gamma_2 ~ normal(0, 2);\n  sigma_w ~ normal(0, 5);\n\n\n}\ngenerated quantities {\n  real w_mean_male;\n  real w_mean_female;\n  real dif_male;\n  array[M] real w_sim_male;\n  array[M] real w_sim_female;\n\n  // simular hombres\n  real do_s = 1;\n  for(i in 1:M){\n    real w_sim_media = gamma_0 + gamma_1 * do_s;\n    w_sim_male[i] = normal_rng(w_sim_media, sigma_w);\n  }\n\n  do_s = 0;\n  for(i in 1:M){\n    real w_sim_media = gamma_0 + gamma_1 * do_s;\n    w_sim_female[i] = normal_rng(w_sim_media, sigma_w);\n  }\n\n  w_mean_male = mean(w_sim_male);\n  w_mean_female = mean(w_sim_female);\n  dif_male = w_mean_male - w_mean_female;\n\n}\n\n\n\ndatos_lista <- list(N = nrow(howell), s= howell$male, \n                    w = howell$weight)\najuste <- mod_2$sample(data = datos_lista, refresh = 1000)\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 finished in 1.7 seconds.\nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 2 finished in 1.7 seconds.\nChain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 3 finished in 1.7 seconds.\nChain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 4 finished in 1.7 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 1.7 seconds.\nTotal execution time: 7.4 seconds.\n\nsims <- ajuste$draws( format = \"df\")\nresumen <- ajuste$summary(c( \"dif_male\"))\noptions(scipen = 9999)\nresumen |> select(variable, mean, q5, q95) |> \n  mutate(across(where(is.numeric), round, 2))\n\n# A tibble: 1 × 4\n  variable  mean    q5   q95\n  <chr>    <dbl> <dbl> <dbl>\n1 dif_male  6.78  5.76  7.86\n\n\n\nsims |> ggplot(aes(x = dif_male)) + \n  geom_histogram(bins = 40)\n\n\n\n\nY obtenemos el mismo resultado con un modelo más simple. El modelo anterior lo usaremos después para explorar el concepto de mediación."
  },
  {
    "objectID": "03-modelos-causales.html#bloqueando-puertas-traseras",
    "href": "03-modelos-causales.html#bloqueando-puertas-traseras",
    "title": "3  Modelos causales e inferencia",
    "section": "3.7 Bloqueando puertas traseras",
    "text": "3.7 Bloqueando puertas traseras\nEn las partes anteriores vimos que estratificando por los padres de la variable de tratamiento \\(X\\) podemos construir un estimador del efecto de \\(X\\) sobre otra variable \\(Y\\), pasando de una distribución observacional a una conceptualmente experimental (dado que los supuestos causales sean aproximadamente correctos).\nSin embargo, esta aplicación de la fórmula de ajuste no funciona si existen padres que no fueron observados, y por tanto no podemos estratificar por ellos. El siguiente método (ajuste por “puerta trasera”) nos da una técnica adicional que podemos usar dado ciertos tipos de estructura en nuestro modelo causal, y presenta una mejoría sobre la fórmula de ajuste simple (veremos también por ejemplo, que a veces podemos usar menos variables que padres de la variable de interés). Nótese que una vez más, este criterio sólo depende de la gráfica causal \\(G\\) asociada a nuestro modelo, y no los modelos locales que utilizemos para modelar la condicional de cada nodo.\n\n\n\n\n\n\nAjuste de puerta trasera (Pearl)\n\n\n\nSi tenemos dos variables \\(T\\) y \\(Y\\) en una gráfica \\(G\\), un conjunto \\(Z\\) de variables satisface el criterio de puerta trasera relativo a \\(T\\) y \\(Y\\) cuando \\(Z\\) bloquea cualquier camino entre \\(T\\) y \\(Y\\) que tenga una arista que incida en \\(T\\), y ninguna variable de \\(Z\\) es descendiente de \\(T\\).\nEn tal caso, podemos utilizar la fórmula de ajuste, pero en lugar de estratificar por los padres de \\(T\\), estratificamos por las variables en \\(Z\\)\n\n\nLa idea es:\n\nQueremos bloquear todos los caminos no causales entre \\(T\\) y \\(Y\\).\nQueremos no perturbar todos los caminos dirigidos de \\(T\\) a \\(Y\\) (caminos causales).\nNo queremos activar caminos no causales entre \\(T\\) y \\(Y\\) al condicionar.\n\nCumplimos 1 al estratificar por variables que bloquean los caminos que son causas de \\(T\\), pues estos caminos no son causales y distorsionan la relación entre \\(T\\) y \\(Y\\). Al mismo tiempo, no bloqueamos caminos causales porque ningúna variable de \\(Z\\) es descendiente de \\(T\\), de modo que se satisface el criterio 2 (todos los caminos causales comienzan con \\(T\\to\\)). Finalmente, al excluir descendientes de \\(T\\) también implica que no condicionamos a colisionadores del tipo \\(T\\to \\cdots \\to Z_1\\gets Y\\), pues esto activa un camino no causal entre \\(T\\) y \\(Y\\) (se cumple 3).\n\nEjemplo (Pearl)\nConsideramos primero este ejemplo simple, donde queremos evaluar la efectividad de un tratamiento en cierta enfermedad. Los datos que tenemos disponibles son si una persona recibió o no un tratamiento, y si se recuperó o no. No se registró el nivel socioeconómico, pero sabemos que el tratamiento es caro, de forma que fue accedido más por gente de NSE más alto. También que sabemos que para este tipo de tratamiento, el peso de la persona es un factor importante. Nuestros supuestos están en la siguiente gráfica:\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2, rankdir = LR]\n  node [shape=plaintext]\n    Trata\n    Res\n  node [shape = circle]\n    NSE\n    Peso\n    U\n  edge [minlen = 3]\n    NSE -> Peso\n    NSE -> Trata\n    Trata -> Res\n    Peso -> Res\n    U -> NSE\n    U -> Peso\n}\n\")\n\n\n\n\n\n\nObservamos que no podemos directamente usar la fórmula de ajuste pues NSE no es una variable observada.\nEn esta circunstancia no podríamos identificar el efecto causal, pues existen un caminos abiertos no causales. Quizá el tratamiento no es muy efectivo, y parece ser bueno pues fue aplicado a personas con menor peso que las que no recibieron el tratamiento, a través del efecto de NSE. Sin embargo, supón que tuviéramos disponible la variable Peso:\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2, rankdir = LR]\n  node [shape=plaintext]\n    Trata\n    Res\n    Peso\n  node [shape = circle]\n    NSE\n    U\n  edge [minlen = 3]\n    NSE -> Peso\n    NSE -> Trata\n    Trata -> Res\n    Peso -> Res\n    U -> NSE\n    U -> Peso\n}\n\")\n\n\n\n\n\n\nEn este caso, todavía no podemos aplicar la fórmula original de ajuste pues no conocemos \\(NSE\\). Sin embargo, podemos bloquear los caminos no causales estratificando por Peso, y entonces podemos usar el criterio de puerta trasera para identificar el efecto del tratamiento, aún cuando no tengamos NSE.\n\n\nEjemplo\nPrimero consideramos un modelo generador:\n\nsimular_bd <- function(n = 10){\n  nse <- sample(c(0, 1), n, replace = TRUE)\n  peso <- rnorm(n, 70 - 7 * nse, 12 + 2 * nse)\n  trata <- rbinom(n, 1, 0.8 * nse + 0.2 * (1 - nse))\n  p_trata <- inv_logit(1 * trata - 0.2 * (peso - 70))\n  res <- rbinom(n, 1, p_trata)\n  tibble(nse, peso, trata, res)\n}\ndatos_bd <- simular_bd(10000)\nhead(datos_bd)\n\n# A tibble: 6 × 4\n    nse  peso trata   res\n  <dbl> <dbl> <int> <int>\n1     0  72.6     0     1\n2     1  67.8     1     0\n3     1  68.8     1     0\n4     1  62.2     1     1\n5     0  81.3     1     0\n6     0  67.6     1     1\n\n\nVeamos qué sucede si cruzamos tratamiento con resultado (es una muestra grande y el error de estimación no es importante):\n\ndatos_bd |> \n  count(trata, res) |>\n  group_by(trata) |> \n  mutate(p = n / sum(n)) |> \n  filter(res == 1) |> \n  ungroup() |> \n  mutate(dif = p - lag(p))\n\n# A tibble: 2 × 5\n  trata   res     n     p    dif\n  <int> <int> <int> <dbl>  <dbl>\n1     0     1  2609 0.530 NA    \n2     1     1  3784 0.746  0.216\n\n\nSabemos que esta diferencia en respuesta puede estar confundida por un camino no causal. El verdadero efecto casual podemos calcularlo en nuestras simulaciones como sigue a partir de nuestro modelo (igualmente, usamos una muestra muy grande):\n\nsimular_efecto <- function(n = 10, peso = NULL){\n  # cómo es la población\n  nse <- sample(c(0, 1), n, replace = TRUE)\n  if(is.null(peso)){\n    peso <- rnorm(n, 70 - 7 * nse, 12 + 2 * nse)\n  }\n  # asignar al azar\n  trata <- rbinom(n, 1, 0.5)\n  p_trata <- inv_logit(1 * trata - 0.2 * (peso - 70))\n  res <- rbinom(n, 1, p_trata)\n  tibble(nse, peso, trata, res)\n}\nsims_efecto <- simular_efecto(20000)\nresumen <- sims_efecto |> \n  count(trata, res) |>\n  group_by(trata) |> \n  mutate(p = n / sum(n)) |> \n  filter(res == 1) |> \n  ungroup() |> \n  mutate(dif = p - lag(p))\ndif_real <- resumen$dif[2]\nresumen\n\n# A tibble: 2 × 5\n  trata   res     n     p    dif\n  <int> <int> <int> <dbl>  <dbl>\n1     0     1  5885 0.586 NA    \n2     1     1  7013 0.705  0.119\n\n\nLa estimación ingenua del cruce simple es mucho más grande que el verdadero efecto.\nPodemos también calcular el efecto para un peso particular:\n\nsims_efecto <- simular_efecto(20000, peso = 70)\nres_70 <- sims_efecto |> \n  count(trata, res) |>\n  group_by(trata) |> \n  mutate(p = n / sum(n)) |> \n  filter(res == 1) |> \n  ungroup() |> \n  mutate(dif = p - lag(p))\ndif_70 <- res_70$dif[2]\nres_70\n\n# A tibble: 2 × 5\n  trata   res     n     p    dif\n  <int> <int> <int> <dbl>  <dbl>\n1     0     1  5028 0.500 NA    \n2     1     1  7306 0.734  0.234\n\n\nSuponiendo nuestro diagrama, queremos estimar estratificando por peso. Podríamos usar un sólo modelo logístico, pero pueden ser más simples los cálculos si construimos nuestro modelo en stan. En este caso, podríamos calcular las diferencias para un peso particular, por ejemplo 70 kg (en lugar de modelar estaturas para producir una estimación de diferencia promedio).\nUsaremos una muestra de 2 mil personas:\n\nmod_trata <- cmdstan_model(\"../src/trata-backdoor.stan\")\nprint(mod_trata)\n\ndata {\n  int<lower=0> N;\n  vector[N] trata;\n  array[N] int res;\n  vector[N] peso;\n\n}\n\ntransformed data {\n  real media_peso;\n\n  // centrar\n  media_peso = mean(peso);\n}\n\nparameters {\n  real gamma_0;\n  real gamma_1;\n  real gamma_2;\n}\n\ntransformed parameters {\n  vector[N] p_logit_res;\n\n  p_logit_res = gamma_0 + gamma_1 * trata + gamma_2 * (peso - media_peso);\n\n}\n\nmodel {\n  // modelo de resultado\n  res ~ bernoulli_logit(p_logit_res);\n  gamma_0 ~ normal(0, 2);\n  gamma_1 ~ normal(0, 1);\n  gamma_2 ~ normal(0, 0.2);\n\n\n}\ngenerated quantities {\n  real dif_trata;\n  real p_trata;\n  real p_no_trata;\n\n  real peso_sim = 70;\n  {\n    array[2000] int res_trata;\n    array[2000] int res_no_trata;\n    for(k in 1:2000){\n      res_trata[k] = bernoulli_rng(\n        inv_logit(gamma_0 + gamma_1 * 1 +\n              gamma_2 * (peso_sim - media_peso)));\n      res_no_trata[k] = bernoulli_rng(\n        inv_logit(gamma_0 + gamma_1 * 0 +\n              gamma_2 * (peso_sim - media_peso)));\n    }\n    p_trata = mean(res_trata);\n    p_no_trata = mean(res_no_trata);\n  }\n  dif_trata = p_trata - p_no_trata;\n}\n\n\n\nset.seed(915)\ndatos_bd <- simular_bd(2000)\ndatos_lista <- list(N = nrow(datos_bd),\n  trata = datos_bd$trata, res = datos_bd$res,\n  peso = datos_bd$peso)\najuste <- mod_trata$sample(data = datos_lista, refresh = 1000)\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 finished in 2.6 seconds.\nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 2 finished in 2.7 seconds.\nChain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 3 finished in 2.6 seconds.\nChain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 4 finished in 2.7 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 2.6 seconds.\nTotal execution time: 10.9 seconds.\n\nsims <- ajuste$draws( format = \"df\")\nresumen <- ajuste$summary(c( \"dif_trata\"))\n\n\nresumen |> select(variable, mean, q5, q95)\n\n# A tibble: 1 × 4\n  variable   mean    q5   q95\n  <chr>     <dbl> <dbl> <dbl>\n1 dif_trata 0.214 0.162 0.268\n\nsims |> select(dif_trata) |> \n  ggplot(aes(x = dif_trata)) + geom_histogram() +\n  geom_vline(xintercept = dif_70, colour = \"red\")\n\nWarning: Dropping 'draws_df' class as required metadata was removed.\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nY obtenemos una estimación correcta del efecto en 70 kg. Podríamos también calcular el efecto en distintos pesos (nuestro estimador es una curva), promediar estimando una distribución de pesos modelada, o tomar una distribución fija de pesos para modelar (cada una de estas estrategias tiene propósitos diferentes).\nSi queremos tener un efecto promedio, podemos modelar los pesos. Otra estrategia es promediar sobre los valores observados de la muestra. Nótese que esto ignora una parte de la incertidumbre proveniente de la muestra particular usada.\n\nmod_trata <- cmdstan_model(\"../src/trata-backdoor-promedio.stan\")\nprint(mod_trata)\n\ndata {\n  int<lower=0> N;\n  vector[N] trata;\n  array[N] int res;\n  vector[N] peso;\n\n}\n\ntransformed data {\n  real media_peso;\n\n  // centrar\n  media_peso = mean(peso);\n}\n\nparameters {\n  real gamma_0;\n  real gamma_1;\n  real gamma_2;\n}\n\ntransformed parameters {\n  vector[N] p_logit_res;\n\n  p_logit_res = gamma_0 + gamma_1 * trata + gamma_2 * (peso - media_peso);\n\n}\n\nmodel {\n  // modelo de resultado\n  res ~ bernoulli_logit(p_logit_res);\n  gamma_0 ~ normal(0, 2);\n  gamma_1 ~ normal(0, 1);\n  gamma_2 ~ normal(0, 0.2);\n\n\n}\ngenerated quantities {\n  real dif_trata;\n  real p_trata;\n  real p_no_trata;\n  vector[N] probs;\n\n  for(i in 1:N){\n    probs[i] = 1.0 / N;\n  }\n\n  {\n    array[2000] int res_trata;\n    array[2000] int res_no_trata;\n    for(k in 1:2000){\n      real peso_sim = peso[categorical_rng(probs)];\n      res_trata[k] = bernoulli_rng(\n        inv_logit(gamma_0 + gamma_1 * 1 +\n              gamma_2 * (peso_sim - media_peso)));\n      res_no_trata[k] = bernoulli_rng(\n        inv_logit(gamma_0 + gamma_1 * 0 +\n              gamma_2 * (peso_sim - media_peso)));\n    }\n    p_trata = mean(res_trata);\n    p_no_trata = mean(res_no_trata);\n  }\n  dif_trata = p_trata - p_no_trata;\n\n}\n\n\n\ndatos_lista <- list(N = nrow(datos_bd),\n  trata = datos_bd$trata, res = datos_bd$res,\n  peso = datos_bd$peso)\najuste <- mod_trata$sample(data = datos_lista, refresh = 1000)\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 finished in 14.3 seconds.\nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 2 finished in 14.7 seconds.\nChain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 3 finished in 14.9 seconds.\nChain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 4 finished in 14.8 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 14.7 seconds.\nTotal execution time: 59.1 seconds.\n\nsims <- ajuste$draws(c(\"dif_trata\"), format = \"df\")\n\n\nresumen <- ajuste$summary(c( \"dif_trata\"))\nresumen |> select(variable, mean, q5, q95)\n\n# A tibble: 1 × 4\n  variable   mean     q5   q95\n  <chr>     <dbl>  <dbl> <dbl>\n1 dif_trata 0.110 0.0785 0.141\n\nsims |> select(dif_trata) |> \n  ggplot(aes(x = dif_trata)) + geom_histogram() +\n  geom_vline(xintercept = dif_real, colour = \"red\")\n\nWarning: Dropping 'draws_df' class as required metadata was removed.\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nY recuperamos nuevamente el efecto verdadero que mostramos arriba."
  },
  {
    "objectID": "03-modelos-causales.html#reglas-del-cálculo-do-opcional",
    "href": "03-modelos-causales.html#reglas-del-cálculo-do-opcional",
    "title": "3  Modelos causales e inferencia",
    "section": "3.8 Reglas del cálculo-do (opcional)",
    "text": "3.8 Reglas del cálculo-do (opcional)\nExisten tres axiomas básicos del cálculo-do de las que se derivan los demás resultados, como veremos en el siguiente ejemplo del criterio de la puerta delantera.\nAntes de verlas, un resumen rápido de las reglas es el siguiente:\n\nLa regla 1 nos dice que las distribuciones asociadas a intervenciones satisfacen también la equivalencia de \\(d\\)-separación e independencia condicional: si \\(Y\\) y \\(Z\\) están \\(d\\)-separadas dado en la gráfica manipulada, entonces \\(p(y | do(x), z) = p(y|do(x))\\).\nLa regla 2 es el criterio de la puerta trasera: si condicionamos a variables \\(W\\) que bloquean toda puerta trasera de \\(X\\) a \\(Y\\), podemos cambiar \\(do(x)\\) por \\(x\\): \\(p(y | do(x), w) = p(y | x, w)\\).\nLa regla 3 expresa que si no hay caminos causales de \\(X\\) a \\(Y\\), entonces \\(p(y|do(x)) = p(y)\\).\n\n\n\n\n\n\n\nCompletitud (Shpitser, Pearl)\n\n\n\nSi un efecto causal es identificable (puede expresarse en términos de cantidades observacionales), entonces puede derivarse una estrategia de identificación a partir de las tres reglas del cálculo-do.\n\n\nNota: esto no excluye que bajo ciertas hipótesis adicionales a las de nuestra gráfica causal (por ejemplo cómo se comportan las distribuciones particulares qeu componen el modelo), sea posible identificar efectos causales con otros medios que van más allá del cálculo-do.\nCon más generalidad, abajo están estas reglas (donde condicionamos a más variables o hacemos más intervenciones, y afinamos las condiciones):\nDenotamos por \\(G_m\\) la gráfica mutilada por \\(do(x)\\), donde quitamos todas las aristas que entran en \\(X\\). Los tres axiomas son:\nRegla 1 Ignorar observaciones: Si \\(Y\\) y \\(Z\\) están \\(d\\)-separados por \\(X\\) y \\(W\\) en \\(G_m\\),\n\\[ p(y|do(x), z, w) = p(y|do(x), w)\\] O en otras palabras, si \\(p_m\\) es la conjunta para \\(G_m\\),\n\\[p_m(y|x,z,w) = p_m(y|x, w)\\] es cierto si \\(Y\\) y \\(Z\\) están \\(d\\)-separados por \\(X\\) y \\(W\\) en \\(G_m\\) (condicionalmente independientes). Así que esta regla es independencia condicional dado \\(d\\)-separación, pero para la gráfica intervenida.\nRegla 2 Usando observaciones como intervenciones:\nSi \\(Y\\) y \\(Z\\) están \\(d\\)-separados por \\(X\\) y \\(W\\) en \\(G_m\\) quitándole todas las aristas que salen de \\(Z\\), entonces\n\\[ p(y|do(x), do(z), w) = p(y|do(x), z, w)\\] Regla 3 Ignorar intervenciones:\nSi \\(Z\\) y \\(Y\\) están \\(d\\)-separadas por \\(X\\) y \\(W\\) en la gráfica \\(G_m\\) donde además quitamos cualquier arista a \\(Z\\) si \\(Z\\) no es antecesor de \\(W\\) en \\(G_m\\), entonces:\n\\[ p(y|do(x), do(z), w) = p(y|do(x), w)\\]"
  },
  {
    "objectID": "03-modelos-causales.html#el-criterio-de-puerta-delantera",
    "href": "03-modelos-causales.html#el-criterio-de-puerta-delantera",
    "title": "3  Modelos causales e inferencia",
    "section": "3.9 El criterio de puerta delantera",
    "text": "3.9 El criterio de puerta delantera\nEn algunos casos, puede ser que no sea posible bloquear algún camino no causal con variables observadas. Un ejemplo clásico es el de la discusión acerca de la relación de fumar con cáncer de pulmón. Algunos estadísticos plantearon que los estudios de asociación entre fumar y cáncer de pulmón podrían tener efectos gravemente confundidos, por ejemplo, por aspectos genéticos que hacen a una persona propensa a fumar al mismo tiempo que aumenta su probabilidad de fumar:\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n  node [shape=plaintext]\n    F\n    C\n  node [shape = circle]\n    U\n  edge [minlen = 3]\n    U -> F\n    U -> C\n    F -> C\n{rank= same; C; F}\n}\n\")\n\n\n\n\n\n\nEn este caso, el efecto de fumar (\\(F\\)) sobre cáncer (\\(C\\)) no es identificable pues no podemos condicionar a la variable de Genotipo (\\(U\\)). Supongamos que tenemos una medida adicional, que es la cantidad de depósitos de alquitrán den los pulmones de los pacientes. Este es es afectado por \\(F\\), y a su vez, el alquitrán incrementa la probabilidad de cáncer:\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n  node [shape=plaintext]\n    F\n    C\n    A\n  node [shape = circle]\n    U\n  edge [minlen = 3]\n    U -> F\n    U -> C\n    F -> A\n    A -> C\n{rank= same; C; F; A}\n}\n\")\n\n\n\n\n\n\nLa idea es primero estimar el efecto de \\(F\\) sobre \\(A\\), y después estimar el efecto de \\(A\\) sobre \\(C\\). La “composición” de estos dos efectos, dado el diagrama, debe darnos el estimador correcto. Primero consideramos el efecto de \\(F\\) sobre \\(A\\), y tenemos que (regla 2)\n\\[p(a|do(f)) = p(a|f),\\] La igualdad se debe a que una vez que condicionamos a \\(F\\) no hay puertas traseras entre \\(F\\) y \\(A\\) (pues no condicionamos a \\(C\\)). Esta dependencia causal la podemos entonces estimar de los datos.\nEl efecto de \\(A\\) sobre \\(C\\) también es identificable, pues el camino no causal se bloquea cuando condicionamos a \\(A\\), de forma que por la fórmula de ajuste:\n\\[p(c|do(a)) = \\int p(c|a, f') p(f')\\, df'\\]\nAhora encadenamos estas dos ecuaciones:\n\\[p(c|do(f)) = \\int p(c|do(a))p(a|f)\\,da\\]\nque equivale en simulación a: dado un valor de \\(F\\), simulamos \\(A=a\\) con nuestro modelo ajustado con datos naturales. Ahora intervenimos \\(A\\) con el valor a que obtuvimos y simulamos \\(C\\). Sin embargo, para hacer este último paso con datos naturales, necesitamos usar el criterio de puerta trasera como explicamos arriba: simulamos entonces \\(f´\\) de \\(p(f)\\), y después simulamos \\(C\\) en función de \\(a\\) y \\(f´\\) (con una distribución construida a partir de datos).\nRequerimos en este caso construir y estimar la condicional \\(p(c|a, f)\\) basado en los datos.\nEn fórmula, en general, se escribe como:\n\n\n\n\n\n\nCriterio de fuerta delantera (Pearl)\n\n\n\nDecimos que un conjunto de variables \\(A\\) satisface el criterio de puerta delantera en relación a las variables \\(F\\) y \\(C\\) cuando:\n\n\\(A\\) intercepta todos las cadenas dirigidos de \\(F\\) a \\(C\\)\nNo hay ningún camino activo de puerta trasera de \\(F\\) a \\(A\\)\nTodos los caminos de puerta trasera de \\(A\\) a \\(C\\) están bloqueados por \\(F\\).\n\nSi \\(A\\) satisface el criterio de puerta delantera en relación a \\(F\\) y \\(C\\), entonces el efecto causal de \\(F\\) en \\(C\\) es identificable y está dado por la fórmula:\n\\[p(c|do(f)) = \\int \\left [ \\int p(c|a,f´)p(f´)\\,df´ \\right ] p(a|f)\\,da\\]\n\n\nTodas estas cantidades puede estimarse de los datos.\n\nEjemplo: proceso generador\nAntes de aplicar este nuevo procedimiento, describamos el proceso generador que utilizaremos:\n\n# simular distribución natural\nsimular_fd <- function(n = 10, efecto_a = 0.3){\n  ## causa común\n  u <- rnorm(n, 0, 1);\n  # cantidad que fuma\n  f <- exp(rnorm(n, 1 + 0.2 * u, 0.1))\n  # acumulación de alquitrán\n  a <- rnorm(n,  4 * f, 2)\n  # probabilidad de cancer\n  p_c <- inv_logit(-6 + efecto_a * a +  2 * u)\n  c <- rbinom(n, 1, p_c)\n  tibble(f, a, c, u)\n}\n# simular datos intervenidos (suponiendo que conocemos todo)\nsim_int_f <- function(n = 100, do_f = 0.3, efecto_a = 0.3){\n  a <- rnorm(n,  4 * do_f, 2)\n  u <- rnorm(n, 0, 1)\n  p_c <-  inv_logit(-6 + efecto_a * a +  2 * u)\n  c <- rbinom(n, 1, p_c)\n  tibble(do_f = do_f, media_c = mean(c))\n}\n\n\nset.seed(4481)\nsims_fd <- simular_fd(5000)\nsims_fd_1 <- simular_fd(10000)\nqplot(sims_fd$f, sims_fd$a)\n\nWarning: `qplot()` was deprecated in ggplot2 3.4.0.\n\n\n\n\n\n¿Cómo se ve la relación de fumador con cáncer? En esta gráfica mostramos también el valor de la variable no observada \\(U\\). Nótese que parte de la correlación positiva que existe es debido a esta variable \\(U\\).\n\nggplot(sims_fd, aes(x = f, y = c, colour = u)) + \n  geom_jitter() + scale_colour_continuous(type = \"viridis\")\n\n\n\n\nAhora veamos cómo se ve el efecto de \\(F\\) sobre \\(C\\) y también cómo se ve el cruce de \\(F\\) y \\(C\\) en los datos naturales:\n\nsims_1 <- map_df(seq(1, 4, 0.5), ~ sim_int_f(100000, .x))\n\nsims_1 |> \n  ggplot() + geom_line(aes(x = do_f, y = media_c)) +\n  geom_smooth(data = sims_fd_1, aes(x = f, y = c), method = \"loess\", span = 0.3, se = FALSE, colour =\"red\") + xlab(\"Grado de tabaquismo\") +\n  xlim(c(1,4))\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 376 rows containing non-finite values (`stat_smooth()`).\n\n\n\n\n\nEn efecto causal promedio de fumar, en cada nivel, sobre la incidencia de cáncer de pulmón, suponiendo nuestro proceso generador. Nótese que la relación no es tan fuerte como observamos en los datos naturales (en rojo). Esto se debe a que en los datos naturales, las personas existe una causa común entre no fumar y prevenir cáncer de pulmón.\n\n\nEjemplo: estimación con puerta delantera\nVeamos cómo sería la estimación si tuviéramos datos disponible, y si es que podemos recuperar el efecto correcto dados los datos observados y la técnica de puerta delantera.\nNótese que sólo necesitamos \\(p(c|a, f), p(a|f)\\) y \\(p(f)\\). Estos son modelos estadísticos con el que podemos identificar el efecto que nos interesa. Una vez que los estimemos, podemos usar simulación:\n\nFijamos una \\(f\\).\nSimulamos una \\(a\\) del modelo \\(p(a|f)\\)\nPara calcular \\(\\int p(c|a,f')p(f')\\), tenemos que simular un valor \\(f'\\) de la marginal de \\(p(f)\\), y luego, sustituir junto la \\(a\\) de 1 para simular una \\(c\\) de \\(p(c|a, f')\\).\nConsideramos solamente \\(c\\) y \\(f\\) para resumir el efecto.\n\n\nset.seed(481)\nsims_fd <- simular_fd(2000)\nmod_front_door <- cmdstan_model(\"../src/front-door-2.stan\")\nprint(mod_front_door)\n\ndata {\n  int<lower=0> N;\n  int<lower=0> n_f;\n  vector[N] f;\n  vector[N]  a;\n  array[N]  int<lower=0, upper=1> c;\n  array[n_f] real do_f;\n\n}\n\ntransformed data {\n  real media_a;\n  real media_f;\n\n  media_a = mean(a);\n  media_f = mean(f);\n}\n\nparameters {\n  real<lower=0> alpha;\n  real alpha_a;\n  real<lower=0> alpha_f;\n  real int_a;\n  real beta_0;\n  real<lower=0> beta_1;\n  real<lower=0> beta;\n  real<lower=0> a_f;\n  real<lower=0> b_f;\n  real<lower=0> sigma_a;\n  real<lower=0> sigma_f;\n\n}\n\n\n\ntransformed parameters {\n\n\n}\n\nmodel {\n  f ~ gamma(a_f, b_f);\n  a ~ normal(beta * f, sigma_a);\n  c ~ bernoulli_logit(int_a + alpha_a * a + alpha_f * f);\n  alpha_a ~ normal(0, 1);\n  alpha_f ~ normal(0, 1);\n  int_a ~ normal(0, 3);\n  sigma_a ~ normal(0, 1);\n  sigma_f ~ normal(0, 0.1);\n  alpha ~ normal(0, 1);\n  beta ~ normal(0, 1);\n  beta_0 ~ normal(0, 3);\n  beta_1 ~ normal(0, 1);\n\n}\ngenerated quantities {\n  array[n_f] real mean_c;\n\n  for(i in 1:n_f){\n    array[2000] real res_sim;\n    for(j in 1:2000){\n      real a_sim = normal_rng(beta * (do_f[i]), sigma_a);\n      real f_sim = gamma_rng(a_f, b_f);\n      res_sim[j] = bernoulli_rng(inv_logit(int_a + alpha_a * a_sim + alpha_f * f_sim));\n    }\n    mean_c[i] = mean(res_sim);\n  }\n\n}\n\n\n\ndo_f <- seq(1, 4, 0.1)\nn_f <- length(do_f)\nsims <- mod_front_door$sample(data = list(N = nrow(sims_fd),\n      f = sims_fd$f, a = sims_fd$a,\n      c = sims_fd$c, do_f = do_f, n_f = n_f),\n  init = 0.01, step_size = 0.01, \n  refresh = 1000,\n  parallel_chains = 4)\n\nRunning MCMC with 4 parallel chains...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 4 finished in 75.6 seconds.\nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 finished in 78.0 seconds.\nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 2 finished in 78.4 seconds.\nChain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 3 finished in 79.2 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 77.8 seconds.\nTotal execution time: 79.4 seconds.\n\n\n\nsims_efecto_tbl <- sims$draws(\"mean_c\", format = \"df\") |> \n  pivot_longer(cols = contains(\"mean_c\"), values_to = \"media_c\") |> \n  separate(name, c(\"nom\", \"id\"), \n    sep = \"[\\\\[\\\\]]\", convert = TRUE, extra = \"drop\") |> \n  left_join(tibble(f = do_f) |> \n  mutate(id = seq_along(f))) \nresumen_tbl <- sims_efecto_tbl |> \n  group_by(id, f) |> \n  summarise(media = mean(media_c), \n    q5 = quantile(media_c, 0.05),\n    q95 = quantile(media_c, 0.95))\n\n\nggplot(resumen_tbl) + \n  geom_linerange(aes(x= f, ymax = q95, ymin = q5), colour = \"red\") + \n  geom_point(aes(x = f, y = media), colour = \"red\") +\n  geom_line(data = sims_1, aes(x = do_f, y = media_c)) +\n  xlab(\"Nivel de tabaquismo\") + ylab(\"Prop afectada\")\n\n\n\n\nY parece que hemos obtenido una estimación razonable del efecto causal de fumar sobre cáncer. Recordemos también que debemos ser cuidadosos al comparar intervalos que salen del mismo modelo por su nivel de traslape.\nPor ejemplo, si quisiéramos calcular contrastes con el nivel 2 de tabaquismo:\n\nefecto_2 <- sims_efecto_tbl |> filter(f == 2) |> \n  select(.draw, efecto_2 = media_c)\ncomp_tbl <- left_join(sims_efecto_tbl, efecto_2) |> \n  mutate(dif_2 = media_c - efecto_2)\n\nJoining, by = \".draw\"\n\ncomp_tbl |> group_by(f) |> \n  summarise(media = mean(dif_2), q5 = quantile(dif_2, 0.05),\n            q95 = quantile(dif_2, 0.95)) |> \nggplot() + geom_linerange(aes(x= f, ymax = q95, ymin = q5)) + geom_point(aes(x = f, y = media))  +\n  xlab(\"Nivel de tabaquismo\") + ylab(\"Prop afectada\")\n\n\n\n\nNota: nótese como en este ejemplo hemos evitado incluir en nuestro modelo la variable no observada \\(U\\), gracias al procedimiento de puerta delantera descrito arriba.\nEs posible sin embargo intentar un modelo completo bayesiano, sin necesidad de recordar la fórmula. El procedimiento, que es más difícil de ajustar: considera una variable latente \\(U\\) no observada, y es necesario definir cómo puede ser su relación con sus descendientes. Es necesario más cuidado en definir formas funcionales e iniciales apropiadas para que los muestreadores funcionen apropiadamente."
  },
  {
    "objectID": "03-modelos-causales.html#mediación-y-datos-de-berkeley",
    "href": "03-modelos-causales.html#mediación-y-datos-de-berkeley",
    "title": "3  Modelos causales e inferencia",
    "section": "3.10 Mediación y datos de Berkeley",
    "text": "3.10 Mediación y datos de Berkeley\nCuando existen distintas rutas causales entre una variable que intervenimos y un resultado, muchas veces es relevante intentar separar los efectos directos del tratamiento de aquellos que están mediados por otras variables.\nEn general, entender separar efectos directos o mediados requiere más supuestos que entender efectos totales sobre todas las posibles rutas causales.\n\n3.10.1 Ejemplo: Admisiones de Berkeley\nEn 1973 se recolectaron datos agregados de solicitantes para estudiar en Berkeley para los 6 departamentos más grandes, clasificados por sexo del solicitante y si fue admitido o no. Los resultados se muestran a continuación:\n\ndata(\"UCBAdmissions\")\nadm_original <- UCBAdmissions |> as_tibble() |> \n   pivot_wider(names_from = Admit, values_from = n) \nadm_indiv <- UCBAdmissions |> as_tibble() |> \n  mutate(Gender = ifelse(Gender==\"Female\", 2, 1)) |> \n  mutate(Dept = factor(Dept) |> as.integer()) |> \n  mutate(Admit = ifelse(Admit == \"Admitted\", 1, 0)) |> \n  uncount(n)\nadm_indiv |> head() \n\n# A tibble: 6 × 3\n  Admit Gender  Dept\n  <dbl>  <dbl> <int>\n1     1      1     1\n2     1      1     1\n3     1      1     1\n4     1      1     1\n5     1      1     1\n6     1      1     1\n\n\nComenzaremos construyendo nuestro modelo causal:\n\nGénero es una causa con el departamento que seleccionan los aplicantes, en primer lugar porque ya sea por educación o otras razones distintos géneros prefieren distintas carreras\nLos departamentos también son una causa de aceptación de aplicantes. Algunos departamentos tienen más aplicantes o menos capacidad, y los que deciden son diferentes personas.\nConsideramos que Género también puede ser una causa directa de admisión, y puede haber favoritismo por algún género.\n\nNuestro primer diagrama, que criticaremos más adelante, se ve cómo sigue:\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n  node [shape=plaintext]\n    G\n    D\n    A \n  #node [shape = circle]\n  #  U\n  edge [minlen = 3]\n    G -> D\n    G -> A\n    D -> A\n{rank = same; G;A}\n}\n\")\n\n\n\n\n\n\nBajo estos supuestos, podemos calcular el efecto total de género en admisiones: para esto es importante no condicionar a departamento. Nuestro modelo es el siguiente:\n\nmod_1_berkeley <- cmdstan_model(\"../src/berkeley-1.stan\")\nprint(mod_1_berkeley)\n\ndata {\n  int<lower=0> N;\n  int<lower=0> n_d;\n  array[N] int admit;\n  array[N] int gender;\n  array[N] int dept;\n}\ntransformed data {\n  array[N] int gender_ind;\n\n  for(i in 1:N){\n    gender_ind[i] = 0;\n    if(gender[i] == 2) {\n      gender_ind[i] = 1;\n    }\n  }\n}\n\nparameters {\n  real beta_0;\n  array[2] vector[n_d] beta;\n  matrix[2, n_d] alpha;\n}\n\n\nmodel {\n  for(i in 1:N){\n    admit[i] ~ bernoulli_logit(alpha[gender[i], dept[i]]);\n    dept[i] ~ categorical_logit(beta[gender[i]]);\n  }\n  gender_ind ~ bernoulli_logit(beta_0);\n  beta_0 ~ normal(0, 0.5);\n  for(i in 1:2){\n    beta[i] ~ normal(0, 1);\n    alpha[i] ~ normal(0, 1);\n  }\n}\n\ngenerated quantities{\n  real contraste_m_h;\n  real admit_prob_mujer;\n  real admit_prob_hombre;\n\n  {\n    int gender_do = 2;\n    array[1000] real admit_prob_mujer_ind;\n    for(j in 1:1000){\n      int dept_sim = categorical_logit_rng(beta[gender_do]);\n      admit_prob_mujer_ind[j] = bernoulli_logit_rng(alpha[gender_do, dept_sim]);\n    }\n    admit_prob_mujer = mean(admit_prob_mujer_ind);\n  }\n  {\n    int gender_do = 1;\n    array[1000] real admit_prob_hombre_ind;\n    for(j in 1:1000){\n      int dept_sim = categorical_logit_rng(beta[gender_do]);\n      admit_prob_hombre_ind[j] = bernoulli_logit_rng(alpha[gender_do, dept_sim]);\n    }\n    admit_prob_hombre = mean(admit_prob_hombre_ind);\n  }\n\n  contraste_m_h = admit_prob_mujer - admit_prob_hombre;\n\n}\n\n\n\ndatos_lista <- list(N = nrow(adm_indiv), n_d = 6,\n  admit = adm_indiv$Admit, gender = adm_indiv$Gender,\n  dept = adm_indiv$Dept)\najuste <- mod_1_berkeley$sample(data = datos_lista, \n          iter_warmup = 200, iter_sampling = 500,\n          refresh = 1000, parallel_chains = 4)\n\nRunning MCMC with 4 parallel chains...\n\nChain 1 Iteration:   1 / 700 [  0%]  (Warmup) \nChain 2 Iteration:   1 / 700 [  0%]  (Warmup) \nChain 3 Iteration:   1 / 700 [  0%]  (Warmup) \nChain 4 Iteration:   1 / 700 [  0%]  (Warmup) \nChain 3 Iteration: 201 / 700 [ 28%]  (Sampling) \nChain 4 Iteration: 201 / 700 [ 28%]  (Sampling) \nChain 1 Iteration: 201 / 700 [ 28%]  (Sampling) \nChain 2 Iteration: 201 / 700 [ 28%]  (Sampling) \nChain 4 Iteration: 700 / 700 [100%]  (Sampling) \nChain 4 finished in 131.2 seconds.\nChain 3 Iteration: 700 / 700 [100%]  (Sampling) \nChain 3 finished in 135.0 seconds.\nChain 1 Iteration: 700 / 700 [100%]  (Sampling) \nChain 1 finished in 137.8 seconds.\nChain 2 Iteration: 700 / 700 [100%]  (Sampling) \nChain 2 finished in 138.4 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 135.6 seconds.\nTotal execution time: 138.5 seconds.\n\nresumen_mod <- ajuste$summary() |> select(variable, mean, q5, q95)\nresumen_mod\n\n# A tibble: 29 × 4\n   variable          mean          q5          q95\n   <chr>            <dbl>       <dbl>        <dbl>\n 1 lp__      -13086.      -13092.     -13081.     \n 2 beta_0        -0.383       -0.432      -0.334  \n 3 beta[1,1]      0.687        0.0473      1.32   \n 4 beta[2,1]     -0.652       -1.31        0.00402\n 5 beta[1,2]      0.300       -0.343       0.938  \n 6 beta[2,2]     -2.06        -2.75       -1.33   \n 7 beta[1,3]     -0.243       -0.884       0.395  \n 8 beta[2,3]      1.05         0.388       1.69   \n 9 beta[1,4]      0.00421     -0.630       0.645  \n10 beta[2,4]      0.587       -0.0775      1.24   \n# … with 19 more rows\n\n\n\nsims_contraste <- ajuste$draws(\"contraste_m_h\", format = \"df\")\nggplot(sims_contraste, aes(x = contraste_m_h)) +\n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nY nuestra conclusión aquí es que el efecto total de género sobre admisión favorece a los hombres, y la diferencia es entre 20 y 8 puntos porcentuales aproximadamente.\nSin embargo, en este ejemplo vale la pena entender que estamos estimando el efecto de dos caminos causales (ver McElreath, Statistical Rethinking):\n\nPosible discriminación directa general porque una aplicación está identificada como “mujer”. Este es un efecto directo, lo que más propiamente llamaríamos discriminación de personas.\nPosible discriminación estructural por las carreras que escogen las personas. En este caso, quizá por ejemplo los departamentos de ingeniería son más fáciles de acceder, pero tradicionalmente no se alienta a las mujeres escoger ese tipo de carreras. Este efecto está mediado por la selección de departamento.\nEl efecto total es el que experimentan las personas, por cualquiera de las dos razones de arriba.\n\nCada una de estas razones son muy diferentes y llevan a distintas conclusiones acerca de los datos. Veremos ahora cómo, bajo el modelo que tenemos ahora, podemos intentar estimar el efecto directo de discriminación. En este caso, necesitamos bloquear la variable departamento, para ver sólo el efecto directo, y esto lo logramos estratificando por departamento.\nCalcularemos ahora \\(p(a | do(g = 1, d = d))\\) para cada departamento. El modelo no cambia, pero simulamos diferente:\n\nmod_2_berkeley <- cmdstan_model(\"../src/berkeley-2.stan\")\n\n\ndatos_lista <- list(N = nrow(adm_indiv), n_d = 6,\n  admit = adm_indiv$Admit, gender = adm_indiv$Gender,\n  dept = adm_indiv$Dept)\najuste <- mod_2_berkeley$sample(data = datos_lista, \n          iter_warmup = 200, iter_sampling = 500,\n          refresh = 1000, parallel_chains = 4)\n\nRunning MCMC with 4 parallel chains...\n\nChain 1 Iteration:   1 / 700 [  0%]  (Warmup) \nChain 2 Iteration:   1 / 700 [  0%]  (Warmup) \nChain 3 Iteration:   1 / 700 [  0%]  (Warmup) \nChain 4 Iteration:   1 / 700 [  0%]  (Warmup) \nChain 1 Iteration: 201 / 700 [ 28%]  (Sampling) \nChain 2 Iteration: 201 / 700 [ 28%]  (Sampling) \nChain 4 Iteration: 201 / 700 [ 28%]  (Sampling) \nChain 3 Iteration: 201 / 700 [ 28%]  (Sampling) \nChain 1 Iteration: 700 / 700 [100%]  (Sampling) \nChain 1 finished in 132.4 seconds.\nChain 3 Iteration: 700 / 700 [100%]  (Sampling) \nChain 3 finished in 140.5 seconds.\nChain 4 Iteration: 700 / 700 [100%]  (Sampling) \nChain 4 finished in 141.0 seconds.\nChain 2 Iteration: 700 / 700 [100%]  (Sampling) \nChain 2 finished in 141.5 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 138.9 seconds.\nTotal execution time: 141.6 seconds.\n\nresumen_mod <- ajuste$summary() |> select(variable, mean, q5, q95)\nresumen_mod\n\n# A tibble: 45 × 4\n   variable         mean          q5         q95\n   <chr>           <dbl>       <dbl>       <dbl>\n 1 lp__      -13086.     -13092.     -13081.    \n 2 beta_0        -0.382      -0.433      -0.330 \n 3 beta[1,1]      0.705      -0.0265      1.37  \n 4 beta[2,1]     -0.645      -1.32        0.0387\n 5 beta[1,2]      0.320      -0.403       0.977 \n 6 beta[2,2]     -2.06       -2.76       -1.34  \n 7 beta[1,3]     -0.225      -0.950       0.445 \n 8 beta[2,3]      1.05        0.391       1.72  \n 9 beta[1,4]      0.0247     -0.700       0.686 \n10 beta[2,4]      0.595      -0.0583      1.26  \n# … with 35 more rows\n\n\n\nsims_contraste <- ajuste$draws(\"contraste_m_h\", format = \"df\") |> \n  pivot_longer(cols = contains(\"contraste\")) |> \n  separate(name, into = c(\"nombre\", \"dept\"), sep = \"[\\\\[\\\\]]\", extra = \"drop\")\n\nWarning: Dropping 'draws_df' class as required metadata was removed.\n\nggplot(sims_contraste, aes(x = value, fill = dept)) +\n  geom_density(alpha = 0.5)\n\n\n\n\nDonde vemos que los departamentos varían en la diferencia de aceptación de hombres y mujeres.\nEl efecto directo (en este caso se llama efecto directo controlado) no es conclusivo, aunque parece favorecer ligeramente a mujeres.\nEn algún momento de la discusión, este argumento fue mostrado para decir que no había discriminación en Berkeley específicamente orientado hacia las mujeres, aún cuando quedaba por investigar por qué el contraste de tasas de aceptación es tan diferente en cada departamento (puede haber muchas razones). Sin embargo, otros investigadores apuntaron al hecho de que la selección de departamentos y la tasa de aceptación puede tener una causa común: por ejemplo, la habilidad general.\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n  node [shape=plaintext]\n    G\n    D\n    A \n  node [shape = circle]\n    U\n  edge [minlen = 3]\n    G -> D\n    G -> A\n    D -> A\n    U -> D\n    U -> A\n{rank = same; G;A}\n{rank = same; U}\n}\n\")\n\n\n\n\n\n\n\n\n\n\n\n\nMediación con variables confusoras\n\n\n\nSi existen variables confusoras entre la variable \\(D\\) que media el efecto de otra variable y el resultado \\(A\\), \\(D\\) se convierte en un colisionador. Cuando condicionamos a \\(D\\) para estimar el efecto directo (que es un colisionador), activamos una ruta no causal entre \\(G\\) y \\(A\\) que va a través de \\(U\\). En este caso, el efecto directo no está identificado.\n\n\nAunque podemos calcular el efecto total de género sobre admisión, no es posible extraer en este caso el efecto directo. Por ejemplo (McElreath), una hipótesis que se ha planteado es la siguiente:\n\nSupongamos que existen departamentos que se sabe que discriminan o tienen prácticas discriminatorias. Las personas que aplican a esos departamentos que son suceptibles a esta discriminación tienden a ser personas de mayor habilidad que el aplicante típico, pues sólo en ese caso están dispuestas a sufrir tal discriminación. Esto implica que también su tasa de aceptación sin discriminación sería más alta por su mayor habilidad, pero en los datos no lo vemos. En este caso, puede haber discriminación directa que acaba enmascarada por esa autoselección.\n\nEn este caso no tenemos la variable de habilidad, pero podríamos hacer análisis de sensibilidad. En el siguiente modelo, consideramos hipotéticamente qué pasaría si en el departamento 2 tuviera la imagen (justificada o no) de ser un ambiente discriminatorio:\n\nmod_3_berkeley <- cmdstan_model(\"../src/berkeley-3.stan\")\nprint(mod_3_berkeley)\n\ndata {\n  int<lower=0> N;\n  int<lower=0> n_d;\n  array[N] int admit;\n  array[N] int gender;\n  array[N] int dept;\n  vector[2] delta;\n  matrix[2, 6] eta;\n}\ntransformed data {\n  array[N] int gender_ind;\n\n  for(i in 1:N){\n    gender_ind[i] = 0;\n    if(gender[i] == 2) {\n      gender_ind[i] = 1;\n    }\n  }\n}\n\nparameters {\n  real beta_0;\n  array[2] vector[n_d] beta;\n  matrix[2, n_d] alpha;\n  vector[N] u; // habilidad latente\n}\n\n\nmodel {\n  for(i in 1:N){\n    // la variable u influye en la tasa de aceptación\n    admit[i] ~ bernoulli_logit(alpha[gender[i], dept[i]] + delta[gender[i]] * u[i]);\n    // la variable u influye en la eleccion de departamento\n    dept[i] ~ categorical_logit(beta[gender[i]] + to_vector(eta[gender[i]]) * u[i]);\n  }\n  gender_ind ~ bernoulli_logit(beta_0);\n  beta_0 ~ normal(0, 0.5);\n  for(i in 1:2){\n    beta[i] ~ normal(0, 1);\n    alpha[i] ~ normal(0, 1);\n  }\n  u ~ normal(0, 1);\n}\n\ngenerated quantities{\n  array[n_d] real contraste_m_h;\n  real contraste_directo;\n  array[n_d] real admit_prob_mujer;\n  array[n_d] real admit_prob_hombre;\n\n  // simulaciones para un aplicante promedio\n  for(k in 1:n_d){\n    int gender_do = 2;\n    array[1000] real admit_prob_mujer_ind;\n    for(j in 1:1000){\n      admit_prob_mujer_ind[j] = bernoulli_logit_rng(alpha[gender_do, k]);\n    }\n    admit_prob_mujer[k] = mean(admit_prob_mujer_ind);\n\n    gender_do = 1;\n    array[1000] real admit_prob_hombre_ind;\n    for(j in 1:1000){\n      admit_prob_hombre_ind[j] = bernoulli_logit_rng(alpha[gender_do, k]);\n    }\n    admit_prob_hombre[k] = mean(admit_prob_hombre_ind);\n\n  contraste_m_h[k] = admit_prob_mujer[k] - admit_prob_hombre[k];\n  }\n\n  contraste_directo = mean(contraste_m_h[dept]);\n\n}\n\n\n\n\n\n\n\n\nVariables latentes\n\n\n\nEn este modelo, \\(u\\) es una variable a nivel individuo. No conocemos su valor pero influye en \\(D\\) y \\(A\\) directamente. Si sabemos algo de la naturaleza de esta influencia, es posible extraer informacion acerca de los valores \\(u\\) de cada individuo.\nDesde el punto de vista bayesiano, los valores que toma esta variable son parámetros a estimar.\n\n\nPor ejemplo, si una mujer es aceptada a un departamento que aparenta actividades descriminatorias, por las razones explicadas arriba podemos deducir que su nivel de habilidad es en general mayor que el aplicantes hombres, y eso puede explicar por qué aún cuando las tasas de aceptación el departamento sean similares, existe una componente de discriminación.\nEn este ejercicio haremos un análisis de sensibilidad de nuestras hipótesis. Supondremos que los niveles de habilidad en general ayudan a entrar en cualquier departamento, pero que la probabilidad de que una mujer aplique a un departamento discriminatorio sólo es alta si su nivel de habilidad es alto (ver los variables delta y eta en el siguiente modelo):\n\ndatos_lista <- list(N = nrow(adm_indiv), n_d = 6,\n  admit = adm_indiv$Admit, gender = adm_indiv$Gender,\n  dept = adm_indiv$Dept)\n## incluimos coeficientes fijos para la relación de habilidad\n## con selección de departamente y adimisión\ndatos_lista <- c(datos_lista,\n  #habilidad ayuda en todos los departamentos\n  list(delta = c(1, 1),\n  #pero los de habilidad alta intentan a aplicar al departamento 2.\n  eta = matrix(c(c(0, 0, 0, 0, 0, 0), c(0, 0, 0, 0, 2, 0)), nrow= 2, byrow = T))\n)\najuste_disc <- mod_3_berkeley$sample(data = datos_lista, \n          iter_warmup = 300, iter_sampling = 1000,\n          refresh = 1000, parallel_chains = 4)\n\nRunning MCMC with 4 parallel chains...\n\nChain 1 Iteration:    1 / 1300 [  0%]  (Warmup) \nChain 2 Iteration:    1 / 1300 [  0%]  (Warmup) \nChain 3 Iteration:    1 / 1300 [  0%]  (Warmup) \nChain 4 Iteration:    1 / 1300 [  0%]  (Warmup) \nChain 1 Iteration:  301 / 1300 [ 23%]  (Sampling) \nChain 4 Iteration:  301 / 1300 [ 23%]  (Sampling) \nChain 3 Iteration:  301 / 1300 [ 23%]  (Sampling) \nChain 2 Iteration:  301 / 1300 [ 23%]  (Sampling) \nChain 1 Iteration: 1300 / 1300 [100%]  (Sampling) \nChain 1 finished in 645.8 seconds.\nChain 4 Iteration: 1300 / 1300 [100%]  (Sampling) \nChain 4 finished in 649.0 seconds.\nChain 3 Iteration: 1300 / 1300 [100%]  (Sampling) \nChain 3 finished in 651.4 seconds.\nChain 2 Iteration: 1300 / 1300 [100%]  (Sampling) \nChain 2 finished in 655.3 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 650.4 seconds.\nTotal execution time: 655.4 seconds.\n\nresumen_disc_mod <- ajuste_disc$summary() |> select(variable, mean, q5, q95)\nresumen_disc_mod\n\n# A tibble: 4,571 × 4\n   variable         mean          q5        q95\n   <chr>           <dbl>       <dbl>      <dbl>\n 1 lp__      -14726.     -14805.     -14647    \n 2 beta_0        -0.382      -0.431      -0.332\n 3 beta[1,1]      0.702       0.0495      1.36 \n 4 beta[2,1]     -0.531      -1.22        0.140\n 5 beta[1,2]      0.315      -0.321       0.984\n 6 beta[2,2]     -1.94       -2.67       -1.25 \n 7 beta[1,3]     -0.230      -0.882       0.435\n 8 beta[2,3]      1.17        0.485       1.84 \n 9 beta[1,4]      0.0196     -0.637       0.686\n10 beta[2,4]      0.711       0.0254      1.37 \n# … with 4,561 more rows\n\n\n\nsims_contraste_disc <- ajuste_disc$draws(\"contraste_m_h\", format = \"df\") |> \n  pivot_longer(cols = contains(\"contraste\")) |> \n  separate(name, into = c(\"nombre\", \"dept\"), sep = \"[\\\\[\\\\]]\", extra = \"drop\")\n\nWarning: Dropping 'draws_df' class as required metadata was removed.\n\nsims_2 <- sims_contraste_disc |> mutate(tipo = \"Con habilidad (hipotético)\") |> \n  bind_rows(sims_contraste |> mutate(tipo = \"Ingorando habilidad\"))\n\nggplot(sims_2, aes(x = value, fill = dept)) +\n  geom_density(alpha = 0.5) + facet_wrap(~ tipo, ncol = 1)\n\n\n\n\nNotamos que los resultados para el “departamento discriminatorio” efectivamente indica un efecto directo más grande que favorece a hombres. Nótese como en este ejemplo el efecto de selección de departamento para mujeres es relativamente fuerte (alta habilidad tiende a ir a departamento 5), los efectos para el resto de los departamentos son contrarios: algunos se mueven a la derecha, es decir, parece haber má ventaja para mujeres. Esto es porque el departamento 5 absorbe desproporcionadamente a mujeres de habilidad alta, lo que implica q ue la habilidad promedio de mujeres en otros departamentos es más baja que la de los hombres.\n\n\n\n\n\n\nAnálisis de sensibilidad\n\n\n\nSi existe la posibilidad de variables confusoras, podemos hacer ejericicios de modelación/simulación para estimar qué tan fuertes tendría que ser la relación de la variable confusora para producir resultados que cambien nuestras conclusiones.\n\n\n\n\nEjemplo (Burks, Pearl)\nEste ejemplo es mencionado por Pearl en The Book of Why. En 1926 Burks recolectó datos sobre qué tanto podría esperarse que la inteligencia de padres se hereda a los hijos (medido según una prueba de IQ). Construyó un diagrama parecido al de abajo:\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n  node [shape = circle]\n    U\n  node [shape=plaintext]\n  edge [minlen = 3]\n    IntPadres -> NSE\n    NSE -> IntHijos\n    U -> NSE\n    U -> IntHijos\n    IntPadres -> IntHijos\n{rank = same; U}\n}\n\")\n\n\n\n\n\n\nComo el NSE es del hogar (una medida general de estatus social), se consideró en principio como una variable pre-tratamiento a la inteligencia de los niños por la que tradicionalmente se controlaba. Burks notó que hacer esto tenía como consecuencia cortar parte del efecto total de la inteligencia sobre el la inteligencia de los hijos. Adicionalmente, condicionar a NSE abre un camino no causal entre Inteligencia de Padres e Hijos."
  },
  {
    "objectID": "03-modelos-causales.html#controles-buenos-y-malos",
    "href": "03-modelos-causales.html#controles-buenos-y-malos",
    "title": "3  Modelos causales e inferencia",
    "section": "3.11 Controles buenos y malos",
    "text": "3.11 Controles buenos y malos\nEn los análisis anteriores muchas veces buscamos construir modelos estadísticos \\(p(y|t, z)\\), donde \\(z\\) son variables por las que controlamos (o estratificamos) para obtener el efecto causal de \\(t\\) sobre \\(y\\) (es decir, estimar \\(p(y|t, z)\\)).\nArriba mostramos (criterio de puerta trasera) que las variables \\(z\\) deben bloquear puertas traseras al tratamiento, no bloquear efectos causales de \\(t\\), y no activar caminos no causales.\nEn Cinelli, Forney, y Pearl, Pearl et al. A Crash Course in Good and Bad Controls muestran diversos ejemplos de buenos y malos controles (variables para incluir en \\(z\\)). Estas ideas aplican tanto a datos observacionales como experimentales.\n\n\n\n\nCinelli, Carlos, Andrew Forney, y Judea Pearl. «A Crash Course in Good and Bad Controls». Sociological Methods & Research 0 (0): 00491241221099552. https://doi.org/10.1177/00491241221099552.\n\n\nMcElreath, Richard. 2015. Statistical Rethinking, A Course in R and Stan. http://xcelab.net/rmpubs/rethinking/Statistical_Rethinking_sample.pdf."
  },
  {
    "objectID": "04-experimentos.html#controles-buenos-o-neutros",
    "href": "04-experimentos.html#controles-buenos-o-neutros",
    "title": "4  Experimentos y controles",
    "section": "4.1 Controles buenos o neutros",
    "text": "4.1 Controles buenos o neutros\nConsideramos el siguiente diagrama: en este caso, \\(Z\\) causa variación en \\(Y\\). Controlar por \\(Y\\) puede mejorar la precisión de nuestras estimaciones causales, sin abrir ningún camino no causal (Modelo 8 en Cinelli, Forney, y Pearl, A Crash Course in Good and Bad Controls) :\n\n\nCódigo\ngrViz('\ndigraph {\n  graph [ranksep = 0.2, rankdir = LR]\n  subgraph caso_1 {\n    node [shape=plaintext]\n    Z [fontcolor=\"red\"]\n    edge [minlen = 3]\n    Z -> Y\n    T -> Y\n  }\n}\n', width = 250, height = 60)\n\n\n\n\n\n\n\n4.1.1 Ejemplo\nQueremos probar un tratamiento para reducir peso. Aleatorizaremos las personas al tratamiento (por ejemplo una medicina), y antes de comenzar el estudio registramos su peso inicial y estatura. Nuestro diagrama es el siguiente, donde incluímos también el peso inicial que influye en el peso final después del tratamiento, y otras variables no observadas que influyen tanto en peso final como peso inicial (por ejemplo, si las personas estuvieron haciendo alguna dietas o no). También medimos una cantidad, al final del experimento, que es bienestar general de la persona (o una calificación de su estado de salud general). Adicionalmente medimos una variable \\(C\\) (cansancio), pues sabemos que esta medicina puede tener ese efecto. El cansancio puede afectar el peso final pues los niveles de actividad pueden cambiar. \\(B\\) puede ser en este caso una medición de circunferencia de abdomen, por ejemplo.\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2, rankdir=LR]\n  node[shape=circle]\n      U\n      V\n  node [shape=plaintext]\n    T\n  edge [minlen = 3]\n   #G -> H\n   #H -> PI\n   T -> PF\n   #G -> PF\n   PI -> PF\n   U -> PI\n   U -> PF\n   V -> PF\n   T -> C -> PF\n   PF -> B\n}\n\")\n\n\n\n\n\n\nNo hay ninguna variable confusora, y una estrategia de estimación es comparar \\(PF\\) entre los grupos.\n\nsim_peso <- function(n){\n  T <- rbinom(n, 1, 0.5)\n  C <- rbinom(n, 1, 1/(1+exp(-(-2 + 4 * T))))\n  U <- rnorm(n, 0, 5)\n  G <- rbinom(n, 1, 0.5)\n  H <- rnorm(n, 170 - 10 * G, 20)\n  PI <- rnorm(n, -20 +  0.5 * H + U, 10)\n  PF <- rnorm(n, PI + U - 20 * T + 3 * C , 5)\n  #V <- PF - (PI + U - 10 * T + 2 * C)\n  B <- rbinom(n, 1, 1/(1 + exp(-(PF-50)/7)))\n  tibble(G, H, T, PI, PF, B, C)\n}\nset.seed(26)\npeso_tbl <- sim_peso(1200)\npeso_tbl\n\n# A tibble: 1,200 × 7\n       G     H     T    PI    PF     B     C\n   <int> <dbl> <int> <dbl> <dbl> <int> <int>\n 1     1  186.     0  73.4  80.9     1     1\n 2     0  173.     0  63.4  72.2     1     0\n 3     1  180.     1  67.4  52.6     0     1\n 4     1  159.     1  56.3  39.2     0     0\n 5     1  135.     0  36.0  36.6     0     0\n 6     0  194.     0  74.5  77.9     1     0\n 7     0  152.     1  45.9  25.4     0     1\n 8     1  189.     1  72.4  44.1     0     1\n 9     1  136.     0  41.6  43.9     1     0\n10     1  168.     1  67.4  43.8     1     1\n# … with 1,190 more rows\n\n\nEn aplicaciones realidad, no sabemos cuál es el efecto causal, pero en ejemplos simulados sí podemos calcularlo. En este caso, hacemos la siguiente simulación para tener nuestra referencia:\n\npeso_sims_tbl <- sim_peso(100000)\npeso_sims_tbl |> group_by(T) |> \n  summarise(peso_final_medio = mean(PF)) |> \n  arrange(T) |> \n  mutate(dif = peso_final_medio - lag(peso_final_medio))\n\n# A tibble: 2 × 3\n      T peso_final_medio   dif\n  <int>            <dbl> <dbl>\n1     0             62.7  NA  \n2     1             45.0 -17.8\n\n\nPodemos hacer simplemente\n\nlm(PF ~ T, peso_tbl) |> broom::tidy()\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic  p.value\n  <chr>          <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)     62.1     0.742      83.7 0       \n2 T              -17.5     1.06      -16.6 7.05e-56\n\n\ny el coeficiente de \\(T\\) sería una estimación del efecto causal promedio. Sin embargo, si condicionamos a \\(PI\\) tampoco creamos ninguna ruta no causal entre \\(T\\) y \\(PF\\). Podemos hacer también\n\nlm(PF ~ T + PI, peso_tbl) |> broom::tidy()\n\n# A tibble: 3 × 5\n  term        estimate std.error statistic   p.value\n  <chr>          <dbl>     <dbl>     <dbl>     <dbl>\n1 (Intercept)    -6.11    0.836      -7.31 4.91e- 13\n2 T             -17.7     0.393     -45.0  2.72e-259\n3 PI              1.10    0.0127     86.5  0        \n\n\nY notamos que nuestra estimación es más precisa. Esto es porque \\(PI\\) absorbe una parte importante de la variación de PF. Al incluir este control no cambiamos la cantidad que estamos estimando, pero sí el estimador particular, que en este caso tiene menos incertidumbre.\n\n\n\n\n\n\nTip\n\n\n\nNótese que no necesariamente podemos interpetar el coeficiente de \\(PI\\) fácilmente, pues existen rutas no casuales activas entre \\(PF\\) y \\(PI\\). Como explicamos antes, un modelo que se usa para identificar un efecto causal particular no implica que puedan interpretarse como causales otros coeficientes."
  },
  {
    "objectID": "04-experimentos.html#malos-controles-sobrecontrol",
    "href": "04-experimentos.html#malos-controles-sobrecontrol",
    "title": "4  Experimentos y controles",
    "section": "4.2 Malos controles: sobrecontrol",
    "text": "4.2 Malos controles: sobrecontrol\nEn los siguientes diagramas, condicionar por \\(Z\\) corta parte del efecto causal de \\(T\\) sobre \\(Y\\) (modelos 11 y 12 de Cinelli, Forney, y Pearl):\n\n\nCódigo\ngrViz('\ndigraph {\n  graph [ranksep = 0.2, rankdir = LR]\n  subgraph caso_1 {\n    node [shape=plaintext]\n    Z [fontcolor=\"red\"]\n    edge [minlen = 3]\n    T -> Z\n    Z -> Y\n    T -> Y\n  }\n  \n  subgraph caso_2 {\n    node [shape=plaintext]\n    Ya [label=\"Y\"]\n    Ta [label=\"T\"]\n    Za [label=\"Z\"][fontcolor=\"red\"]\n    edge [minlen = 3]\n    Ta -> M\n    M -> Ya\n    M -> Za\n    Ta -> Ya\n  }\n}\n', width = 250, height = 120)\n\n\n\n\n\n\n\nlm(PF ~ T +  C, peso_tbl) |> broom::tidy()\n\n# A tibble: 3 × 5\n  term        estimate std.error statistic  p.value\n  <chr>          <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)    61.7      0.767     80.5  0       \n2 T             -20.1      1.64     -12.2  1.53e-32\n3 C               3.29     1.64       2.01 4.52e- 2\n\nlm(PF ~ T +  PI + C, peso_tbl) |> broom::tidy()\n\n# A tibble: 4 × 5\n  term        estimate std.error statistic   p.value\n  <chr>          <dbl>     <dbl>     <dbl>     <dbl>\n1 (Intercept)    -6.56    0.828      -7.92 5.31e- 15\n2 T             -20.4     0.601     -33.9  7.44e-177\n3 PI              1.10    0.0125     87.7  0        \n4 C               3.55    0.601       5.90 4.77e-  9\n\n\nY vemos que nuestra estimación del efecto del tratamiento está sesgada, aparentando ser más efectiva de lo que es. La razón es que el camino que pasa por \\(C\\) “daña” en lugar de ayudar. El efecto causal total toma en cuenta tanto beneficios como daños."
  },
  {
    "objectID": "04-experimentos.html#malos-controles-variables-post-tratamiento",
    "href": "04-experimentos.html#malos-controles-variables-post-tratamiento",
    "title": "4  Experimentos y controles",
    "section": "4.3 Malos controles: variables post-tratamiento",
    "text": "4.3 Malos controles: variables post-tratamiento\nVariables que son efectos de la variable respuesta que nos interesa son en general malos controles. Es un caso particular de cómo se produce sesgo casos-control (por ejemplo, cuando seleccionamos individuos para observar dependiendo de una variable post-tratamiento). Para entender eso, agregamos explícitamente nodos que usualmente no mostramos en nuestros diagramas (están ahí implícitamente), que son efectos sobre \\(Y\\) que no tienen conexiones causales con otras partes del diagrama:\n\n\nCódigo\ngrViz('\ndigraph {\n  graph [ranksep = 0.2, rankdir = LR]\n  subgraph caso_1 {\n    node[shape= circle]\n    U_y\n    node [shape=plaintext]\n    Z [fontcolor=\"red\"]\n    edge [minlen = 3]\n    Y -> Z\n    T -> Y  \n    U_y -> Y\n  }\n}\n', width = 250, height = 120)\n\n\n\n\n\n\nHemos añadido un nodo implícito (otros factores que afectan \\(Y\\) y no tienen relación con otras variables del sistema) para explicar qué es lo que pasa cuando condicionamos a \\(Z\\): como \\(Z\\) es un descendiente del colisionador en \\(Y\\), se activa una ruta no causal entre \\(U_y\\) y \\(T\\), y estas dos cantidades aparecen como correlacionadas (es una correlación no causal). Esto en consecuencia modifica la correlación entre \\(T\\) y \\(Y\\).\n\nEjemplo\nEn nuestro ejemplo, podemos comparar las pendientes condicionando o no a la variable \\(B\\): vemos que dentro de cada grupo de \\(B\\), la pendiente es más chica que la que sugiere el efecto del tratamiento:\n\nggplot(peso_tbl, aes(x = T, y = PF, colour = factor(B))) +\n  geom_jitter() + \n   geom_smooth(method = \"lm\") +\n  geom_smooth(formula = \"y~ 1+x\", method = \"lm\", colour = \"red\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nComo vemos, la pendiente en cada grupo de \\(B\\) es más baja que la que obtendríamos si no condicionáramos a \\(B\\). Podemos explicarlo así, bajo el supuesto de que el tratamiento tiene algún efecto:\n\nEn el grupo \\(B=0\\): tiende a haber gente de peso más bajo. Para los que no recibieron el tratamiento, esto quiere decir que otros factores externos \\(U_y\\) fueron los explican por qué que cayeran en un nivel bajo (tienen \\(U_y\\) bajas. Por otro lado, el peso bajo de los que recibieron el tratamiento se debe también al tratamiento, por lo tanto, este grupo tiene \\(U_y\\) parecidas más parecidas a la población. Esto implica que estamos comparando grupos distintos de personas, y negamos ventajas de la aleatorización.\nEn el grupo \\(B=1\\): el argumento es similar. Aquí tiene a haber gente de peso más alto. Para los que recibieron tratamiento, esto implica que tienden a tener \\(U_y\\)’s más altas que la población. Para el grupo que no recibió el tratamiento, sus \\(U_y\\) son más parecidas a la población.\n\nEn ambos casos, estamos negando ventajas de aleatorización. En una regresión, \\(B\\) absorbe entonces parte de la variación que en realidad le corresponde al tratamiento:\n\nlm(PF ~ T +  B, peso_tbl) |> broom::tidy()\n\n# A tibble: 3 × 5\n  term        estimate std.error statistic   p.value\n  <chr>          <dbl>     <dbl>     <dbl>     <dbl>\n1 (Intercept)     45.1     0.812      55.6 0        \n2 T              -10.6     0.841     -12.6 4.80e- 34\n3 B               24.8     0.845      29.3 1.34e-142\n\n\nEn la regresión el coeficiente de \\(T\\) está contaminado por esa asociación que creamos al condicionar a un descendiente de un colisionador: este coeficiente “explica” otra variación del peso final que no tiene qué ver con el tratamiento, en lugar de explicar solamente la variación por el tratamiento."
  },
  {
    "objectID": "04-experimentos.html#control-malo-sesgo-de-colisionador",
    "href": "04-experimentos.html#control-malo-sesgo-de-colisionador",
    "title": "4  Experimentos y controles",
    "section": "4.4 Control Malo: sesgo de colisionador",
    "text": "4.4 Control Malo: sesgo de colisionador\nLos modelo 16 y 17 ya los hemos examinado antes: cuando condicionamos a un colisionador activamos no causales que distorsionan la asociación.\n\n\nCódigo\ngrViz('\ndigraph {\n  graph [ranksep = 0.2, rankdir = LR]\n  subgraph caso_1 {\n    node [shape=plaintext]\n    Z [fontcolor=\"red\"]\n    edge [minlen = 3]\n    T -> Z\n    Y -> Z\n    T -> Y\n  }\n  \n  subgraph caso_2 {\n    node [shape=circle]\n    U\n    node [shape=plaintext]\n    Ya [label=\"Y\"]\n    Ta [label=\"T\"]\n    Za [label=\"Z\"][fontcolor=\"red\"]\n    edge [minlen = 3]\n    U -> Za\n    U -> Ya\n    Ta -> Ya\n    Ta -> Za\n  {rank=same; Za; Ta}\n  }\n}\n', width = 250, height = 140)\n\n\n\n\n\n\n\nEjemplo: la paradoja de peso de recién nacidos\nPara ilustrar la primera de estas gráficas referimos al caso de la paradajo del peso bajo de los recién nacidos (Hernández-Díaz, Schisterman, y Hernán (2006)), The Birth Weight “Paradox” Uncovered?\nEn 1991, se observó que bebés nacidos de madres fumadoras tenían tanto peso más bajo como más alta mortalidad. Sin embargo, si excluíamos el análisis a bebés nacidos con bajo peso, los bebés de fumadoras tenían menos mortalidad que los de no fumadoras. Aunque hubo algunas especulaciones si fumar “protegía” a niños de bajo peso, podemos explicar la aparición de esta correlación por la activación de una ruta no causal al condicionar a niños de bajo peso.\nEn la gráfica de arriba, \\(T\\) indica si la madre es fumadora o no, y \\(Y\\) la mortalidad. \\(Z\\) si el bebé nació con bajo peso o no.\n\\(U\\) son posibles defectos de nacimiento no observados, que causan peso bajo e incrementan el riesgo de muerte. Cuando observamos a mujeres fumadoras, tenemos una explicación para el peso bajo, lo cual hace más improbable que se trate de un defecto grave de nacimiento. En consecuencia, el riesgo de muerte es más bajo.\nEsta es una asociación no causal creada por condicionar a un colisionador.\n\n\n\n\nCinelli, Carlos, Andrew Forney, y Judea Pearl. «A Crash Course in Good and Bad Controls». Sociological Methods & Research 0 (0): 00491241221099552. https://doi.org/10.1177/00491241221099552.\n\n\nHernández-Díaz, Sonia, Enrique F. Schisterman, y Miguel A. Hernán. 2006. «The Birth Weight “Paradox” Uncovered?» American Journal of Epidemiology 164 (11): 1115-20. https://doi.org/10.1093/aje/kwj275."
  },
  {
    "objectID": "05-contrafactuales.html#efectos-causales-a-nivel-individuo.",
    "href": "05-contrafactuales.html#efectos-causales-a-nivel-individuo.",
    "title": "5  Contrafactuales",
    "section": "5.1 Efectos causales a nivel individuo.",
    "text": "5.1 Efectos causales a nivel individuo.\nSupongamos que nos interesa una respuesta \\(Y\\) a un tratamiento \\(T\\). Por simplicidad, empezamos considerando que \\(T\\) puede tomar los valores 0 o 1.\nEn el modelo causal de Rubin, consideramos, para cada individuo de la población de interés, las dos cantidades:\n\\[y_{i}^1, y_{i}^0,\\] que se definen la siguiente manera: Si \\(y_i\\) es la respuesta observada para una unidad, entonces:\n\n\\(y_i = y_{i}^1\\) cuando \\(t_i=1\\), es decir, la unidad recibió el tratamiento, o\n\\(y_i = y_{i}^0\\) cuando \\(t_i=0\\), la unidad no recibió el tratamiento.\n\nPodemos escribir también como\n\\[y_i = y_{i}^1 t_i + y_{i}^0 (1 - t_i)\\] El primer avance, entonces, es establecer que para cada unidad hay dos posibles resultados potenciales, pero nosotros solamente observamos uno: \\(y_i\\). Esta notación más específica nos permite definir:\n\n\n\n\n\n\nContrafactuales\n\n\n\n\nCuando observamos \\(y_i=y_i^1\\), decimos que su observación contrafactual es \\(y_i^0\\), es decir, qué hubiéramos observado si esta unidad no hubiera recibido el tratamiento.\nCuando observamos \\(y_i=y_i^0\\), decimos que su observación contrafactual es \\(Y_i^1\\), es decir, qué hubiéramos observado si esta unidad hubiera recibido el tratamiento.\nEn algunos casos, escribiremos como \\(y_i^{obs}\\) la respuesta observada, y como \\(y_i^{mis}\\) el contrafactual. Para cada unidad siempre hay una respuesta faltante.\n\n\n\nNota: En general, podemos definir \\(y_i^t = y_i(t)\\) como el contrafactual para la unidad \\(i\\) cuando recibe el tratamiento \\(T=t\\).\n\nEjemplo\nSupongamos que nos interesa el tratamiento de tomar aspirina, y queremos ver su efecto en dolor de cabeza. En este caso tenemos un experimento donde el tratamiento se asignó al azar. Consideramos la intensidad del dolor (inicial y final) en una escala continua, con el dolor inicial estandarizado.-\nEntonces podríamos ver algo como lo que sigue:\n\nlibrary(tidyverse)\nlibrary(DiagrammeR)\nlibrary(kableExtra)\n\n\nmecanismo_aspirina <- function(dat_tbl){\n    # esta función contiene el mecanismo de funcionamiento\n    # del tratamiento, en términos probabilísticos\n    res_tbl <- dat_tbl |>  \n      mutate(u = rnorm(n, 0, 1)) |> \n      mutate(Y_1 = 0.8 * intensidad - 0.5 + 0.5 * u) |> \n      mutate(Y_0 = 0.8 * intensidad + 2 * u) |> \n      mutate(Y = ifelse(T, Y_1, Y_0))  |> \n      mutate(across(where(is.numeric), ~ round(.x, 3))) |> \n      select(T, Y, Y_1, Y_0, everything())\n    res_tbl\n}\n\n\nn <- 1600\nset.seed(134233)\nejemplo_1 <- tibble(.rows = n) |>  \n    mutate(intensidad = rnorm(n, 0, 1)) |> \n    mutate(T = rbernoulli(n, 0.5)) \nresultados_1 <- ejemplo_1 |> \n  mecanismo_aspirina() \nobs_1 <- resultados_1 |> \n  mutate(Y_1 = ifelse(T, Y_1, NA)) |> \n  mutate(Y_0 = ifelse(T, NA, Y_0)) |> \n  select(T, intensidad, Y, Y_1, Y_0)\nobs_1 |> head() |> knitr::kable() |> kableExtra::kable_paper()\n\n\n\n \n  \n    T \n    intensidad \n    Y \n    Y_1 \n    Y_0 \n  \n \n\n  \n    FALSE \n    0.757 \n    -0.313 \n    NA \n    -0.313 \n  \n  \n    FALSE \n    -1.348 \n    -1.226 \n    NA \n    -1.226 \n  \n  \n    TRUE \n    0.328 \n    0.833 \n    0.833 \n    NA \n  \n  \n    FALSE \n    0.408 \n    -1.105 \n    NA \n    -1.105 \n  \n  \n    FALSE \n    -0.971 \n    2.588 \n    NA \n    2.588 \n  \n  \n    FALSE \n    -0.175 \n    0.721 \n    NA \n    0.721 \n  \n\n\n\n\n\nNótese que nunca observamos al mismo tiempo \\(y_i^1\\) y \\(y_i^0\\). Nuestros resultados completos se verían como:\n\nresultados_1 |> \n  select(T, intensidad, Y_1, Y_0) |> \n  mutate(efecto_causal_ind = (Y_1 - Y_0)) |> \n  head()\n\n# A tibble: 6 × 5\n  T     intensidad    Y_1    Y_0 efecto_causal_ind\n  <lgl>      <dbl>  <dbl>  <dbl>             <dbl>\n1 FALSE      0.757 -0.124 -0.313             0.189\n2 FALSE     -1.35  -1.62  -1.23             -0.39 \n3 TRUE       0.328  0.833  4.54             -3.71 \n4 FALSE      0.408 -0.531 -1.10              0.574\n5 FALSE     -0.971 -0.436  2.59             -3.02 \n6 FALSE     -0.175 -0.425  0.721            -1.15 \n\n\nPodemos definir el efecto causal a nivel unidad de la siguiente forma, aunque esto no nos dice directamente cómo calcularlo con los datos observados:\n\nresultados_1 |> \n  mutate(efecto_causal_ind = Y_1 - Y_0) |> \n  summarise(ATE = mean(efecto_causal_ind), \n            ee = sd(efecto_causal_ind)/sqrt(n()))\n\n# A tibble: 1 × 2\n     ATE     ee\n   <dbl>  <dbl>\n1 -0.522 0.0377\n\n\n\n\n\n\n\n\nEfectos causales a nivel de unidad\n\n\n\nDefinimos el efecto del tratamiento \\(T\\) sobre el individuo \\(i\\) como la cantidad:\n\\[\\delta_i = y_{i}^1 - y_{i}^0,\\] Aunque también podríamos definirlo como cambio porcentual, o cociente, por ejemplo\n\n\nBajo este esquema, cantidades como el efecto promedio sobre la población pueden calcularse. Promediando sobre la población, escribiríamos\n\\[\\delta = \\frac{1}{N}\\sum_i \\delta_i = \\frac{1}{N}\\sum_i y_{i}^1 - \\frac{1}{N}\\sum_i y_{i}^0\\] que también podemos escribir, si \\(Y, Y_{}^1, Y_{}^0\\) indican los valores correspondientes a una persona tomada al azar de la población, como\n\\[\\delta = E[Y^1] - E[Y^0]\\] En términos de nuestra notación de la sección anterior, esto es lo mismo que\n\\[\\delta = E[Y|do(T=1)] - E[Y|do(T=0)].\\] y estos valores esperados son bajo la distribución \\(p(y|do(t))\\). Nótese sin embargo, que en cálculo-do siempre tratamos con las distribuciones poblacionales, y el enfoque de contrafactuales nos permite conectarlos con efectos individuales.\nPara que las definiciones de arriba tengan sentido y podamos trabajar con ellas de manera relativamente simple, es necesario hacer algunos supuestos. Los primeros se denominan SUTVA, o Stable Unit Treatment Value Assumption), ver (Rubin (2005)):\n\n\n\n\n\n\nSUTVA\n\n\n\nEl supuesto de valores estables de tratamientos de las unidades consiste en:\n\nLos resultados potenciales \\(y_{i}^1, y_{i}^0\\) no son afectados por el tratamiento que recibe la unidad, o ninguna otra unidad.\nLos resultados potenciales \\(y_{i}^1, y_{i}^0\\) no dependen de cómo se asignó el tratamiento.\n\n\n\nEn otro caso, es difícil establecer qué significado tienen los contrafactuales. Este supuesto muchas veces es apropiado, excepto cuando hay interacciones importantes entre las unidades. Por ejemplo: Un cambio en una plataforma para compartir documentos para una unidad A puede tener efectos en las \\(Y\\)’s correspondientes a unidades que comparten documentos con A. Otro ejemplo es si consideramos una enfermedad contagiosa: la intervención sobre una unidad puede tener efecto sobre los resultados potenciales de otra persona cercana. En esos casos, es necesario considerar distintos tipos de unidades (por ejempo, intervenciones a nivel red de contactos, escuelas, etc.), o utilizar modelos más complejos.\nCon estos conceptos, Rubin (Rubin (2005)) llama al modelo \\(p(x, y^1, y^0)\\) el modelo “científico” (este modelo es construido por conocimiento experto) mientras que el modelo de asignación es \\(p(t|x, y^0, y^1)\\), separando claramente la “ciencia” del mecanismo de asignación del tratamiento, que puede ser un experimento aleatorio, una asignación basada en políticas, autoselección de las personas, etc.\n\nNótese que en general, la asignación del tratamiento puede depender de los dos valores potenciales (por ejemplo, las personas que deciden tomar algún tratamiento son justamente aquellas para las que \\(Y^0\\) es similar a \\(Y_1\\)).\n\nIgual que en el marco de modelos causales estructurales (DAGs), es necesario hacer supuestos considerables acerca de estos dos modelos.\nEn cuanto al proceso de asignación del tratamiento, Rubin introduce el concepto de ignorabilidad:\n\n\n\n\n\n\nIngorabilidad\n\n\n\nSi \\(P(t|x, y^0, y^1) = P(t|x)\\), es decir, los resultados no influyen en la asignación de tratamiento dadas las covariables \\(x\\), decimos que el mecanismo de asignación es ignorable.\nEn este caso, es posible simular contrafactuales usando la distribución \\(P(y^{mis}| x, y^{obs})\\) que se deduce del modelo “científico” bajo ignorabilidad.\n\n\n\n\nEjemplo simple (Rubin)\nEn nuestro ejemplo de aspirinas, consideramos por ejemplo que \\(x\\) es la intensidad del dolor inicial. Establecemos el modelo “científico”: \\[y^0_i = \\alpha_0 + \\alpha x+ \\sigma_1 u_i^0\\] y \\[y^1_i = \\alpha_0 + \\alpha x + \\beta + \\sigma_2 u_i^1\\] Y podríamos suponer que \\((u_i^0, u_i^1)\\) tienen una distribución normal bivariada estándar con media en 0. Aunque podemos estimar las varianzas, no es posible estimar la correlación, y tendríamos que ponerla en algún valor consistente con el conocimiento experto (por ejemplo, los casos extremos son \\(\\rho = 1\\) o \\(\\rho = 0\\)). Supondremos en este ejemplo que \\(\\rho = 1\\) (ver Imbens y Rubin (2015) por ejemplo para más casos).\nComo la asignación del tratamiento es ignorable (este es un experimento), entonces para simular \\(y_i^{mis}\\) hacemos los siguiente:\n\nDenotamos por \\(\\theta\\) a los parámetros \\(\\alpha_0,\\alpha, \\beta,\\sigma_1,\\sigma_2,\\rho\\).\nObtenemos la posterior de los parámetros \\(\\theta\\) dada los datos \\((x_i, y_i^{obs}, t_i)\\).\nSimulamos un conjunto de parámetros \\(\\theta\\) de esta posterior.\nCon parámetros fijos, simulamos la observación contrafactual.\nCalculamos el resumen de interés a partir de la diferencia de observado y contrafactual.\n\nY ahora, con todos los pares posibles de observación y contrafactual, calculamos el resumen del efecto causal que nos interese (por ejemplo, media de la diferencia).\n\nlibrary(cmdstanr)\n\nThis is cmdstanr version 0.5.3\n\n\n- CmdStanR documentation and vignettes: mc-stan.org/cmdstanr\n\n\n- CmdStan path: /home/runner/.cmdstan/cmdstan-2.31.0\n\n\n- CmdStan version: 2.31.0\n\nmod_aspirina <- cmdstan_model(\"../src/contrafactual-simple.stan\")\nprint(mod_aspirina)\n\n\ndata {\n  int<lower=0> N;\n  array[N] real y_obs;\n  vector[N] intensidad;\n  vector[N] t;\n}\n\n// The parameters accepted by the model. Our model\n// accepts two parameters 'mu' and 'sigma'.\nparameters {\n  real alpha;\n  real alpha_0;\n  real beta;\n  array[2] real<lower=0> sigma;\n}\n\ntransformed parameters{\n  array[N] real media;\n  array[N] real u_obs;\n\n  for(i in 1:N){\n    media[i] = alpha_0 + alpha * intensidad[i] + beta * t[i];\n    u_obs[i] = y_obs[i] - media[i];\n  }\n\n}\n\nmodel {\n  for(i in 1:N){\n    if(t[i] == 1){\n      y_obs[i] ~ normal(media[i], sigma[1]);\n    }\n    else {\n      y_obs[i] ~ normal(media[i], sigma[2]);\n    }\n  }\n  alpha_0 ~ normal(0, 1);\n  alpha ~ normal(0, 1);\n  beta ~ normal(0, 1);\n  sigma ~ normal(0, 1);\n}\n\ngenerated quantities{\n  array[N] real y_mis;\n  array[N] real efecto_trata_ind;\n  real efecto_trata;\n\n  for(i in 1:N){\n    // simular contrafactual\n    if(t[i] == 1){\n      y_mis[i] = alpha_0 + alpha * intensidad[i] + beta * 0 +\n        u_obs[i] * sigma[2] / sigma[1];\n      efecto_trata_ind[i] = y_obs[i]  - y_mis[i];\n    } else {\n      y_mis[i] = alpha_0 + alpha * intensidad[i] + beta * 1 +\n        u_obs[i] * sigma[1] / sigma[2];\n      efecto_trata_ind[i] = y_mis[i] - y_obs[i];\n    }\n  }\n  efecto_trata = mean(efecto_trata_ind);\n}\n\n\n\najuste <- mod_aspirina$sample(data = list(N = nrow(obs_1), \n  t = as.numeric(obs_1$T),\n  intensidad = obs_1$intensidad, y_obs = obs_1$Y), \n  init = 0.1, step_size = 0.1, refresh = 1000)\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 finished in 9.0 seconds.\nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 2 finished in 8.6 seconds.\nChain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 3 finished in 7.8 seconds.\nChain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 4 finished in 7.5 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 8.2 seconds.\nTotal execution time: 33.4 seconds.\n\n\n\najuste$summary(c(\"sigma\", \"alpha_0\", \"alpha\", \"beta\", \"efecto_trata\")) |> \n  select(c(\"variable\", \"mean\", \"q5\", \"q95\"))\n\n# A tibble: 6 × 4\n  variable         mean     q5    q95\n  <chr>           <dbl>  <dbl>  <dbl>\n1 sigma[1]      0.507    0.486  0.529\n2 sigma[2]      1.99     1.91   2.08 \n3 alpha_0      -0.00452 -0.121  0.109\n4 alpha         0.809    0.782  0.836\n5 beta         -0.481   -0.600 -0.359\n6 efecto_trata -0.483   -0.584 -0.380\n\n\n\n\n\n\n\n\nModelos e Ignorabilidad\n\n\n\n\nLa ignorabilidad de asignación del tratamiento es un supuesto complejo. Las DAGs ayudan en el sentido de que transparentan las razones por las que asumimos ignorabilidad (por ejemplo, el criterio de puerta trasera).\nLa construcción del modelo que Rubin llama “ciencia” puede ser asistido y quizá más claramente explicado con DAGs."
  },
  {
    "objectID": "05-contrafactuales.html#asignación-no-ignorable",
    "href": "05-contrafactuales.html#asignación-no-ignorable",
    "title": "5  Contrafactuales",
    "section": "5.2 Asignación no ignorable",
    "text": "5.2 Asignación no ignorable\nEl concepto de contrafactual también nos permite entender por otro camino por qué la comparación simple de grupos no resulta necesariamente en efectos causales.\nSupongamos primero que el tratamiento se asignó al azar. Si este es el caso, nótese que entonces\n\\[\n\\begin{align}\n\\delta_{ing} & =  E[Y|T=1] - E[Y|T=0] \\\\\n& = E[Y^1|T=1] - E[Y^0|T=0] \\\\\n& = E[Y^1] - E[Y^0] = ATE = \\delta\n\\end{align}\n\\] pues por definición \\(T\\) es independiente de \\(Y^1, Y_0\\) (ignorabilidad). El lado izquierdo lo podemos estimar como es usual:\n\\[\\delta_{ing} = \\frac{1}{n_1} \\sum_{t_i = 1} y_i - \\frac{1}{n_0} \\sum_{t_i = 0} y_i\\]\nque llamamos el estimador ingenuo del efecto causal \\(\\delta\\). Esto ya lo sabíamos del cálculo-\\(do\\), pues la independencia de \\(T\\) y \\(Y_1,Y_0\\) puede deducirse del hecho de que no hay puertas traseras activas al tratamiento \\(T\\) con la respuesta \\(Y\\), pues \\(T\\) no depende de ninguna otra variable de nuestra gráfica.\nSi embargo, en general la ecuación de arriba no necesariamente se cumple cuando el tratamiento no se asigna al azar. En este caso podemos por ejemplo escribir (sumando y restand los términos centrales):\n\\[\\delta_{ing} =  (E[Y^1|Y=1] - E[Y^0|Y=1]) + (E[Y^0|T=1] - E[Y^0|T=0]) \\] \\[\\delta_{ing} =  ATT + (E[Y^0|T=1] - E[Y^0|T=0]) \\]\n\nATT: el primer término es el efecto causal del tratamiento sobre los tratados (ATT).\nSesgo de selección: el segundo término compara el grupo de tratados con el de no tratados en ausencia de ningún tratamiento. Esto quiere decir que si los grupos muy diferentes, el estimador ingenuo puede depender más de cómo son diferentes los grupos de tratados que los de los no tratados que del efecto casual del tratamiento.\nNótese que sin más supuestos, ninguna de las dos cantidades de la derecha pueden calcularse directamente, pues dependen de situaciones contrafactuales.\n\nPor ejemplo, podríamos comparar las personas que beben alcohol moderadamente (tratamiento) con aquellos que no beben alcohol. Quizá observamos que la salud de los que beben alcohol moderadamente es mejor que los que no beben alcohol. Sin embargo, no podemos concluir que beber alcohol moderadamente ayuda en la salud. La razón puede estar en que las personas que padecen enfermedades de distintos tipos evitan el alcohol, y en ese caso el término de la derecha \\(E[Y^0|T=1] - E[Y^0|Y=0]\\) podría ser grande (mejor salud de los que deciden tomar alcohol \\(T=1\\) sin tratamiento \\(Y^0\\)), lo cual haría nuestro estimador ingenuo \\(\\delta_{ing}\\) grande, aún cuando el efecto \\(E[Y^1|T=1] - E[Y^0|T=1]\\) fuera cercano a cero.\nEjercicio: describe esta situación mediante un DAG.\nIgualmente, podemos escribir\n\\[\\delta_{ing} =  (E[Y^1|T=0] - E[Y^0|T=0]) + (E[Y^1|T=1] - E[Y^1|T=0])  \\] \\[\\delta_{ing} =  ATU + (E[Y^1|T=1] - E[Y^1|T=0])  \\]\n\nATU: el primer término es el efecto causal del tratamiento sobre los no tratados.\nSesgo de selección: el segundo término compara el grupo de tratados con el de no tratados con tratamiento. Esto quiere decir que si los grupos muy diferentes, el estimador ingenuo puede depender más de cómo responden de manera diferente los grupos de tratados que los de los no tratados que del efecto casual del tratamiento.\n\nCombinando estas dos, si \\(\\pi\\) es la proporción de tratados,\n\\[\n\\begin{align*}\n\\delta_{ing} & = ATE \\\\\n& + \\pi (E[Y^0|T=1] - E[Y^0|T=0])\\\\\n& + (1-\\pi)(E[Y^1|T=1] - E[Y^1|T=0])\n\\end{align*}\n\\]\nQue podemos reescribir como\n\\[\n\\begin{align*}\n\\delta_{ing} & = ATE \\\\\n& +  (E[Y^0|T=1] - E[Y^0|T=0])\\\\\n& + (1-\\pi)(E[Y^1 -Y^0|T=1] - E[Y^1-Y^0|T=0])\n\\end{align*}\n\\]\nY el estimador ingenuo es diferente del efecto causal promedio (ATE) por:\n\nSesgo base: las unidades tratadas tienen distinto \\(Y^0\\) que los no tratados\nSesgo de tratamiento diferencial: las unidades que se seleccionan para ser tratadas son más o menos propensas a tener mejoras o desmejoras.\n\nPor ejemplo, supongamos que estamos comparando el efecto de la educación en la abilidad mental de personas adultas, y el tratamiento es ir a la universidad. Entonces, si comparamos habilidad mental de personas que van a la universidad vs los que no van a la universidad, tenemos dos posibles fuentes de confusión:\n\nPara empezar, los que van a la universidad tenían más habilidad que los que no fueron (efecto base)\nEn segundo lugar, aquellos que tienen más habilidad se benefician más con la educación universitaria que aquellos que no (efecto diferencial de tratamiento).\nEn este caso, la comparación ingenua estimaría considerablemente el efecto promedio del tratamiento.\n\nDesde le punto de vista del DAG, este sesgo aparece pues no hemos bloqueado una puerta trasera \\(HabilidadFinal \\gets HabilidadInicial \\to Universidad\\). Una vez que estratificamos por Habilidad Inicial, este sesgo desaparece.\nUna ventaja de esta aproximación de contrafactuales es que términos como \\(ATT\\) son fácilmente accesibles. Esta última cantidad, sin embargo, no podemos definirla exclusivamente desde el punto de vista el cálculo-do, pues tenemos que considerar cuál es el efecto del tratamiento de universidad sólo para aquellos que naturalmente hubieran asistido a la universidad."
  },
  {
    "objectID": "05-contrafactuales.html#mediacion-con-contrafactuales",
    "href": "05-contrafactuales.html#mediacion-con-contrafactuales",
    "title": "5  Contrafactuales",
    "section": "5.3 Mediacion con contrafactuales",
    "text": "5.3 Mediacion con contrafactuales\nUsando el concepto de contrafactuales es posible hacer una mejor definición de efectos directos e indirectos (Pearl, Glymour, y Jewell (2016)). Consideramos el diagrama:\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2, rankdir = LR]\n  node [shape=circle]\n  node [shape=plaintext]\n  \n\n  edge [minlen = 3]\n  T -> Y\n  T -> M\n  M -> Y\n#{ rank = same; A; D }\n}\n\", width = 200, height = 50)\n\n\n\n\n\n\nEn primer lugar tenemos los primeros dos conceptos que revisamos en el ejemplo de admisiones de Berkeley:\n\nEl efecto total,\n\n\\[ATE= E[Y^1 - Y^0] = E[Y|do(T=1)] - E[Y|do(T=0)] \\]\n\nEl efecto directo controlado\n\n\\[CDE(m) = E[Y|do(T=1, M=m)] - E[Y|do(T=0, M=m)]\\] que vimos en el ejemplo de Berkeley de la sección anterior. Depende de en qué fijamos el valor de \\(M\\), sin fijarnos en el valor que toma \\(T\\).\nAdicionalmente, usando el lenguaje de contrafactuales, podemos definir:\n\nEl efecto natural directo:\n\n\\[NDE = E[Y^{1,M_0} - Y^{0,M_0}]\\] En este caso, \\(Y^{1,M_0}\\) quiere decir: qué valor tomaría \\(Y\\) si \\(T=1\\), y tomamos la distibución de \\(M_0\\) como si \\(T=0\\).\nEsta cantidad mide el incremento en \\(Y\\) cuando cambiamos el tratamiento de 0 a 1, mientras que la variable medidadora toma el valor que hubiera tomado antes del cambio (es decir, bajo \\(T=0\\)). Por ejemplo: vemos el estado de aceptación de una mujer, dado que selecciona departamento como si fuera un hombre y contrastamos el estado de aceptación de un hombre como normalmente selecciona departamento. De esta manera bloqueamos el efecto del tratamiento en la selección de departamento.\n\nEl efecto natural indirecto :\n\n\\[NIE = E[Y^{0,M_1} - Y^{0,M_0} ]\\] En este caso, mantenemos \\(T=0\\), pero observamos qué pasaría si \\(M\\) se escoge bajo \\(T=1\\) o bajo \\(T=0\\). Captura la porción del efecto que se explica sólo por la mediación (quitando la capacidad de que \\(T\\) afecte a \\(Y\\)). En términos del ejemplo de Berkeley, fijamos \\(t=0\\) (hombre), y comparamos que pasaría si seleccionara departamento como una mujer vs. como normalmente lo haría.\n\n5.3.1 Caso donde no hay variables confusoras\nEn el caso donde no hay variables confusoras (ver el diagrama de arriba), el efecto natural directo está identificado por:\n\\[NDE = \\int (E[Y|T=1, M = m]- E[Y|T=0, M = m] )p(m|t=0)dm \\] Cada integral la podemos estimar simulando y promediando. Por ejemplo, para la primer integral, simulamos \\(M=m\\) dado que \\(T=0\\), y luego simulamos \\(Y\\) dado \\(T=1\\) y \\(M=m\\) con la \\(m\\) que obtuvimos en le paso anterior. Igualmente para la segunda integral.\nEl efecto indirecto también está identificado y es:\n\\[NIE = \\int E[y|T=0, M = m]p(m|t=1)dm - \\int E[y|T=0, M = m]p(m|t=0)dm\\] Que igualmente podemos calcular simulando.\n\n\n\n\n\n\nTip\n\n\n\nExcepto para modelos lineales sin interacciones, no es cierto que la suma del efecto directo más el indirecto es el efecto total.\n\n\nEsto se debe a interacciones que puede haber entre el tratamiento y la variable mediadora. Tomando un caso extremo, podemos pensar en una medicina que tienen un efecto total positivo sobre algún resultado. Existe una variable mediadora (por ejemplo, baja el colesterol). Sin embargo, si el colesterol no es bajo, otros efectos de la medicina no pueden darse, de modo que \\(Y^{1, M_0} = Y^{0, M_0}\\) (el efecto natural directo es 0). Por otra parte, el efecto de sólo bajar el colesterol (sin tomar la medicina) no tiene un efecto considerable \\(Y^{0,M_1} \\approx Y^{0,M_0}\\). Estos dos efectos son chicos, aunque el efecto causal total \\(Y^{1, M_1} = Y^{0, M_0}\\) puede ser grande.\nEn el caso lineal sin interacciones es más simple: si \\(M = a+bT\\) y \\(Y = c + dM + eT\\), entonces el efecto natural directo es \\[NDE = (c+ da + e) - (c + da) = e,\\] el efecto natural indirecto es \\[NIE = (c + d(a+b)) - (c + da) = bd\\], y el efecto total es \\[ATE = (c+ d(a+b) + e) - (c + da) = bd +e.\\]\n\n\nEjemplo\nEste ejemplo es de Pearl, Glymour, y Jewell (2016). Un tratamiento impulsa a alumnos a hacer la tarea, y queremos calcular el efecto del tratamiento en la probabilidad de aprobar el curso. También nos interesa si es que el aumento en la tarea es la razón de este efecto, independientemente del programa de entrenamiento. Supondremos que hemos estimado los parámetros de nuestro modelo (en este caso son sólo proporciones pues todas las variables son discretas).\nLas distribuciones estimadas de datos observados son\n_\n\ntabla_1 <- tibble(t = c(1, 1, 0, 0), tarea = c(1, 0, 1, 0), prob_exito = c(0.80, 0.40, 0.30, 0.20))\ntabla_1\n\n# A tibble: 4 × 3\n      t tarea prob_exito\n  <dbl> <dbl>      <dbl>\n1     1     1        0.8\n2     1     0        0.4\n3     0     1        0.3\n4     0     0        0.2\n\n\nY tenemos para el nodo de tarea, el tratamiento incrementa la probabilidad de hacer tarea considerablemente:\n\ntabla_2 <- tibble(t = c(0, 1), prob_tarea = c(0.4, 0.75))\ntabla_2\n\n# A tibble: 2 × 2\n      t prob_tarea\n  <dbl>      <dbl>\n1     0       0.4 \n2     1       0.75\n\n\nAunque es posible hacer todos los cálculos de manera analítica, en este ejemplo calcularemos con simulación. El efecto total es\n\nset.seed(101)\nsim_total <- function(n =100000){\n  # tratados\n  sim_tarea <- rbinom(n, 1, 0.75)\n  sim_exito_trata <- rbinom(n, 1, 0.8*sim_tarea + 0.4*(1-sim_tarea))\n  # no tratados\n  sim_tarea <- rbinom(n, 1, 0.4)\n  sim_exito_sin_trata <- rbinom(n, 1, 0.3*sim_tarea + 0.2*(1-sim_tarea))\n  # contraste\n  mean(sim_exito_trata - sim_exito_sin_trata)\n}\nate <- sim_total()\nate\n\n[1] 0.4591\n\n\nEl efecto natural directo es\n\nsim_nde <- function(n =100000){\n  # simulamos tarea sin tratamiento\n  sim_tarea <- rbinom(n, 1, 0.4)\n  # simulamos éxito con tarea anterior, suponiendo tratamiento\n  sim_exito_trata <- rbinom(n, 1, 0.8*sim_tarea + 0.4*(1-sim_tarea))\n  # simulamos éxito con tarea anterior, sin tratamiento\n  sim_exito_sin_trata <- rbinom(n, 1, 0.3*sim_tarea + 0.2*(1-sim_tarea))\n  parte_1 <- mean(sim_exito_trata)\n  parte_2 <- mean(sim_exito_sin_trata)\n  parte_1 - parte_2\n}\nnde <- sim_nde()\nnde\n\n[1] 0.32065\n\n\nY el efecto natural indirecto es:\n\nsim_nie <- function(n =100000){\n  # simulamos tarea con tratamiento\n  sim_tarea <- rbinom(n, 1, 0.75)\n  # simulamos éxito sin tratamiento\n  sim_exito_sin_trata <- rbinom(n, 1, 0.3*sim_tarea + 0.2*(1-sim_tarea))\n  parte_1 <- mean(sim_exito_sin_trata)\n  \n  # simulamos tarea sin tratamiento\n  sim_tarea<- rbinom(n, 1, 0.4)\n  # simulamos éxito sin tratamiento\n  sim_exito_sin_trata <- rbinom(n, 1, 0.3*sim_tarea + 0.2*(1-sim_tarea))\n  parte_2 <- mean(sim_exito_sin_trata)\n  # calculamos la diferencia entre las dos medias\n  parte_1 - parte_2\n}\nnie <- sim_nie()\nnie\n\n[1] 0.03589\n\n\nTenemos:\n\n# Efecto total \nate\n\n[1] 0.4591\n\n# Efecto indirecto comparado con ATE:\n1 - nde/ate\n\n[1] 0.3015683\n\n# Efecto indirecto comparado con ATE:\nnie/ate\n\n[1] 0.07817469\n\n\n\nEl programa incrementa en 46 puntos porcentuales la tasa de éxito\n30% de este incremento se debe a la capacidad del programa de estimular esfuerzos en la tarea.\nPero sólo alrededor 8% de este incremento se puede explicar por un incremento en tareas por sí solas sin el beneficio del programa.\n\nNuestra conclusión es que incidir solamente en la variable \\(Tarea\\), quizá de una manera más barata, y a niveles similares a los de este programa, no tendría un resultado cercano en efectividad.\n\n\n5.3.2 Ejemplo (Admisiones de Berkeley)\nEn el ejemplo Berkeley, suponiendo siguiente diagrama, calcularemos los efectos naturales directos e indirectos:\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n  node [shape=plaintext]\n    G\n    D\n    A \n  #node [shape = circle]\n  #  U\n  edge [minlen = 3]\n    G -> D\n    G -> A\n    D -> A\n{rank = same; G;A}\n}\n\")\n\n\n\n\n\n\n\ndata(\"UCBAdmissions\")\nadm_original <- UCBAdmissions |> as_tibble() |> \n   pivot_wider(names_from = Admit, values_from = n) \nadm_indiv <- UCBAdmissions |> as_tibble() |> \n  mutate(Gender = ifelse(Gender==\"Female\", 2, 1)) |> \n  mutate(Dept = factor(Dept) |> as.integer()) |> \n  mutate(Admit = ifelse(Admit == \"Admitted\", 1, 0)) |> \n  uncount(n) |> filter(Dept < 5)\nadm_indiv |> head() \n\n# A tibble: 6 × 3\n  Admit Gender  Dept\n  <dbl>  <dbl> <int>\n1     1      1     1\n2     1      1     1\n3     1      1     1\n4     1      1     1\n5     1      1     1\n6     1      1     1\n\n\n\nmod_efectos_berkeley <- cmdstan_model(\"../src/berkeley-efectos-naturales.stan\")\nprint(mod_efectos_berkeley)\n\ndata {\n  int<lower=0> N;\n  int<lower=0> n_d;\n  array[N] int admit;\n  array[N] int gender;\n  array[N] int dept;\n}\ntransformed data {\n  array[N] int gender_ind;\n\n  for(i in 1:N){\n    gender_ind[i] = 0;\n    if(gender[i] == 2) {\n      gender_ind[i] = 1;\n    }\n  }\n}\n\nparameters {\n  real beta_0;\n  array[2] vector[n_d] beta;\n  matrix[2, n_d] alpha;\n}\n\n\nmodel {\n  for(i in 1:N){\n    admit[i] ~ bernoulli_logit(alpha[gender[i], dept[i]]);\n    dept[i] ~ categorical_logit(beta[gender[i]]);\n  }\n  gender_ind ~ bernoulli_logit(beta_0);\n  beta_0 ~ normal(0, 0.5);\n  for(i in 1:2){\n    beta[i] ~ normal(0, 1);\n    alpha[i] ~ normal(0, 1);\n  }\n}\n\ngenerated quantities{\n  real efecto_nat_dir;\n  real efecto_nat_ind;\n  real efecto_total;\n  real prop_mediador;\n  {\n    array[2000] real admit_sim_2;\n    array[2000] real admit_sim_1;\n    // calcular efecto natural directo\n    array[2000] int k;\n    for(j in 1:2000){\n      // extraer una elección de departamento de hombres:\n      k[j] = categorical_logit_rng(beta[1]);\n      // extraer admisión al departamento si es mujer\n      admit_sim_2[j] = bernoulli_logit_rng(alpha[2, k[j]]);\n      // extraer admisión al departamento si es hombre\n      admit_sim_1[j] = bernoulli_logit_rng(alpha[1, k[j]]);\n    }\n    efecto_nat_dir = mean(admit_sim_2) - mean(admit_sim_1);\n  }\n  {\n    array[2000] real admit_sim_2;\n    array[2000] real admit_sim_1;\n    array[2000] int k_1;\n    array[2000] int k_2;\n    // calcular efecto natural indirecto\n    for(j in 1:2000){\n      // escoger depto bajo tratamiento\n      k_1[j] = categorical_logit_rng(beta[2]);\n      // simular admisión sin tratamiento\n      admit_sim_2[j] = bernoulli_logit_rng(alpha[1, k_1[j]]);\n      // escoger depto sin tratamiento\n      k_2[j] = categorical_logit_rng(beta[1]);\n      // simular admisión con tratamiento\n      admit_sim_1[j] = bernoulli_logit_rng(alpha[1, k_2[j]]);\n\n     }\n      efecto_nat_ind = mean(admit_sim_2) - mean(admit_sim_1);\n    }\n\n    {\n    array[2000] real admit_sim_2;\n    array[2000] real admit_sim_1;\n    array[2000] int k_1;\n    array[2000] int k_2;\n    // calcular efecto total\n    for(j in 1:2000){\n      // extraer una elección de departamento para mujeres\n      k_1[j] = categorical_logit_rng(beta[2]);\n      admit_sim_2[j] = bernoulli_logit_rng(alpha[2, k_1[j]]);\n      // extraer una elección de departamento para hombres\n      k_2[j] = categorical_logit_rng(beta[1]);\n      admit_sim_1[j] = bernoulli_logit_rng(alpha[1, k_2[j]]);\n    }\n    efecto_total = mean(admit_sim_2) - mean(admit_sim_1);\n  }\n}\n\n\n\ndatos_lista <- list(N = nrow(adm_indiv), n_d = 4,\n  admit = adm_indiv$Admit, gender = adm_indiv$Gender,\n  dept = adm_indiv$Dept)\n\najuste <- mod_efectos_berkeley$sample(data = datos_lista, \n          iter_warmup = 300, iter_sampling = 1000,\n          refresh = 1000, parallel_chains = 4)\n\nRunning MCMC with 4 parallel chains...\n\nChain 1 Iteration:    1 / 1300 [  0%]  (Warmup) \nChain 2 Iteration:    1 / 1300 [  0%]  (Warmup) \nChain 3 Iteration:    1 / 1300 [  0%]  (Warmup) \nChain 4 Iteration:    1 / 1300 [  0%]  (Warmup) \nChain 3 Iteration:  301 / 1300 [ 23%]  (Sampling) \nChain 1 Iteration:  301 / 1300 [ 23%]  (Sampling) \nChain 2 Iteration:  301 / 1300 [ 23%]  (Sampling) \nChain 4 Iteration:  301 / 1300 [ 23%]  (Sampling) \nChain 3 Iteration: 1300 / 1300 [100%]  (Sampling) \nChain 3 finished in 151.9 seconds.\nChain 4 Iteration: 1300 / 1300 [100%]  (Sampling) \nChain 4 finished in 162.6 seconds.\nChain 2 Iteration: 1300 / 1300 [100%]  (Sampling) \nChain 2 finished in 163.3 seconds.\nChain 1 Iteration: 1300 / 1300 [100%]  (Sampling) \nChain 1 finished in 166.0 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 160.9 seconds.\nTotal execution time: 166.1 seconds.\n\nresumen_mod <- ajuste$summary(\n  c( \"efecto_nat_dir\", \"efecto_nat_ind\", \"efecto_total\")) |> \n  select(variable, mean, q5, q95)\nresumen_mod\n\n# A tibble: 3 × 4\n  variable          mean      q5    q95\n  <chr>            <dbl>   <dbl>  <dbl>\n1 efecto_nat_dir  0.0792  0.0245  0.132\n2 efecto_nat_ind -0.139  -0.173  -0.105\n3 efecto_total   -0.129  -0.168  -0.09 \n\n\nEn este caso, el efecto total (que favorece al género 1) puede explicarse principalmente, mediante el efecto natural indirecto (la selección de departamento), y el efecto directo natural favorece al género 2. Nótese que esto supone que no hay variables confusoras entre departamento y admisión. Como vimos en la sección anterior, esto no es necesariamente cierto.\nEjercicio: bajo este modelo y considerando los efectos que acabamos de estimar, ¿ayudaría en algo hacer que las aplicaciones fueran “ciegas”, en el sentido de quitar nombres o otras maneras de editar las aplicaciones para que no se pueda saber el género del aplicante (si fuera posible)?\n\n\n\n\n\n\nIdentificación de NDE y NIE\n\n\n\nLos efectos naturales directos e indirectos nos siempre son identificables, aún cuando algunos casos pueden resolverse estratificando por algunas variables. Para más detalles, ver 4.5 en Pearl, Glymour, y Jewell (2016).\nPor ejemplo, en el caso de un experimento (\\(T\\) no tiene padres), entonces es suficiente identificar estos efectos si enocntramos un conjunto \\(W\\) de variables observadas que no sean descendientes de \\(T\\) y que bloqueen los caminos de puerta trasera de \\(M\\) a \\(Y\\) (sin contar \\(T\\to M\\) y \\(T\\to Y\\)).\n\n\n\nPor ejemplo, en nuestro diagrama de Berkeley donde existía el confusor \\(D\\gets U\\to A\\), no es posible identificar estos efectos directos e indirectos, pues no podemos bloquear el camino de puerta trasera entre mediador \\(D\\) y la respuesta \\(A\\) que pasa por \\(U\\).\n\n\n\n\n\nImbens, Guido W., y Donald B. Rubin. 2015. Causal Inference for Statistics, Social, and Biomedical Sciences: An Introduction. Cambridge University Press. https://doi.org/10.1017/CBO9781139025751.\n\n\nPearl, J., M. Glymour, y N. P. Jewell. 2016. Causal Inference in Statistics: A Primer. Wiley. https://books.google.com.mx/books?id=L3G-CgAAQBAJ.\n\n\nRubin, Donald B. 2005. «Causal Inference Using Potential Outcomes». Journal of the American Statistical Association 100 (469): 322-31. https://doi.org/10.1198/016214504000001880."
  },
  {
    "objectID": "06-exp-naturales.html#intro-variables-instrumentales",
    "href": "06-exp-naturales.html#intro-variables-instrumentales",
    "title": "6  Otros métodos para inferencia causal",
    "section": "6.1 Intro: Variables instrumentales",
    "text": "6.1 Intro: Variables instrumentales\nEn el siglo XIX John Snow tenía la teoría de que algo en la calidad del suministro de agua estaba relacionado con la aparición de casos de cólera en Londres (que entonces era una epidemia).\nReconoció que tenía el problema de variables no observadas que abren puertas traseras: la calidad de agua que toman las personas (o por ejemplo en zonas de la ciudad) es diferente: en zonas más pobres en general la calidad del agua es mala, y también hay más muertes de cólera en lugares pobres.\nOtra variable de confusión podía ser el entonces llamado “miasma”: cosas malas en el aire que contaminan el agua y a las personas.\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n \n  node [shape = circle]\n    MiasmaPobreza\n  node [shape=plaintext]\n\n  edge [minlen = 3]\n    PurezaAgua -> Colera\n    MiasmaPobreza -> Colera\n    MiasmaPobreza -> PurezaAgua\n  {rank = same; PurezaAgua; Colera}\n}\n\", width = 200, height = 100)\n\n\n\n\n\n\nDado este diagrama, como hemos discutido, no podemos identificar el efecto causal de la calidad de suministro de agua en las muertes o infecciones de cólera: podría ser la “miasma” que contamina el agua y enferma a las personas (correlación no causal), por ejemplo, y no hay relación causal entre tomar agua contaminada y cólera.\nJohn Snow, sin embargo, que no creía en la teoría del miasma, investigó con detalle de dónde provenía el agua que tomaban en varias casas a lo largo de toda la ciudad. Lo que descubrió, en sus palabras es que:\n\nEn grandes partes de Londres, los suministros de agua de distintas compañías están organizados de forma compleja. Los tubos de cada compañía van por todas las calles de todas las zonas.\nLa decisión de qué compañía suministraba a cada casa generalmente se había tomado hace mucho, y los habitantes generalmente no lo decidían ni sabían que compañía de agua les correspondía.\nHabía casas muy cercanas, unas con una compañía y otras con otra.\n\nSi las distintas compañías de agua tiene distintos niveles de calidad de agua, podriamos expandir nuestro DAG a:\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n \n  node [shape = circle]\n    Miasma\n  node [shape=plaintext]\n\n  edge [minlen = 3]\n    Comp -> PurezaAgua -> Colera\n    Miasma -> PurezaAgua\n    Miasma -> Colera\n  {rank = same; Comp; PurezaAgua; Colera}\n}\n\")\n\n\n\n\n\n\nTenemos entonces:\n\nLa compañía que suministra a cada casa o zona es causa de la pureza de agua en cada casa.\nNo puede haber aristas directas entre compañía y cólera: el único efecto de compañía en cólera puede ser a través del agua que suministra.\nNo puede haber una arista de Pobreza a Compañía, por la observación de Snow: la decisión de qué compañía suministraba a qué casa se había tomado mucho antes, y no tenía relación con pobreza, miasma actual ni cólera (que no existía cuando se tomaron esas decisiones)\n\nLa conclusión de Snow es que desde el punto de vista de cólera y el sistema que nos interesa, la compañía de agua se comporta como si fuera asignada al azar: no hay ninguna variable relevente al problema que incida en qué compañía abastece a cada casa o zona. Como observó asociación entre compañía de agua y Cólera, concluyó correctamente que esto implicaba que la pureza del agua tenía un efecto causal en la propagación del cólera.\nLa idea de Snow entonces podemas :\n\nPor la gráfica, la asociación entre Compañía y Cólera es causal (no hay confusoras para Compañía y Cólera).\nSi esta relación existe, entonces por los supuestos, la Pureza de Agua tiene un efecto causal sobre Cólera.\n\nLa tabla de Snow, tomada de Freedman (1991):\n\ntibble(comp = c(\"Southwark+Vauxhall\", \"Lambeth\", \"Resto\"),\n       casas = c(40046, 26107, 256423),\n       muertes_colera = c(1263, 98, 1422),\n       tasa_muertes_10milcasas = c(315, 37, 59)) |> \nknitr::kable() |> kable_paper()\n\n\n\n \n  \n    comp \n    casas \n    muertes_colera \n    tasa_muertes_10milcasas \n  \n \n\n  \n    Southwark+Vauxhall \n    40046 \n    1263 \n    315 \n  \n  \n    Lambeth \n    26107 \n    98 \n    37 \n  \n  \n    Resto \n    256423 \n    1422 \n    59 \n  \n\n\n\n\n\nEsta diferencia grande muestra que la razón de la aparición de cólera tenía que ver con el agua que consumían las personas, considerando los supuestos de arriba. Para llegar a la conclusión de Snow, es necesario que se cumpla la estructura causal del diagrama de arriba."
  },
  {
    "objectID": "06-exp-naturales.html#variables-instrumentales",
    "href": "06-exp-naturales.html#variables-instrumentales",
    "title": "6  Otros métodos para inferencia causal",
    "section": "6.2 Variables instrumentales",
    "text": "6.2 Variables instrumentales\nEl diagrama básico que define una variable instrumental con el propósito de identificar el efecto causal de \\(T\\) sobre \\(Y\\) es el siguiente:\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n \n  node [shape = circle]\n    U\n  node [shape=plaintext]\n\n  edge [minlen = 3]\n    Z -> T -> Y\n    U-> T\n    U-> Y\n  {rank = same; Z;T; Y}\n}\n\", width= 200, height = 70)\n\n\n\n\n\n\n\n\n\n\n\n\nVariables instrumentales\n\n\n\nDecimos que \\(Z\\) es una variable instrumental para estimar el efecto causal de \\(T\\) sobre \\(Y\\) cuando:\n\n\\(Z\\) es una variable que influye en la asignación del tratamiento.\n\\(Z\\) está \\(d\\)-separada de \\(U\\).\n\\(Z\\) sólo influye en \\(Y\\) a través de \\(T\\) (restricción de exclusión)\n\n\n\n\nGeneralmente las últimas dos de estas hipótesis tienen que postularse basadas en conocimiento experto, ya que no es posible checarlas con datos.\nCon estrategias de condicionamiento es posible encontrar instrumentos potenciales en gráficas más complejas.\nEsta estrategia funciona con modelos lineales. Más generalmente, pero bajo ciertos supuestos, los estimadores de variables instrumentales son más propiamente estimadores de un cierto tipo de efecto causal (por ejemplo, para tratamientos binarios, el efecto causal sobre los compliers, ver Morgan y Winship (2015))."
  },
  {
    "objectID": "06-exp-naturales.html#estimación-con-variables-instrumentales",
    "href": "06-exp-naturales.html#estimación-con-variables-instrumentales",
    "title": "6  Otros métodos para inferencia causal",
    "section": "6.3 Estimación con variables instrumentales",
    "text": "6.3 Estimación con variables instrumentales\nLa estimación de efectos causales con variables instrumentales depende de supuestos adicionales a los del cálculo-do, y su utilidad depende de qué tan fuerte es el instrumento (qué tan correlacionado está con el tratamiento).\nPrimero, hacemos una discusión para ver cómo esto puede funcionar. Lo más importante es notar que el efecto de \\(Z\\) sobre \\(Y\\) y el de \\(Z\\) sobre \\(T\\) son identificables y podemos calcularlos. El que nos interesa el efecto de \\(T\\) sobre \\(Y\\). Supongamos que todos los modelos son lineales:\n\nSupongamos que cuando \\(Z\\) aumenta una unidad, \\(T\\) aumenta en \\(a\\) unidades,\nSupongamos que cuando \\(T\\) aumenta 1 unidad \\(Y\\) aumenta \\(b\\) unidades (este es el efecto causal que queremos calcular).\nEsto quiere decir que cuando \\(Z\\) aumenta una unidad, \\(Y\\) aumenta \\(c = ab\\) unidades.\nEl efecto causal de \\(T\\) sobre \\(Y\\) se puede calcular dividiendo \\(c/a\\) (que es igual a \\(b\\)), y estas dos cantidades están identificadas\n\nNótese que si \\(a=0\\), o es muy chico, este argumento no funciona (\\(Z\\) es un instrumento débil).\nVeremos un ejemplo simulado, y cómo construir un estimador estadístico en el caso lineal para estimar el efecto causal.\n\nsim_colera <- function(n){\n  # se selecciona al azar la compañía\n  comp <- sample(1:5, n, replace = TRUE)\n  contaminacion_comp <- c(5, 5, 0.3, 0.2, 0)\n  # confusor\n  u <- rnorm(n, 0, 1)\n  # confusor afecta a pureza y muertes\n  pureza <- rnorm(n, contaminacion_comp[comp] +  2 * u, 1)\n  colera <- rnorm(n, 3 * pureza +  2 * u, 1)\n  tibble(comp, pureza, colera) \n}\nset.seed(800)\ndatos_tbl <- sim_colera(1000)\n\n\ndatos_tbl |> head()\n\n# A tibble: 6 × 3\n   comp pureza colera\n  <int>  <dbl>  <dbl>\n1     3 -0.569  -3.73\n2     3  2.89   10.3 \n3     2  3.59    9.26\n4     2  4.59   12.4 \n5     4 -0.744  -2.88\n6     4 -4.23  -17.9 \n\n\nPodríamos construir un modelo generativo modelando una variable latente \\(U\\). Si embargo, es más simple definir un modelo estadístico como sigue:\n\nLas variables pureza son normales bivariadas con alguna correlación (producida por el confusor U).\nLa media de Pureza depende la compañía (modelo de primera etapa)\nLa media de Cólera depende de la pureza (modelo de segunda etapa)\n\nCon un modelo así podemos resolver el problema de estimar el efecto causal la variable instrumental.\nSin embargo, modelos de regresión simples no nos dan la respuesta correcta. Por ejemplo, sabemos que esta regresión es incorrecta (por el confusor):\n\nlm(colera~ pureza, datos_tbl) |> broom::tidy()\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic  p.value\n  <chr>          <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)   -0.739    0.0702     -10.5 1.27e-24\n2 pureza         3.38     0.0184     184.  0       \n\n\n\nlm(colera ~ pureza + factor(comp), datos_tbl) |> broom::tidy()\n\n# A tibble: 6 × 5\n  term          estimate std.error statistic   p.value\n  <chr>            <dbl>     <dbl>     <dbl>     <dbl>\n1 (Intercept)    -4.02      0.137    -29.4   6.92e-137\n2 pureza          3.80      0.0187   203.    0        \n3 factor(comp)2   0.0447    0.139      0.322 7.47e-  1\n4 factor(comp)3   3.77      0.162     23.2   7.99e- 96\n5 factor(comp)4   3.92      0.164     23.9   4.03e-100\n6 factor(comp)5   4.14      0.166     24.9   5.35e-107\n\n\nY agregar la variable compañía empeora la situación. La razón es que al condicionar a pureza, abrimos un nuevo camino no causal entre compañía y la respuesta, y esta es capturada por esos coeficientes.\n\nlibrary(cmdstanr)\n\nThis is cmdstanr version 0.5.3\n\n\n- CmdStanR documentation and vignettes: mc-stan.org/cmdstanr\n\n\n- CmdStan path: /home/runner/.cmdstan/cmdstan-2.31.0\n\n\n- CmdStan version: 2.31.0\n\nmod_colera <- cmdstan_model(\"../src/iv-ejemplo.stan\")\nprint(mod_colera)\n\ndata {\n  int<lower=0> N;\n  array[N] int compania;\n  vector[N] colera;\n  vector[N] pureza;\n}\n\ntransformed data {\n    array[N] vector[2] py;\n    for(i in 1:N){\n      py[i][1] = pureza[i];\n      py[i][2] = colera[i];\n    }\n}\n\nparameters {\n  vector[6] alpha;\n  real alpha_0;\n  real beta_0;\n  real beta_1;\n  corr_matrix[2] Omega;\n  vector<lower=0>[2] sigma;\n}\n\ntransformed parameters{\n  array[N] vector[2] media;\n  cov_matrix[2] S;\n\n  for(i in 1:N){\n    media[i][2] = beta_0 + beta_1 * pureza[i];\n    media[i][1] = alpha_0 + alpha[compania[i]];\n  }\n\n  S = quad_form_diag(Omega, sigma);\n}\n\nmodel {\n  py ~ multi_normal(media, S);\n  Omega ~ lkj_corr(2);\n  sigma ~ normal(0, 10);\n  alpha_0 ~ normal(0, 1);\n  beta_0 ~ normal(0, 1);\n  beta_1 ~ normal(0, 1);\n  alpha ~ normal(0, 300);\n}\n\ngenerated quantities{\n\n}\n\n\n\najuste <- mod_colera$sample(\n  data = list(N = nrow(datos_tbl), \n                compania = datos_tbl$comp,\n                colera = datos_tbl$colera,\n                pureza = datos_tbl$pureza),\n  init = 0.01, step_size = 0.01,\n  parallel_chains = 4, iter_warmup = 500, iter_sampling = 1000\n)\n\nRunning MCMC with 4 parallel chains...\n\nChain 1 Iteration:    1 / 1500 [  0%]  (Warmup) \nChain 2 Iteration:    1 / 1500 [  0%]  (Warmup) \nChain 3 Iteration:    1 / 1500 [  0%]  (Warmup) \nChain 4 Iteration:    1 / 1500 [  0%]  (Warmup) \nChain 1 Iteration:  100 / 1500 [  6%]  (Warmup) \nChain 3 Iteration:  100 / 1500 [  6%]  (Warmup) \nChain 2 Iteration:  100 / 1500 [  6%]  (Warmup) \nChain 4 Iteration:  100 / 1500 [  6%]  (Warmup) \nChain 2 Iteration:  200 / 1500 [ 13%]  (Warmup) \nChain 3 Iteration:  200 / 1500 [ 13%]  (Warmup) \nChain 1 Iteration:  200 / 1500 [ 13%]  (Warmup) \nChain 4 Iteration:  200 / 1500 [ 13%]  (Warmup) \nChain 3 Iteration:  300 / 1500 [ 20%]  (Warmup) \nChain 1 Iteration:  300 / 1500 [ 20%]  (Warmup) \nChain 2 Iteration:  300 / 1500 [ 20%]  (Warmup) \nChain 4 Iteration:  300 / 1500 [ 20%]  (Warmup) \nChain 3 Iteration:  400 / 1500 [ 26%]  (Warmup) \nChain 1 Iteration:  400 / 1500 [ 26%]  (Warmup) \nChain 2 Iteration:  400 / 1500 [ 26%]  (Warmup) \nChain 3 Iteration:  500 / 1500 [ 33%]  (Warmup) \nChain 3 Iteration:  501 / 1500 [ 33%]  (Sampling) \nChain 4 Iteration:  400 / 1500 [ 26%]  (Warmup) \nChain 1 Iteration:  500 / 1500 [ 33%]  (Warmup) \nChain 1 Iteration:  501 / 1500 [ 33%]  (Sampling) \nChain 2 Iteration:  500 / 1500 [ 33%]  (Warmup) \nChain 2 Iteration:  501 / 1500 [ 33%]  (Sampling) \nChain 3 Iteration:  600 / 1500 [ 40%]  (Sampling) \nChain 4 Iteration:  500 / 1500 [ 33%]  (Warmup) \nChain 4 Iteration:  501 / 1500 [ 33%]  (Sampling) \nChain 3 Iteration:  700 / 1500 [ 46%]  (Sampling) \nChain 2 Iteration:  600 / 1500 [ 40%]  (Sampling) \nChain 1 Iteration:  600 / 1500 [ 40%]  (Sampling) \nChain 3 Iteration:  800 / 1500 [ 53%]  (Sampling) \nChain 4 Iteration:  600 / 1500 [ 40%]  (Sampling) \nChain 2 Iteration:  700 / 1500 [ 46%]  (Sampling) \nChain 1 Iteration:  700 / 1500 [ 46%]  (Sampling) \nChain 3 Iteration:  900 / 1500 [ 60%]  (Sampling) \nChain 4 Iteration:  700 / 1500 [ 46%]  (Sampling) \nChain 2 Iteration:  800 / 1500 [ 53%]  (Sampling) \nChain 3 Iteration: 1000 / 1500 [ 66%]  (Sampling) \nChain 1 Iteration:  800 / 1500 [ 53%]  (Sampling) \nChain 4 Iteration:  800 / 1500 [ 53%]  (Sampling) \nChain 3 Iteration: 1100 / 1500 [ 73%]  (Sampling) \nChain 2 Iteration:  900 / 1500 [ 60%]  (Sampling) \nChain 1 Iteration:  900 / 1500 [ 60%]  (Sampling) \nChain 3 Iteration: 1200 / 1500 [ 80%]  (Sampling) \nChain 4 Iteration:  900 / 1500 [ 60%]  (Sampling) \nChain 2 Iteration: 1000 / 1500 [ 66%]  (Sampling) \nChain 3 Iteration: 1300 / 1500 [ 86%]  (Sampling) \nChain 1 Iteration: 1000 / 1500 [ 66%]  (Sampling) \nChain 2 Iteration: 1100 / 1500 [ 73%]  (Sampling) \nChain 4 Iteration: 1000 / 1500 [ 66%]  (Sampling) \nChain 3 Iteration: 1400 / 1500 [ 93%]  (Sampling) \nChain 1 Iteration: 1100 / 1500 [ 73%]  (Sampling) \nChain 3 Iteration: 1500 / 1500 [100%]  (Sampling) \nChain 3 finished in 79.5 seconds.\nChain 2 Iteration: 1200 / 1500 [ 80%]  (Sampling) \nChain 4 Iteration: 1100 / 1500 [ 73%]  (Sampling) \nChain 1 Iteration: 1200 / 1500 [ 80%]  (Sampling) \nChain 2 Iteration: 1300 / 1500 [ 86%]  (Sampling) \nChain 4 Iteration: 1200 / 1500 [ 80%]  (Sampling) \nChain 1 Iteration: 1300 / 1500 [ 86%]  (Sampling) \nChain 2 Iteration: 1400 / 1500 [ 93%]  (Sampling) \nChain 4 Iteration: 1300 / 1500 [ 86%]  (Sampling) \nChain 1 Iteration: 1400 / 1500 [ 93%]  (Sampling) \nChain 2 Iteration: 1500 / 1500 [100%]  (Sampling) \nChain 2 finished in 93.7 seconds.\nChain 4 Iteration: 1400 / 1500 [ 93%]  (Sampling) \nChain 1 Iteration: 1500 / 1500 [100%]  (Sampling) \nChain 1 finished in 95.9 seconds.\nChain 4 Iteration: 1500 / 1500 [100%]  (Sampling) \nChain 4 finished in 97.4 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 91.6 seconds.\nTotal execution time: 97.6 seconds.\n\n\n\najuste$summary(c(\"alpha\", \"beta_0\", \"beta_1\", \"sigma\", \"Omega\")) |> select(variable, mean, q5, q95)\n\n# A tibble: 14 × 4\n   variable      mean        q5     q95\n   <chr>        <dbl>     <dbl>   <dbl>\n 1 alpha[1]    4.94      3.27     6.52 \n 2 alpha[2]    4.87      3.21     6.47 \n 3 alpha[3]    0.235    -1.41     1.83 \n 4 alpha[4]    0.191    -1.45     1.80 \n 5 alpha[5]   -0.0716   -1.70     1.50 \n 6 alpha[6]   -1.04   -497.     509.   \n 7 beta_0      0.0620   -0.0972   0.219\n 8 beta_1      2.98      2.92     3.03 \n 9 sigma[1]    2.29      2.21     2.38 \n10 sigma[2]    2.31      2.19     2.44 \n11 Omega[1,1]  1         1        1    \n12 Omega[2,1]  0.811     0.785    0.835\n13 Omega[1,2]  0.811     0.785    0.835\n14 Omega[2,2]  1         1        1    \n\n\nNótese que recuperamos el coeficiente correcto (\\(\\beta_1\\)).\nNotas:\n\nEn estos modelos, muchas veces es crucial la información a priori. Iniciales no informativas pueden dar resultados malos (dificultades numéricas, poca precisión y sesgo).\nFuera del ámbito bayesiano se utilizan métodos como mínimos cuadrados en 2 etapas.\nSin supuestos lineales, hay más supuestos que se tienen que cumplir para que este enfoque funcione (ver Morgan y Winship (2015)), por ejemplo, ¿qué se identifica en el caso de efecto heterogéneo sobre los individuos?\nEl enfoque de contrafactuales esclarece cómo funciona este método.\n\nEjemplos clásicos de potenciales instrumentos son:\n\nTemporada en la que nace una persona (construye por ejemplo un diagrama para educación, salario en el futuro y mes en el que nació una persona), y por qué variables instrumentales podrían ayudar a identificar el efecto causal de educación en salario futuro.\nDistancia a algún servicio: el uso de un servicio varía con la distancia para accederlo (por ejemplo, ¿cómo saber si un centro comunitario en una población mejora el bienestar del que lo usan?)\nLoterías reales para determinar cuál es el efecto de recibir una cantidad grande de dinero sobre bienestar o ahorros futuros, etc.\n\nPuedes encontrar más ejemplos en Morgan y Winship (2015) y aquí."
  },
  {
    "objectID": "06-exp-naturales.html#regresión-discontinua",
    "href": "06-exp-naturales.html#regresión-discontinua",
    "title": "6  Otros métodos para inferencia causal",
    "section": "6.4 Regresión discontinua",
    "text": "6.4 Regresión discontinua\nMuchas veces, la decisión de aplicar un tratamiento o no depende de un límite administrativo en una variable dada. Por ejemplo, supongamos que quisiéramos saber si una atracción particular de feria produce malestar en niños al salir del parque.\nTodos los niños de una escuela se forman para subirse a la atracción. Si al director de la escuela le interesara hacer un experimento, podría seleccionar al azar a algunos niños para subirse y otros no. Sin embargo, el director de la escuela nota que hay un límite de estatura que hay que pasar para poder subirse al juego.\nTienen la idea entonces de que esto presenta un experimento natural: entre todos los niños que están cerca de 1.20 de estatura, quién se sube o no prácticamente depende del azar.\nNuestro diagrama es como sigue:\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2, rankdir=LR]\n  node [shape = circle]\n    U\n    #V\n  node [shape=plaintext]\n    Estatura\n  edge [minlen = 3]\n     U -> Y\n     #V -> Estatura\n     #V -> Y\n    Estatura -> T\n    T -> Y\n    Estatura -> Y\n{rank = same; U; T}\n{rank = min;  Estatura}\n\n}\n\", width = 200, height = 200)\n\n\n\n\n\n\nComo vimos, hay una variable observable (la estatura) que determina la aplicación del tratamiento, y que se asigna de la siguiente forma:\n\nSi \\(Estatura >= 1.20\\) entonces \\(T=1\\)\nSi \\(Estatura < 1.20\\) entonces \\(T=0\\),\n\nentonces es posible restringir el análisis a un intervalo muy chico alrededor del punto de corte 1.20, y para fines prácticos el diagrama se convierte en:\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2, rankdir=LR]\n \n  node [shape = circle]\n    U\n  node [shape=plaintext]\n\n  edge [minlen = 3]\n     U -> Y\n     \n    Estatura120 -> T\n    T -> Y\n{rank = same; U; Y}\n{rank = min; T; Estatura120}\n}\n\",width = 200, height = 200)\n\n\n\n\n\n\nEn este caso, el grupo Estatura120 son aquellos que miden entre 118 y 122, por ejemplo, y estamos suponiendo que el efecto de la variación de la estatura en este grupo es mínimo.\nLa idea es comparar en el grupo Estatura120 aquellos que recibieron el tratamiento con los que no lo recibieron, y la razón es:\n\nCaminos no causales a través de Estatura están prácticamente bloqueados, pues prácticamente estamos condicionando a un valor de Estatura fijo.\nPor la regla administrativa, no existen otras variables no observadas que influyan en la asignación de tratamiento \\(T\\) (no hay puertas traseras).\n\nEn la práctica, usualmente un grupo suficientemente angosto produciría un tamaño de muestra chico y sería difícil estimar el efecto del tratamiento (no tendríamos precisión). Así que recurrimos a modelos simples de la forma\n\\[p(y|x)\\] que tienen la particularidad de que permiten un cambio discontinuo en la distribución en el punto de corte \\(x = x_0\\). Se puede tratar de dos modelos: uno del lado izquierdo y otro del lado derecho, aunque es posible que compartir parámetros.\n\nEjemplo simulado\nSupongamos existe un programa de becas para permanecer en la escuela que se les da a niños de 9 o más años cumplidos. Nos interesa ver cuál es la asistencia escolar en el año siguiente al programa. Veamos un ejemplo simulado:\n\ninv_logit <- function(x) 1/(1+exp(-x))\nsimular_des <- function(n = 100){\n  edad <- runif(n, 5, 12)\n  t <- ifelse(edad >= 9, 1, 0)\n  u <- rnorm(n, 0, 0.6)\n  asistencia_dias <- 200 * inv_logit(3 - 0.6* (edad - 5) + 1 * t + u)\n  tibble(edad, t, asistencia_dias)\n}\nset.seed(8)\ndatos_tbl <- simular_des(500)\nggplot(datos_tbl, aes(x = edad, y = asistencia_dias)) +\n  geom_point() +\n  geom_vline(xintercept = 9, colour = \"red\")\n\n\n\n\nPodríamos ajustar dos modelos:\n\nggplot(datos_tbl, aes(x = edad, y = asistencia_dias)) +\n  geom_point() +\n  geom_vline(xintercept = 9, colour = \"red\") +\n  geom_smooth(aes(group = t))\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\nSi nuestros modelos son apropiados, podemos estimar el efecto causal a los 9 años: el programa incrementa la asistencia en un promedio de larededor de 25 días de 200 posibles. Para hacer inferencia apropiadamente, podemos ajustar modelos como veremos más adelante.\n\n\n\n\n\n\nRegresión discontinua\n\n\n\nEl supuesto básico de identificación para regresión discontinua se puede expresar con contrafactuales:\n\nTanto \\(p(Y_i^1|X=x)\\) como \\(p(Y_i^0|X=x)\\) varían continuamente en el punto de corte \\(x=x_0\\)\nEl único criterio de aplicación del tratamiento es estar en \\(X\\) por arriba o abajo de \\(x_0\\).\n\n\n\nEsto quiere decir que si vemos un salto en el punto de corte del tratamiento, este se debe al tratamiento, y no a cómo son \\(p(Y_i^0|X=x)\\) y \\(p(Y_i^1|X=x)\\).\nEn particular, para el efecto promedio:\n\\[E[Y^1 - Y^0|X=x_0] = E[Y^1|X=x_0] - E[Y^1|X=x_0]\\] es igual a\n\\[\\lim_{x\\to x_0^+} E[Y^1|X=x_0] - \\lim_{x\\to x_0^-} E[Y^0|X=x_0]\\] Después de \\(x_0\\) todas las unidades tienen el tratamiento, y antes ninguna, de modo que esto equivale a\n\\[\\lim_{x\\to x_0^+} E[Y|X=x, T = 1] - \\lim_{x\\to x_0^-} E[Y|X=x, T = 0]\\] y estas dos cantidades están identificadas. Solamente usamos el supuesto de continuidad y del punto de corte para el tratamiento. Nótese que este supuesto se puede violar cuando unidades de un lado del corte son diferentes a las del otro lado, lo cual sucede por ejemplo cuando es un corte genérico que afecta muchas cosas o cuando de alguna manera la variable del corte es manipulable por los individuos:\n\nHay otras cosas que suceden el punto de corte, por ejemplo: es difícil usar mayoria de edad como punto de corte, porque varias cosas suceden cuando alguien cumple 18 años (puede votar, puede ser que tome decisiones alrededor de esos momentos, puede comprar alcohol, etc).\nHay maneras de manipular la variable con la que se hace el punto de corte (por ejemplo, si mi hijo nace en septiembre reporto en el acta que nació en agosto por fines escolares).\n\nUna manera usual de checar estos supuestos es considerar otras variables (que varían continuamente con la variable que usa para el corte), y que no deberían ser afectadas por el tratamiento, y verificar que no hay discontinuidades en el punto de corte de interés.\nPuedes ver más aquí\n\n\nEjemplo: parte 2\nArriba hicimos un ajuste con curvas loess. Lo más apropiado es construir modelos y así facilitar la inferencia del tamaño del efecto.\n\nlibrary(cmdstanr)\nlibrary(splines)\n\nmodelo_disc <- cmdstan_model(\"../src/reg-discontinua.stan\")\nprint(modelo_disc)\n\ndata {\n  int N;\n  int n_base;\n  vector[N] y;\n  vector[N] x;\n  vector[N] trata;\n  matrix[n_base, N] B;\n}\n\nparameters {\n  row_vector[n_base] a_raw;\n  real a0;\n  real delta;\n  real<lower=0> sigma;\n  real<lower=0> tau;\n}\n\ntransformed parameters {\n  row_vector[n_base] a;\n  vector[N] y_media;\n  a = a_raw * tau;\n  y_media = a0 * x + to_vector(a * B) + trata * delta;\n}\n\nmodel {\n  a_raw ~ normal(0, 1);\n  tau ~ normal(0, 1);\n  sigma ~ normal(0, 10);\n  delta ~ normal(0, 10);\n  y ~ normal(y_media, sigma);\n}\n\ngenerated quantities {\n\n}\n\n\n\nx <- datos_tbl$edad \nB <- t(ns(x, knots = 6, intercept = TRUE)) \ny <- datos_tbl$asistencia_dias\ntrata <- datos_tbl$t\ndatos_lista <- list(N = length(x), n_base = nrow(B), B = B,\n                    y = y, x = x, trata = trata)\najuste <- modelo_disc$sample(data = datos_lista, parallel_chains = 4)\n\nRunning MCMC with 4 parallel chains...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 1 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 2 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 3 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 4 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 1 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 2 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 4 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 3 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 1 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 2 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 4 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 1 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 3 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 2 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 3 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 4 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 1 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 2 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 3 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 4 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 1 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 2 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 4 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 1 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 3 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 2 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 3 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 4 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 1 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 2 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 1 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 3 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 4 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 2 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 3 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 4 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 2 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 3 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 4 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 1 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 2 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 3 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 4 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 1 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 2 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 3 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 4 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 1 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 4 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 2 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 3 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 1 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 3 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 4 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 2 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 4 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 1 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 2 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 3 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 1 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 4 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 2 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 3 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 4 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 1 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 2 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 3 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 4 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 1 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 2 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 3 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 4 finished in 4.8 seconds.\nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 finished in 5.0 seconds.\nChain 2 finished in 4.9 seconds.\nChain 3 finished in 4.9 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 4.9 seconds.\nTotal execution time: 5.1 seconds.\n\n\nNuestro resumen del efecto local en 9 años es el siguiente:\n\najuste$summary(\"delta\") |> select(variable, mean, q5, q95)\n\n# A tibble: 1 × 4\n  variable  mean    q5   q95\n  <chr>    <dbl> <dbl> <dbl>\n1 delta     19.3  12.6  25.8\n\n\nFinalmente, vemos cómo ajusta el modelo:\n\ny_media_tbl <- ajuste$draws(\"y_media\", format = \"df\") |> \n  pivot_longer(cols = contains(\"y_media\"), names_to = \"variable\") |> \n  separate(variable, into = c(\"a\", \"indice\"), sep = \"[\\\\[\\\\]]\", \n           extra = \"drop\", convert = TRUE) \n\nWarning: Dropping 'draws_df' class as required metadata was removed.\n\ny_media_tbl <- y_media_tbl |> \n  left_join(tibble(indice = 1:length(x), edad= x))\n\nJoining, by = \"indice\"\n\n\n\nres_y_media_tbl <- y_media_tbl |> group_by(indice, edad) |> \n  summarise(media = mean(value), q5 = quantile(value, 0.05),\n            q95 = quantile(value, 0.95))\n\n`summarise()` has grouped output by 'indice'. You can override using the\n`.groups` argument.\n\nggplot(res_y_media_tbl, aes(x = edad)) + \n  geom_line(aes(y = media), colour = \"red\", size = 2) +\n  geom_line(aes(y = q5), colour = \"red\") +\n  geom_line(aes(y = q95), colour = \"red\") + \n  geom_point(data = datos_tbl, aes(y = asistencia_dias), alpha = 0.2)\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\nNotas:\n\nIgual que en experimentos, puede tener sentido controlar por otras variables(“buenos controles”) para mejorar la precisión del análisis.\nEsto es especialmente cierto cuando la variable \\(x\\) en la regresión discontinua no determina de manera muy fuerte la respuesta \\(y\\) (datos ruidosos)\nEs necesario tener cuidado con la forma funcional que se utiliza en los modelos (ver esta liga, donde muestran por ejemplo este análisis que es incorrecto:\n\n\nEn general, usar polinomios de orden alto es mala idea, pues la forma general de los datos lejos de la discontinuidad puede influir fuertemente la diferencia que observamos cerca de la discontinuidad.\n\n\nEjemplo: edad mínima de consumo de alcohol\nConsideramos datos de The Effect of Alcohol Consumption on Mortality: Regression Discontinuity Evidence from the Minimum Drinking Age\nEn este caso, queremos ver el efecto causal de permitir legalmente tomar alcohol sobre la mortalidad de jóvenes. La regla administrativa en este caso es que a partir de los 21 años es legal que consuman alcohol.\nEn este ejemplo particular, los datos se agruparon en cubetas por rangos de edad de 2 meses de edad. Esto no es necesario (podríamos utilizar los datos desagregados y un modelo logístico, por ejemplo).\nVeamos dos ejemplos particulares, muertes en vehículos, suicidios y homicidios:\n\nmlda_tbl <- read_csv(\"../datos/mlda.csv\") |> \n  select(agecell,  over21, all, homicide, suicide, \n         `vehicle accidents` = mva, drugs, external, externalother) |> \n  pivot_longer(cols=c(all:externalother), names_to = \"tipo\", values_to = \"mortalidad\") |> \n  filter(tipo %in% c(\"vehicle accidents\", \"suicide\", \"homicide\"))\nhead(mlda_tbl)\n\n# A tibble: 6 × 4\n  agecell over21 tipo              mortalidad\n    <dbl>  <dbl> <chr>                  <dbl>\n1    19.1      0 homicide                16.3\n2    19.1      0 suicide                 11.2\n3    19.1      0 vehicle accidents       35.8\n4    19.2      0 homicide                16.9\n5    19.2      0 suicide                 12.2\n6    19.2      0 vehicle accidents       35.6\n\nggplot(mlda_tbl, aes(x = agecell, y = mortalidad, group = over21)) + geom_point() +\n  geom_smooth(method = \"loess\", span = 1, formula = \"y ~ x\") + facet_wrap(~tipo)\n\n\n\n\nEjercicio: construye modelos de stan para estos datos, como en el ejemplo anterior.\n\n\n\n\nFreedman, David A. 1991. «Statistical Models and Shoe Leather». Sociological Methodology 21: 291-313. http://www.jstor.org/stable/270939.\n\n\nMorgan, S. L., y C. Winship. 2015. Counterfactuals and Causal Inference. Analytical Methods for Social Research. Cambridge University Press. https://books.google.com.mx/books?id=Q6YaBQAAQBAJ."
  },
  {
    "objectID": "07-intro-series.html#patrones-en-series-de-tiempo",
    "href": "07-intro-series.html#patrones-en-series-de-tiempo",
    "title": "7  Análisis de series de tiempo",
    "section": "7.1 Patrones en series de tiempo",
    "text": "7.1 Patrones en series de tiempo\nAntes de comenzar a modelar estructura de series, mostramos los patrones que tienden a aparecer en diversas series\n\n\n\n\n\n\nPatrones principales\n\n\n\n\nTendencia y ciclos: patrones de largo plazo.\nPatrones periódicos fijos, estacionalidad.\nPatrones de corto plazo (autocorrelación o cambios estructurales).\n\n\n\nAbajo mostramos varios ejemplos estos patrones:\n\nEjemplo 1: tendencia y ciclos\nPrimero veremos una serie larga donde la característica principal es su tendencia general y la presencia de ciclos:\n\nautoplot(us_employment |> filter(Title == \"Total Private\"),\n         Employed) +\n  labs(subtitle = \"Total empleo privado (millones)\") + geom_point(size=0.1)\n\n\n\n\n\nSi principal característica es la tendencia creciente.\nSin embargo, existen desviaciones (que ocurren a largo de años) de tendencia lineal. Estos normalmente se consideran ciclos.\nEsta serie también tiene algo de estacionalidad que veremos\n\n\n\nEjemplo 2: estacionalidad\nPor ejemplo, examinemos la producción de energía eléctrica por mes en México:\n\nenergia <- read_csv(\"../datos/czpcimzhlu_IIIA1C01_12032023_21_29.csv\", \n                    na = c(\"N/D\", \"\", \"NA\")) |> \n  pivot_longer(cols = contains(\"/20\"), \n               names_to = \"mes_año\", values_to = \"generacion\") |> \n  mutate(fecha = yearmonth(my(mes_año))) |> \n  rename(estado = `...1`) |> \n  filter(!is.na(generacion)) |> \n  as_tsibble(key = estado, index = fecha)\n\n\nenergia_total <- energia |> filter(estado==\"TOTAL\")\nautoplot(energia_total, generacion) + geom_point() + \n  ylab(\"Generación (MWh)\")\n\n\n\n\nEn este ejemplo, vemos un patrón de estacionalidad fuerte de mayor generación de energía alrededor de la mitad del año:\n\ngg_season(energia_total, generacion)\n\n\n\n\n\nTambién tiene una tendencia creciente al principio de 2010 que parece terminar en 2012, junto con un cambio de nivel considerable a principios de 2020.\nPara este tipo de series de tiempo, es crucial hacer predicciones de corto plazo (un día, horas) y también puede ser útil hacer predicciones con horizontes más largos.\n\n\n\n7.1.1 Ejemplo 3\nConsideramos datos de afluencia para estaciones del metro en la CDMX. Veremos una estación en particular:\n\nmetro_tbl <- \n  read_csv(\"../datos/metro-cmdx/afluenciastc_simple_11_2022.csv\") |> \n  mutate(linea = str_replace(linea, \"í\", \"i\")) |> \n  mutate(dia_sem = weekdays(fecha)) |> \n  as_tsibble(index = fecha, key = c(estacion, linea)) \n\nRows: 919815 Columns: 6\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (3): mes, linea, estacion\ndbl  (2): anio, afluencia\ndate (1): fecha\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nestacion_tbl <- metro_tbl |> filter(estacion == \"Hospital General\") |> \n  filter(year(fecha) <= 2018) \n\n\nautoplot(estacion_tbl, afluencia, alpha = 0.5) + \n  facet_wrap(~ dia_sem)\n\n\n\n\n\nEn este caso vemos un tendencia descendiente, con algunas oscilaciones que ocurren a lo largo de varios años. Hay algunos días que parecen tener cierres (probablemente deberíamos considerar estos datos como faltantes) y también picos de uso interesantes.\nExiste un patrón de estacionalidad que en la siguiente gráfica anual: principalmente vemos menos afluencia a principios y finales de año:\n\n\nestacion_tbl |> gg_season(afluencia, alpha = 0.5) \n\n\n\n\nHay otros patrones periódicos que podemos examinar, por ejemplo el patrón semanal:\n\nestacion_tbl |> gg_season(afluencia, period = \"week\", alpha = 0.2)\n\n\n\n\n\nPodemos imaginar que series a nivel hora tendrían patrones adicionales periódicos que será necesario incluir para modelar y pronosticar adecuadamente."
  },
  {
    "objectID": "07-intro-series.html#ejemplo-series-irregulares",
    "href": "07-intro-series.html#ejemplo-series-irregulares",
    "title": "7  Análisis de series de tiempo",
    "section": "7.2 Ejemplo: series irregulares",
    "text": "7.2 Ejemplo: series irregulares\nEs común tratar con series irregulares, por ejemplo cuando consideramos datos de sensores. En este caso, vemos la serie de tiempo del nivel de una cisterna de cerca de 9 mil litros:\n\ncisterna_tbl <- read_csv(\"../datos/sensor-cisterna.csv\") |> \n  mutate(fecha_hora = as_datetime(last_updated_ts)) |> \n  mutate(fecha = as_date(fecha_hora)) |> \n  as_tsibble(index = fecha_hora, regular=FALSE)\n\n\nggplot(cisterna_tbl |> \n  filter(fecha < ymd(\"2023-03-01\"), fecha > ymd(\"2023-02-19\")),\n  aes(x = fecha_hora,  y = state)) + geom_line() + \n  geom_point() + ylab(\"Litros\")\n\n\n\n\nAdemás de patrones de uso y entrega de agua, observamos el hecho de que los sensores son ruidosos. Una tarea útil en estos casos es filtrar las observaciones ruidosas, por ejemplo para tener datos confiables para utilizar en automatización."
  },
  {
    "objectID": "07-intro-series.html#ejemplo-observaciones-heterogéneas",
    "href": "07-intro-series.html#ejemplo-observaciones-heterogéneas",
    "title": "7  Análisis de series de tiempo",
    "section": "7.3 Ejemplo: observaciones heterogéneas",
    "text": "7.3 Ejemplo: observaciones heterogéneas\nOtro ejemplo adicional que consideraremos son observaciones irregulares con mediciones heterogéneas (algunas contemporáneas), por ejemplo, cuando consideramos el problema de utilizar encuestas para predecir resultados de elecciones. En este caso vemos datos para 2016, extraídos de TheEconomist us-potus-model\n\n# https://github.com/TheEconomist/us-potus-model/tree/master/data\ngelman_tbl <- read_csv(\"../datos/all_polls_gelman.csv\")\n\n\npolls_tbl <- gelman_tbl |> \n  mutate(undecided = ifelse(is.na(undecided), 0, undecided)) |> \n  mutate(oter = ifelse(is.na(other), 0, other)) |> \n  mutate(H_Clinton = clinton/(clinton + trump),\n  D_Trump = 1 - H_Clinton) |> \n  filter(population %in% c(\"Likely Voters\", \"Registered Voters\"), \n         end.date > \"2016-06-10\",\n         pollster %in% c(\"Ipsos/Reuters\", \"Quinnipiac\",\n         \"Monmouth University\", \"SurveyMonkey\", \"UPI/CVOTER\"),\n         state == \"--\")\n\n\nggplot(polls_tbl, aes(x = end.date, y = H_Clinton, colour = pollster)) +\n  geom_hline(yintercept = 0.5, colour = \"gray\") +\n  geom_point() + ylim(c(0.4,0.7))"
  },
  {
    "objectID": "07-intro-series.html#estructura-de-correlación-a-corto-plazo",
    "href": "07-intro-series.html#estructura-de-correlación-a-corto-plazo",
    "title": "7  Análisis de series de tiempo",
    "section": "7.4 Estructura de correlación a corto plazo",
    "text": "7.4 Estructura de correlación a corto plazo\nEn escalas más cortas, también podemos encontrar patrones de asociación más allá de las que produce la tendencia, ciclos y estacionalidad, y que son importantes para entender la serie.\nEn primer lugar, consideramos datos simulados:\n\ngenerar_obs <- function(n = 200, phi = 0.5, a = 100, sigma = 5, nu = NULL){\n  y <- numeric(n)\n  e <- numeric(n)\n  tendencia <- numeric(n)\n  tendencia[1] <- rnorm(1, a, 0.2 * a)\n  if(is.null(nu)){\n      nu <- rnorm(n, 0, 10)\n  }\n  epsilon <- rnorm(n, 0, 20)\n  for(i in 2:n){\n    e[i] <- phi * e[i - 1] + epsilon[i]\n    tendencia[i] <-  tendencia[i - 1] + nu[i]\n  }\n  y <- tendencia + e \n  tibble(t = 1:n, y = y, phi = phi, y_detrend = e)\n}\nset.seed(82)\nnu <- rnorm(200, 0, 10)\nserie_1 <- generar_obs(phi = -0.7, nu = nu ) \nserie_2 <- generar_obs(phi =  0.0, nu = nu ) \nserie_3 <- generar_obs(phi =  0.7, nu = nu ) \nseries_tbl <- bind_rows(list(serie_1, serie_2, serie_3)) |> \n  as_tsibble(index = t, key = phi)\n\n\nggplot(series_tbl, aes(x = t, y = y)) +\n  geom_line() +\n  facet_wrap(~ phi, ncol = 1) +\n  geom_smooth(se = FALSE, span = 0.5)\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\nEstas tres series, aunque tienen una tendencia similar, tienen un patrón de variación distinto en el corto plazo:\n\nLa primera serie tiende a “sobrecorregir” al siguiente periodo cuando se aleja de la tendencia\nEn la segunda serie, las variaciones alrededor de la tendencia no tienen dependencia: a este caso se le llama a veces ruido blanco.\nEn la tercera serie, la serie tiende tener oscilaciones más largas alrededor de la tendencia.\n\nPara confirmar nuestra observación, podemos hacer una gráfica de rezagos para las series sin tendencia (es decir, restamos la tendencia de la gráfica anterior a los datos):\n\ngg_lag(series_tbl |> filter(phi == -0.7), \n       y_detrend, lags = 1:4, geom = \"point\") + ylab(\"\")\ngg_lag(series_tbl |> filter(phi == 0.7), \n       y_detrend, lags = 1:4, geom = \"point\") \n\n\n\n\n\n\nFig 1\n\n\n\n\n\n\n\nFig 2\n\n\n\n\n\n\nY podemos resumir estas gráficas calculando un resumen de asociación, usualmente la correlacción en cada de una de estas gráficas (es decir, una serie contra la misma serie rezagada en \\(h\\) tiempos):\n\n\n\n\n\n\nFunción de autocorrelación\n\n\n\nLa función de autocorrelación para rezagos \\(h=1,2,\\ldots\\) está dada por\n\\[\\textrm{ACF(h)} = \\rho(h) = \\textrm{cor}(y_t, y_{t-h})\\]\n\n\n\nEn palabras, comparamos la serie con una versión rezagada de ella misma.\nLa ACF captura varios aspectos de autocorrelación de la serie: por ejemplo, refleja también tendencia y estacionalidad.\nGeneralmente es más útil en series donde hemos quitado tendencia y estacionalidad, y así la usaremos típicamente en este curso.\nUn ejemplo es el siguiente: veremos que una señal de modelos para pronósticos deficientes es que la ACF de los errores de predicción no es ruido blanco (nuestro pronóstico no está usando toda la información disponible).\n\nPara el ejemplo de arriba, tenemos\n\nacf_tbl <- series_tbl |> ACF(y_detrend) \nacf_tbl |> head()\n\n# A tsibble: 6 x 3 [1]\n# Key:       phi [1]\n    phi      lag    acf\n  <dbl> <cf_lag>  <dbl>\n1  -0.7        1 -0.699\n2  -0.7        2  0.430\n3  -0.7        3 -0.294\n4  -0.7        4  0.248\n5  -0.7        5 -0.202\n6  -0.7        6  0.111\n\n\n\nautoplot(acf_tbl)\n\n\n\n\ntres series\n\n\n\n\nNota 1: dado que la ACF se estima con una muestra, tiene error. Las líneas punteadas que generalmente la acompañan son intervalos de 95% para la autocorrelación bajo la hipótesis de que los valores de la serie no tienen correlación.\nEste resumen coincide con nuestra descripción de arriba: la primera serie oscila “sobre-corrigiendo”, la segunda serie oscila de manera más suave alrededor de la tendencia. En la intermedia vemos que las estimaciones están generalmente dentro de la banda señalada por las líneas puntuadas.\n\nEjemplo: nacimientos\nEn general, cuando calculamos la ACF de una serie con tendencia-ciclo y estacionalidad fuertes, esos son los aspectos que tienden a dominar la gráfica.\nConsideremos por ejemplo la siguiente serie de nacimientos por día en México:\n\nnatalidad_tbl <- read_rds(\"../datos/natalidad.rds\") |> \n  ungroup() |> \n  arrange(fecha) |> \n  filter(fecha > ymd(\"2000-01-01\")) |> \n  rename(nacimientos = n) |> \n  as_tsibble(index = fecha)\n\nLa serie completa se ve como sigue:\n\nautoplot(natalidad_tbl, alpha = 0.8)\n\nPlot variable not specified, automatically selected `.vars = nacimientos`\n\n\n\n\n\nAhora consideramos la función de autocorrelacción, que tiene un pico negativo en el primer rezago:\n\nACF(natalidad_tbl, nacimientos, lag_max = 60) |> autoplot()\n\n\n\n\nEsta ACF captura tanto la tendencia-ciclo (todas las correlaciones son positivas), como la estacionalidad (picos en múltiplos de 7 días). Podemos ver esta relación graficando directamente la serie contra sus rezagos:\n\ngg_lag(natalidad_tbl, nacimientos, geom = \"point\", size = 1, alpha = 0.6) \n\n\n\n\nVeremos más adelante técnicas para extraer tendencia, ciclo y estacionalidad de series. En este caso utilizaremos el metodo loess para examinar qué sucede con la variación adicional que podemos explicar con tendencia y estacionalidad anual y semanal:\n\ndescomp_nat <- natalidad_tbl |>\n  model(\n    STL(nacimientos ~ trend(window = 101) +\n          season(period = \"1 year\", window = 7) +\n          season(period = \"week\", window =15),\n    robust = TRUE)) |>\n  components() \n\n\nggplot(descomp_nat, aes(x = fecha, y = remainder)) + \n  geom_line()\n\n\n\n\nComo vemos, esta serie no tiene una tendencia o estacionalidad claras, pues las hemos extraido con el proceso de arriba. Sin embargo, tiene una estructura de correlación:\n\ndescomp_nat |> as_tsibble(index = fecha) |> \n  ACF(remainder) |> \n  autoplot() + ylim(c(-0.2,0.2))\n\n\n\n\nNotamos que, aunque las autocorrelaciones son mucho más chicas, todavía existe una correlación positiva en rezago 1 y 2.\nPor otro lado, si se tratara de una serie donde las observaciones no tienen ninguna correlación, observaríamos:\n\ndescomp_nat <- mutate(descomp_nat, \n  remainder_perm = sample(remainder))\nggplot(descomp_nat, aes(x = fecha, y = remainder_perm)) + \n  geom_line()\n\n\n\n\nCon ACF como sigue:\n\ndescomp_nat |> as_tsibble(index = fecha) |> \n  ACF(remainder_perm) |> \n  autoplot() + ylim(c(-0.2,0.2))"
  },
  {
    "objectID": "07-intro-series.html#más-de-autocorrelación",
    "href": "07-intro-series.html#más-de-autocorrelación",
    "title": "7  Análisis de series de tiempo",
    "section": "7.5 Más de autocorrelación",
    "text": "7.5 Más de autocorrelación\nConsideramos \\(y_1,y_2,\\ldots, y_T\\) observaciones de una serie de tiempo, donde el subíndice indica el momento donde se tomó cada observación. Un modelo que podemos considerar es el siguiente:\n\n\nCódigo\ngrViz('\ndigraph {\n  graph [ranksep = 0.2]\n  node [shape=plaintext]\n        Y1 [label = <Y<SUB>1</SUB>>]\n    dots [label = \"...\"]\n    Ytm1 [label = <Y<SUB>t-1</SUB>>]\n    Yt [label = <Y<SUB>t</SUB>>]\n    Yt1 [label = <Y<SUB>t+1</SUB>>]\n    Yt2 [label = <Y<SUB>t+2</SUB>>]\n    etm1 [label = <e<SUB>t-1</SUB>>]\n    et [label = <e<SUB>t</SUB>>]\n    et1 [label = <e<SUB>t+1</SUB>>]\n    et2 [label = <e<SUB>t+2</SUB>>]\n  edge [minlen = 3]\n   Y1 -> dots\n   dots -> Ytm1\n   Ytm1 -> Yt\n   Yt -> Yt1\n   Yt1 -> Yt2\n   e1 -> Y1\n   etm1 -> Ytm1\n   et -> Yt\n   et1 -> Yt1\n   et2 -> Yt2\n{rank=same; Y1; dots; Ytm1; Yt; Yt1; Yt2}\n\n}\n', width = 200, height = 40)\n\n\n\n\n\n\nEn este modelo suponemos que dado \\(Y_{t}\\), \\(Y_{t+1}\\) es condicionalmente independiente de cualquier otra \\(Y\\) anterior a \\(t\\). La conjunta \\(p(y_1,y_2,\\ldots, y_T)\\) se escribe como\n\\[p(y_1)p(y_2|y_1)\\cdots p(y_{T-1}|y_{T-2}) p(y_T | y_{T-1})\\] Y podemos definir un modelo para cada \\(p(y_t|y_{t-1})\\). En modelos estáticos, generalmente se define una relación que depende de parámetros fijos, por ejemplo, un modelo autoregresivo de orden 1 AR(1) con errores normales es:\n\\[y_t = \\alpha_0 + \\alpha_1 y_{t-1} + \\epsilon_t\\] donde \\(\\epsilon_t\\sim N(0,\\sigma)\\) son independientes. En este caso, la relación probabilística de entre las observaciones es fija en cualquier tiempo. Podemos estimar \\(\\alpha_1\\), que se puede escribir en términos de la correlación entre \\(y_t\\) y \\(y_{t-1}\\), y podemos interpretar como el efecto directo d \\(y_{t-1}\\) sobre \\(y_t\\).\nCuando consideramos la correlación entre \\(y_{t-2}\\) y \\(y_t\\), sustituyendo en le ecuación anterior podemos ver que también se trata de un modelo lineal. Podemos estimar el coeficiente de \\(y_{t-2}\\) (que es \\(\\alpha_1^2\\)). En este caso, obtenemos esta correlación por el efecto mediado por \\(y_{t-1}\\), como en el ejemplo anterior de las tres series que vimos arriba.\nEn este caso, la ACF muestra correlaciones totales (efecto total). Podríamos también preguntarnos por correlaciones parciales, que es la correlación entre \\(y_t\\) y \\(y_{t-2}\\) condicionando a \\(y_{t-1}\\). En este caso nos interesa el efecto directo de \\(y_{t-2}\\) sobre \\(y_t\\), controlando por \\(y_{t-1}\\).\nPodemos definir la función de autocorrelación parcial PACF como las correlaciones entre \\(y_t\\) y \\(y_{t-h}\\) condicionadas a los valores intermedios \\(y_{t-1},\\ldots, y_{t-h}\\): es decir, es la correlación directa, bloqueando la correlación que ocurre a través de otros nodos de la gráfica\nEn nuestro ejemplo anterior, encontramos que\n\nseries_tbl |> ACF(y_detrend) |> \n  autoplot()\n\n\n\n\nSin embargo, las autocorrelaciones parciales dan:\n\nseries_tbl |> PACF(y_detrend) |> \n  autoplot()\n\n\n\n\nY vemos que el coeficiente del primer rezago es igual que el de la ACF (no condicionamos a nada), pero una vez que condicionamos a rezagos intermedios, las correlaciones parciales son 0. De esta manera identificamos que el modelo subyacente es autoregresivo de orden 1.\nPodemos también considerar otras estructuras para modelar, como\n\n\nCódigo\ngrViz('\ndigraph {\n  graph [ranksep = 0.2]\n  node [shape=plaintext]\n        Y1 [label = <Y<SUB>1</SUB>>]\n    dots [label = \"...\"]\n    Ytm1 [label = <Y<SUB>t-1</SUB>>]\n    Yt [label = <Y<SUB>t</SUB>>]\n    Yt1 [label = <Y<SUB>t+1</SUB>>]\n    Yt2 [label = <Y<SUB>t+2</SUB>>]\n    aa [label = \"\"]\n        etm1 [label = <e<SUB>t-1</SUB>>]\n    et [label = <e<SUB>t</SUB>>]\n    et1 [label = <e<SUB>t+1</SUB>>]\n    et2 [label = <e<SUB>t+2</SUB>>]\n  edge [minlen = 3]\n   Y1 -> dots\n   dots -> Ytm1\n   Ytm1 -> Yt\n   Ytm1 -> Yt1\n   Yt -> Yt1\n   Yt -> Yt2\n   Yt1 -> Yt2\n   aa -> Ytm1\n   e1 -> Y1\n   etm1 -> Ytm1\n   et -> Yt\n   et1 -> Yt1\n   et2 -> Yt2\n{rank=same; Y1; dots; Ytm1; Yt; Yt1; Yt2;aa}\n}\n', width = 200, height = 40)\n\n\n\n\n\n\nEn este caso, el modelo generador es de la forma\n\\[y_t = \\alpha_0 + \\alpha_1 y_{t-1} + \\alpha_2 y_{t-2} + \\epsilon_t\\] donde \\(\\epsilon_t\\sim N(0,\\sigma)\\) son independientes. Abajo simulamos de estos modelos:\n\ngenerar_obs_2 <- function(n = 200, phi = c(0.5, 0.2), \n                          a = 100, sigma = 5, nu = NULL){\n  y <- numeric(n)\n  e <- numeric(n)\n  tendencia <- numeric(n)\n  tendencia[1] <- rnorm(1, a, 0.2 * a)\n  if(is.null(nu)){\n      nu <- rnorm(n, 0, 10)\n  }\n  epsilon <- rnorm(n, 0, 20)\n  for(i in 2:n){\n    tendencia[i] <-  tendencia[i - 1] + nu[i]\n  }\n  for(i in 3:n){\n    e[i] <- phi[1] * e[i - 1] + phi[2] * e[i - 2] + epsilon[i]\n  }\n  y <- tendencia + e \n  tibble(t = 1:n, y = y, phi = paste(phi, collapse = \",\"), y_detrend = e)\n}\nset.seed(82)\nnu <- rnorm(200, 0, 10)\nserie_1 <- generar_obs_2(phi = c(-0.3, 0.5), nu = nu ) \nserie_2 <- generar_obs_2(phi =  c(0.0, 0.0), nu = nu ) \nserie_3 <- generar_obs_2(phi =  c(0.3, 0.5), nu = nu ) \nseries_2_tbl <- bind_rows(list(serie_1, serie_2, serie_3)) |> \n  as_tsibble(index = t, key = phi)\n\n\nseries_2_tbl |> ACF(y_detrend) |> \n  autoplot()\n\n\n\n\nSin embargo, las autocorrelaciones parciales dan:\n\nseries_2_tbl |> PACF(y_detrend) |> \n  autoplot()\n\n\n\n\nY estas gráficas son típicas para un proceso AR(2) como el que simulamos.\n\n\n\n\n\n\nModelos AR(p)\n\n\n\n\nEn los modelos autorregresivos de orden \\(p\\) suponemos una relación lineal no dinámica con valores anteriores de la serie observada.\nIdentificamos \\(p\\) por sus patrones de autocorrelación y autocorrelación parcial.\nSon parte del esquema ARIMA (o SARIMA) para hacer pronósticos.\n\n\n\nEn este curso no nos concentramos en modelos ARIMA, pues no son muy apropiados para nuestra primera tarea de entender la estructura de series de tiempo, pero son modelos que pueden dar buenos resultados en pronósticos. Puedes leer más en nuestra referencia Forecasting: Principles and Practica."
  },
  {
    "objectID": "08-modelos-1.html#modelo-de-nivel-local",
    "href": "08-modelos-1.html#modelo-de-nivel-local",
    "title": "8  Modelos de espacio de estados",
    "section": "8.1 Modelo de nivel local",
    "text": "8.1 Modelo de nivel local\nEn primer lugar, consideraremos modelar la tendencia-ciclo de series con el enfoque de espacio de estados. En primer lugar, tenemos una ecuación de observación, que está dada por\n\\[y_t = \\textrm{nivel}_t + \\epsilon_t,\\] donde las \\(\\epsilon_t \\sim N(0,\\sigma_\\epsilon)\\) independientes. Es decir, dado el nivel, las observaciones \\(y_t\\) son independientes. Adicionalmente tenemos una ecuación de transición de estados, que en este caso es simplemente:\n\\[\\textrm{nivel}_t = \\textrm{nivel}_{t-1} + \\eta_t\\] donde \\(\\eta_t \\sim N(0,\\sigma_\\eta)\\) independientes.\nPodemos hacer un diagrama como sigue para esta situación:\n\n\nCódigo\ngrViz('\ndigraph {\n  graph [ranksep = 0.2]\n  node [shape=circle]\n    nt\n    nt1\n    nt2\n    ntm1\n    etm1\n    et\n    et1\n    et2\n  node [shape=plaintext]\n    #    Y1 [label = <Y<SUB>1</SUB>>]\n    dots [label = \"...\"]\n    Ytm1 [label = <Y<SUB>t-1</SUB>>]\n    Yt [label = <Y<SUB>t</SUB>>]\n    Yt1 [label = <Y<SUB>t+1</SUB>>]\n    Yt2 [label = <Y<SUB>t+2</SUB>>]\n    etm1 [label = <e<SUB>t-1</SUB>>]\n    et [label = <  e<SUB>t. </SUB>>]\n    et1 [label = <e<SUB>t+1</SUB>>]\n    et2 [label = <e<SUB>t+2</SUB>>]\n        ntm1 [label = <n<SUB>t-1</SUB>>]\n    nt [label = <  n<SUB>t  </SUB>>]\n    nt1 [label = <n<SUB>t+1</SUB>>]\n    nt2 [label = <n<SUB>t+2</SUB>>]\n  edge [minlen = 3]\n   #Y1 -> dots\n   #dots -> Ytm1\n   #Ytm1 -> Yt\n   #Yt -> Yt1\n   #Yt1 -> Yt2\n   ntm1 -> Ytm1\n   ntm1 -> nt\n   nt1 -> Yt1\n   nt -> Yt\n   nt2 -> Yt2\n   nt -> nt1\n   nt1 -> nt2\n   #e1 -> Y1\n   etm1 -> Ytm1\n   et -> Yt\n   et1 -> Yt1\n   et2 -> Yt2\n{rank=same;  Ytm1; Yt; Yt1; Yt2}\n{rank=max; ntm1; nt; nt1; nt2}\n{rank=min; etm1; et; et1; et2}\n\n\n}\n', width = 300, height = 150)\n\n\n\n\n\n\nNótese que en esta gráfica, las \\(y_t\\) no son independientes: están correlacionadas a través de caminos abiertos que pasan por el estado, que en este caso es el nivel de la serie.\n\n\n\n\n\n\nModelos de espacio de estados\n\n\n\nLos modelos de espacio de estados para serie de tiempo consisten en dos ecuaciones. Si \\(y_t\\) son los datos observados y \\(\\theta_t\\) son los parámetros que describen el estado, tenemos la ecuación de observación \\[y_t = f(\\theta_t, \\epsilon_t)\\] Es decir, cómo se relaciona el estado con las observaciones, y una ecuación de evolución del estado: \\[\\theta_t = g(\\theta_{t-1}, \\eta_t)\\] En los modelos dinámicos lineales (DLM), \\(f\\) y \\(g\\) son funciones lineales.\n\n\nNota: más adelante veremos detalles de este planteamiento, en particular para los DLMs, y por qué aún cuando haya dependencias de más largo plazo en estado siempre es posible escribir nuestros modelos de esta forma.\nPara completar este modelo, es necesario:\n\nPoner una distribución previa al estado inicial \\(p(\\textrm{nivel}_1)\\)\nPoner distribuciones previas al tamaño del ruido de la medición \\(p(\\sigma_\\epsilon)\\) y a la evolución del nivel \\(p(\\sigma_\\eta)\\).\n\nUsualmente consideramos que el nivel debe tener movimientos relativamente suaves, de manera que \\(p(\\sigma_\\eta)\\) debe estar adecuadamente concentrada cerca de 0."
  },
  {
    "objectID": "08-modelos-1.html#ejemplo-nivel-del-río-nilo",
    "href": "08-modelos-1.html#ejemplo-nivel-del-río-nilo",
    "title": "8  Modelos de espacio de estados",
    "section": "8.2 Ejemplo: nivel del río Nilo",
    "text": "8.2 Ejemplo: nivel del río Nilo\nEmpezamos con un ejemplo clásico y simple, que consiste en medidas anuales del nivel del río Nilo.\nUsaremos Stan para ver los detalles de la implementación del modelo de nivel local:\n\nlibrary(cmdstanr)\n\nThis is cmdstanr version 0.5.3\n\n\n- CmdStanR documentation and vignettes: mc-stan.org/cmdstanr\n\n\n- CmdStan path: /home/runner/.cmdstan/cmdstan-2.31.0\n\n\n- CmdStan version: 2.31.0\n\nsource(\"../R/limpiar_draws.R\")\nmodelo_nivel <- cmdstan_model(\"../src/series-de-tiempo/modelo-nivel-local.stan\")\nprint(modelo_nivel)\n\ndata {\n  int<lower=0> N;\n  vector[N] y;\n  real s_obs;\n  int<lower=0> n_h; //numero de periodos de pronóstico\n  real q;\n}\n\nparameters {\n\n  real alpha_1;\n  real<lower=0> sigma_nivel;\n  real<lower=0> sigma_obs;\n  vector[N + n_h] z_nivel;\n\n}\n\ntransformed parameters {\n  vector[N + n_h] mu;\n  vector[N + n_h] alpha;\n\n  alpha[1] = alpha_1;\n  mu[1] = alpha[1];\n  for(t in 2:(N + n_h)){\n    alpha[t] = alpha[t-1] + z_nivel[t] * sigma_nivel;\n    mu[t] = alpha[t];\n  }\n}\n\nmodel {\n  y[1:N] ~ normal(mu[1:N], sigma_obs);\n  alpha_1 ~ normal(y[1], s_obs);\n  z_nivel ~ normal(0, 1);\n  sigma_nivel ~ normal(0, q * s_obs);\n  sigma_obs ~ normal(0, s_obs);\n\n}\n\ngenerated quantities{\n  vector[N] y_rep;\n  vector[n_h] y_f;\n\n\n  for(t in 1:N){\n    y_rep[t] = normal_rng(mu[t], sigma_obs);\n  }\n  for(h in 1:n_h){\n    y_f[h] = normal_rng(mu[N + h], sigma_obs);\n  }\n}\n\n\n\nsims <- modelo_nivel$sample(\n  data = list(y = Nile, N = length(Nile),  s_obs = 200, q = 0.5, n_h = 4),\n  parallel_chains = 4, refresh = 1000, init = 0.1, step_size = 0.1,\n  adapt_delta = 0.99)\n\nRunning MCMC with 4 parallel chains...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \n\n\nChain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n\n\nChain 1 Exception: normal_lpdf: Location parameter[2] is inf, but must be finite! (in '/tmp/RtmpDYlMU7/model-28874c8a89a1.stan', line 31, column 2 to column 38)\n\n\nChain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n\n\nChain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n\n\nChain 1 \n\n\nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 2 finished in 8.1 seconds.\nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 finished in 8.2 seconds.\nChain 4 finished in 8.1 seconds.\nChain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 3 finished in 8.2 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 8.2 seconds.\nTotal execution time: 8.4 seconds.\n\n\nMostramos primero nuestra estimación de las desviaciones estándar para el nivel y para la observación:\n\nsims$summary(c(\"sigma_obs\", \"sigma_nivel\"))\n\n# A tibble: 2 × 10\n  variable     mean median    sd   mad    q5   q95  rhat ess_bulk ess_tail\n  <chr>       <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>    <dbl>    <dbl>\n1 sigma_obs   123.   122.   12.6  12.5 102.  144.   1.00     910.    1829.\n2 sigma_nivel  43.1   41.4  15.7  16.1  20.5  71.3  1.00     519.     930.\n\n\nY ahora resumimos y mostramos cómo se ve el nivel inferido bajo nuestro modelo.\n\nsims_nivel_tbl <- sims$draws(c(\"mu\"), format = \"df\") |> \n  limpiar_draws(c(\"mu\")) \n\nWarning: Dropping 'draws_df' class as required metadata was removed.\n\nmedia_tbl <- sims_nivel_tbl |>  \n  group_by(variable, t) |> \n  summarise(media = mean(valores), q5 = quantile(valores, 0.05),\n            q95 = quantile(valores, 0.95))\n\n`summarise()` has grouped output by 'variable'. You can override using the\n`.groups` argument.\n\n\n\nggplot(sims_nivel_tbl |> filter(variable == \"mu\")) + \n  geom_line(aes(x = t, y = valores, group = .draw), \n            alpha = 0.01, size = 0.1, colour = \"red\") +\n  geom_line(data = media_tbl, aes(x = t, y = media), colour = \"red\") +\n  geom_point(data = tibble(y = Nile), aes(x = 1:length(Nile), y = Nile))\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\nEn esta gráfica:\n\nLa línea roja es el valor esperado del nivel (que originalmente no es observado).\nLa nube roja muestra varias simulaciones del nivel. Con esto entendemos cuánta incertidumbre tenemos acerca de la verdadera posición del nivel en cada momento.\nNótese que la nube roja no tiene por qué cubrir los valores observados de la serie, pues la ecuación de observación tiene incertidumbre adicional.\nExtendimos la estimación del estado para cuatro años adicionales. Nota cómo conforme avanza el tiempo perdemos certidumbre acerca de dónde se encontrará el nivel.\nNuestro modelo tiene 100 observaciones y 100 + 2 + 1 parámetros: el estado incial del nivel, las dos desviaciones estándar de modelos de observación y de estado, y los 100 niveles no observados.\n\nPodemos hacer chequeos predictivos posteriores simulando distintas series a partir de los parámetros ajustados, y viendo si la estructura difiere mucho de\n\nobs_rep_tbl <- sims$draws(c(\"y_rep\"), format = \"df\") |> \n  limpiar_draws(c(\"y_rep\")) \n\nWarning: Dropping 'draws_df' class as required metadata was removed.\n\nresumen_tbl <- obs_rep_tbl |> \n  filter(.draw <= 10) #|> \n  #group_by(variable, t, indice, .draw) |> \n  #summarise(media = mean(valores), q5 = quantile(valores, 0.05),\n  #          q95 = quantile(valores, 0.95))\n\n\nresumen_tbl <- resumen_tbl |> \n  bind_rows(tibble(t = 1:length(Nile), valores = Nile, .draw = 11))\nggplot(resumen_tbl, aes(x = t, y = valores)) + geom_line() +\n  facet_wrap(~ .draw)\n\n\n\n\nComo es usual, cualquier resumen relevante puede usarse para hacer chequeos predictivos posteriores, por ejemplo, las gráficas de acutocorrelación de datos simulados (una caja tiene los verdaderos datos observados):\n\nresumen_tbl |> as_tsibble(index = t, key = .draw) |> \n  filter(.draw > 5, t <= 100) |> \n  ACF(valores) |> autoplot()\n\n\n\n\n\n\n\n\n\n\nDiagnósticos para nivel local\n\n\n\n\nEs posible hacer chequeos posteriores predictivos como con cualquier modelo bayesiano generativo.\nVeremos más adelante un diagnóstico importante que por ahora excluímos: la verificación de que las predicciones un paso hacia adelante cumplen ciertas propiedades. Una de las más importantes es que no tengan autocorrelación\n\n\n\nFinalmente, podemos ver cómo se ven pronósticos bajo este modelo. En este caso, en la parte de cantidades generadas incluímos el código relevante. Nuestro pronóstico podríamos graficarlo como sigue (con intervalos de 90%, por ejemplo):\n\npronosticos_tbl <- sims$draws(c(\"y_f\"), format = \"df\") |> \n  limpiar_draws(c(\"y_f\")) |> \n  group_by(variable, t) |> \n  summarise(media = mean(valores), q5 = quantile(valores, 0.05),\n            q95 = quantile(valores, 0.95)) |> \n  mutate(t = t + length(Nile))\n\nWarning: Dropping 'draws_df' class as required metadata was removed.\n\nggplot(sims_nivel_tbl |> filter(variable == \"mu\")) + \n  geom_line(aes(x = t, y = valores, group = .draw), \n            alpha = 0.01, size = 0.1, colour = \"red\") +\n  geom_line(data = media_tbl, aes(x = t, y = media), colour = \"red\") +\n  geom_point(data = tibble(y = Nile), aes(x = 1:length(Nile), y = Nile)) +\n  geom_ribbon(data = pronosticos_tbl, aes(x = t, y = media, ymin = q5,\n                                         ymax = q95), alpha = 0.1) +\n  geom_point(data = pronosticos_tbl, aes(x = t, y = media))\n\n\n\n\n\nEjemplo de desajuste\nSupongamos que en nuestro ejemplo no utilizáramos nivel dinámico, sino constante.\n\nsims_desajuste <- modelo_nivel$sample(\n  data = list(y = Nile, N = length(Nile),  s_obs = 200, q = 0.00001, n_h = 4),\n  parallel_chains = 4, refresh = 1000, init = 0.1, step_size = 0.1,\n  adapt_delta = 0.99)\n\nRunning MCMC with 4 parallel chains...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 2 finished in 2.0 seconds.\nChain 4 finished in 2.0 seconds.\nChain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 3 finished in 2.0 seconds.\nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 finished in 2.4 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 2.1 seconds.\nTotal execution time: 2.4 seconds.\n\n\nRepetimos nuestros chequeos posteriores predictivos:\n\nobs_rep_tbl <- sims_desajuste$draws(c(\"y_rep\"), format = \"df\") |> \n  limpiar_draws(c(\"y_rep\")) \n\nWarning: Dropping 'draws_df' class as required metadata was removed.\n\nresumen_tbl <- obs_rep_tbl |> \n  filter(.draw <= 10) #|> \n  #group_by(variable, t, indice, .draw) |> \n  #summarise(media = mean(valores), q5 = quantile(valores, 0.05),\n  #          q95 = quantile(valores, 0.95))\n\n\nresumen_tbl <- resumen_tbl |> \n  bind_rows(tibble(t = 1:length(Nile), valores = Nile, .draw = 11))\nggplot(resumen_tbl, aes(x = t, y = valores)) + geom_line() +\n  facet_wrap(~ .draw)\n\n\n\n\n\nresumen_tbl |> as_tsibble(index = t, key = .draw) |> \n  filter(.draw > 7, t <= 100) |> \n  ACF(valores) |> autoplot()\n\n\n\n\nEn todas estas gráficas podemos identificar claramente donde están los datos. Nuestro modelo de nivel constante (no dinámico) no ajusta a estos datos simples."
  },
  {
    "objectID": "99-referencias.html",
    "href": "99-referencias.html",
    "title": "Referencias",
    "section": "",
    "text": "Bishop, Christopher M. 2006. Pattern Recognition and Machine\nLearning (Information Science and Statistics). Secaucus, NJ, USA:\nSpringer-Verlag New York, Inc.\n\n\nCinelli, Carlos, Andrew Forney, and Judea Pearl. “A Crash Course\nin Good and Bad Controls.” Sociological Methods &\nResearch 0 (0): 00491241221099552. https://doi.org/10.1177/00491241221099552.\n\n\nFreedman, David A. 1991. “Statistical Models and Shoe\nLeather.” Sociological Methodology 21: 291–313. http://www.jstor.org/stable/270939.\n\n\nHernández-Díaz, Sonia, Enrique F. Schisterman, and Miguel A. Hernán.\n2006. “The Birth Weight ‘Paradox’\nUncovered?” American Journal of Epidemiology 164\n(11): 1115–20. https://doi.org/10.1093/aje/kwj275.\n\n\nImbens, Guido W., and Donald B. Rubin. 2015. Causal Inference for\nStatistics, Social, and Biomedical Sciences: An Introduction.\nCambridge University Press. https://doi.org/10.1017/CBO9781139025751.\n\n\nJulious, Steven A, and Mark A Mullee. 1994. “Confounding and\nSimpson’s Paradox.” BMJ 309 (6967):\n1480–81. https://doi.org/10.1136/bmj.309.6967.1480.\n\n\nKoller, D., and N. Friedman. 2009. Probabilistic Graphical Models:\nPrinciples and Techniques. MIT Press.\n\n\nMcElreath, Richard. 2015. Statistical Rethinking, a Course in r and\nStan. http://xcelab.net/rmpubs/rethinking/Statistical_Rethinking_sample.pdf.\n\n\nMorgan, S. L., and C. Winship. 2015. Counterfactuals and Causal\nInference. Analytical Methods for Social Research. Cambridge\nUniversity Press. https://books.google.com.mx/books?id=Q6YaBQAAQBAJ.\n\n\nPearl, J., M. Glymour, and N. P. Jewell. 2016. Causal Inference in\nStatistics: A Primer. Wiley. https://books.google.com.mx/books?id=L3G-CgAAQBAJ.\n\n\nRubin, Donald B. 2005. “Causal Inference Using Potential\nOutcomes.” Journal of the American Statistical\nAssociation 100 (469): 322–31. https://doi.org/10.1198/016214504000001880."
  },
  {
    "objectID": "apendice-1.html#demostración-de-regla-de-puerta-delantera",
    "href": "apendice-1.html#demostración-de-regla-de-puerta-delantera",
    "title": "Appendix A — Apéndice 1",
    "section": "A.1 Demostración de regla de puerta delantera:",
    "text": "A.1 Demostración de regla de puerta delantera:\nEsta es la demostración de Pearl (ver Book of Why) del criterio de puerta delantera:\nUsando probabilidad total:\n\\[p(c|do(f)) = \\int p(c|do(f),a) p(a|do(f))\\,da\\]\nPor la regla 2, como \\(C\\) y \\(A\\) están \\(d\\)-separados dado \\(F\\) (no hay puertas traseras entre \\(T\\) y \\(C\\)):\n\\[p(c|do(f)) = \\int p(c|do(f),do(a)) p(a|f)\\,da\\] Por la regla 3, \\(do(f)\\) no tiene efecto si condicionamos a \\(A\\):\n\\[p(c|do(f)) = \\int p(c|do(a)) p(a|f)\\,da\\]\nAhora estratificamos por \\(F\\): or probabilidad total tenemos\n\\[p(c|do(f)) = \\int \\left [ \\int p(c|do(a),f´)p(f´|do(a)) \\, df´ \\right ] p(a|f) \\,da\\]\nPor la regla 2 (\\(F\\) bloquea caminos de puerta trasera en \\(A\\) a \\(F\\)):\n\\[p(c|do(f)) = \\int \\left [ \\int p(c|a,f´)p(f´|do(a)) \\, df´ \\right ] p(a|f) \\,da\\]\nY aplicando la regla 3:\n\\[p(c|do(f)) = \\int \\left [ \\int p(c|a,f´)p(f´) \\, df´ \\right ] p(a|f) \\,da\\]"
  }
]